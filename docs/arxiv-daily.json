{
    "agent": {
        "2411.18266": "|**2024-11-27**|**Wearable intelligent throat enables natural speech in stroke patients with dysarthria**|Chenyu Tang et.al.|[2411.18266](http://arxiv.org/abs/2411.18266)|null|可穿戴无声语音系统在恢复言语障碍患者的沟通方面具有巨大潜力。然而，无缝、连贯的语音仍然难以实现，临床疗效尚未得到证实。在此，我们提出了一种由人工智能驱动的智能喉部（IT）系统，该系统集成了喉部肌肉振动和颈动脉脉搏信号传感器以及大型语言模型（LLM）处理，以实现流畅、富有情感表达的沟通。该系统利用超灵敏的纺织应变传感器从颈部区域捕捉高质量信号，并支持token级别的处理，以实现实时、连续的语音解码，从而实现无缝、无延迟的通信。在测试中，使用五种言语障碍的卒中患者进行测试，IT的LLM智能代理智能地纠正token错误，丰富句子级情感和逻辑连贯性，实现了低错误率（4.2%的词错误率，2.9%的句子错误率）和用户满意度55%的增长。这项工作为言语障碍患者建立了一个便携、直观的通信平台，有望广泛应用于不同的神经学条件和多语言支持系统。|\n",
        "2411.17636": "|**2024-11-26**|**MALMM: Multi-Agent Large Language Models for Zero-Shot Robotics Manipulation**|Harsh Singh et.al.|[2411.17636](http://arxiv.org/abs/2411.17636)|null|大型语言模型（LLMs）在各种领域，包括机器人操作和导航，展现了出色的规划能力。虽然最近在机器人领域的努力已经利用LLMs进行高级和低级规划，但这些方法通常面临重大挑战，如长期任务中的幻觉以及由于在单次生成计划时缺乏实时反馈而导致的适应性有限。为了解决这些限制，我们提出了一种新的多智能体LLM框架，即用于操作的智能体大型语言模型（MALMM），它将高级规划和低级控制代码生成分配给专门的LLM智能体，并由一个额外的智能体动态管理转换。通过在每一步后纳入环境观察，我们的框架有效地处理了中间失败，并实现了适应性重新规划。与现有方法不同，我们的方法不依赖于预训练的技能策略或在上下文中学习的示例，并且可以推广到各种新的任务。我们在包括长期任务在内的九个RLBench任务上评估了我们的方法，并展示了其在零样本设置下解决机器人操作的能力，从而克服了现有基于LLM的操作方法的局限性。|\n",
        "2411.16031": "|**2024-11-25**|**Agent-Based Modelling Meets Generative AI in Social Network Simulations**|Antonino Ferraro et.al.|[2411.16031](http://arxiv.org/abs/2411.16031)|null|基于代理建模（ABM）已成为模拟社交网络的重要工具，涵盖了诸如信息传播、影响力动态和社区形成等多种现象。然而，手动配置各种代理交互和信息流动态带来挑战，往往导致模型过于简化，缺乏现实世界的普适性。将现代大型语言模型（LLM）与ABM相结合为解决这些挑战和提升模拟真实度提供了一条有希望的途径，利用LLM在感知、推理和行为方面类似人类的能力。在本文中，我们提出了一种新颖的框架，该框架利用LLM赋能的代理根据用户的兴趣和个性特征模拟社交网络用户。该框架允许定制代理交互，类似于各种社交网络平台，包括内容重新分享和个性化推荐机制。我们使用2020年美国选举的全面Twitter数据集验证了我们的框架，证明LLM代理能够准确复制真实用户的言行，包括语言模式和政治倾向。这些代理形成了同质化的意识形态集群，并保留了其社区的主要主题。值得注意的是，基于偏好的推荐对代理行为有显著影响，促进了更高的参与度、网络同质性以及回音室的形成。总体而言，我们的发现突出了LLM代理在推进社交媒体模拟和揭示复杂在线动态中的潜力。|\n",
        "2411.15891": "|**2024-11-24**|**From Laws to Motivation: Guiding Exploration through Law-Based Reasoning and Rewards**|Ziyu Chen et.al.|[2411.15891](http://arxiv.org/abs/2411.15891)|null|大型语言模型（LLMs）和强化学习（RL）是构建自主智能体的两种强大方法。然而，由于对游戏环境的理解有限，智能体往往依赖低效的探索和试错，难以发展长期策略或做出决策。我们提出了一种方法，通过从交互记录中提取经验来模拟游戏环境的潜在规律，并利用这些经验作为内部动机来引导智能体。这些经验以语言形式表达，非常灵活，既可以直接协助智能体进行推理，也可以转化为训练中的奖励。在Crafter上的评估结果显示，RL和LLM智能体都从这些经验中受益，从而提高了整体性能。|\n",
        "2411.16723": "|**2024-11-23**|**Two Heads Are Better Than One: Collaborative LLM Embodied Agents for Human-Robot Interaction**|Mitchell Rosser et.al.|[2411.16723](http://arxiv.org/abs/2411.16723)|null|随着自然语言生成模型（称为大型语言模型，LLMs）的近期发展，一种潜在的应用场景得以开启，即改进人类与机器人助手互动的方式。这些LLMs应能利用其广泛的理解能力，将自然语言命令解释为有效、符合任务和安全的机器人任务执行。然而，在现实中，这些模型存在幻觉问题，可能会引起安全问题或偏离任务。在其他领域，这些问题已通过使用协作人工智能系统得到改善，在该系统中，多个LLM代理可以共同规划、编码和自我检查输出。在本研究中，通过将多个协作人工智能系统与单个独立人工智能代理进行对比测试，以确定在其他领域的成功是否能够转化为改进的人机交互性能。结果显示，代理数量与模型的成功率之间没有明确的趋势。然而，很明显，某些协作人工智能代理架构可以显著提高生成无错误代码和解决抽象问题的能力。|\n",
        "2411.15396": "|**2024-11-23**|**The Decoy Dilemma in Online Medical Information Evaluation: A Comparative Study of Credibility Assessments by LLM and Human Judges**|Jiqun Liu et.al.|[2411.15396](http://arxiv.org/abs/2411.15396)|null|人工智能在进行自动化信息判断任务时是否会产生认知偏差？尽管近期在衡量和缓解人工智能和大型语言模型（LLMs）中的社会和算法偏差方面取得了进展，但LLMs在多大程度上表现出“理性”行为，或者它们是否也容易受到人类认知偏差的触发，仍不明确。为了解决这个未解问题，我们的研究包括一个众包用户实验和一个LLM驱动的模拟实验，比较了在信息检索（IR）环境中，LLMs和人类评判员在潜在诱饵效应下的可信度评估，并实证研究了与传统的基于人类评估的基线相比，LLMs在COVID-19医疗（误）信息评估任务中的认知偏差程度。来自跨主体用户实验和LLM驱动的重复实验的结果表明：1）更大、更新版的LLMs在区分可信信息和虚假信息方面表现出更高的一致性和准确性。然而，由于存在更显著、更具诱饵性质的虚假信息结果，它们更有可能给予虚假信息更高的评分；2）虽然诱饵效应在人类和LLMs的评估中都发生了，但在LLMs的判断中，这种效应在不同条件和主题下比人类的可信度评分更为普遍。与普遍认为的AI工具的“理性”相反，我们的研究从实证上确认了LLM代理中嵌入的认知偏差风险，评估了诱饵对LLMs与人类可信度评估的影响，从而突出了去偏差AI代理、开发心理学导向的AI审计技术和政策（用于自动化判断任务及更多领域）的复杂性和重要性。|\n",
        "2411.15100": "|**2024-11-22**|**XGrammar: Flexible and Efficient Structured Generation Engine for Large Language Models**|Yixin Dong et.al.|[2411.15100](http://arxiv.org/abs/2411.15100)|null|LLM代理的应用正变得越来越复杂和多样化，导致对可以解析为代码、结构化函数调用和具身代理命令的规范化输出的需求日益增长。这些发展对LLM推理中的规范化生成提出了重大需求。无上下文文法是一种灵活的方法，通过限制解码来实现规范化生成。然而，执行无上下文文法需要在运行时遍历词汇表中所有标记的多个栈状态，给规范化生成带来不可忽视的开销。在本文中，我们提出了XGrammar，这是一个灵活且高效的LLM结构生成引擎。XGrammar通过将词汇表划分为可预检查的上下文无关标记和需要运行时解释的上下文相关标记来加速无上下文文法的执行。我们进一步构建了转换来扩展语法上下文并减少上下文无关标记的数量。此外，我们构建了一个高效的持久栈来加速上下文相关标记的检查。最后，我们与LLM推理引擎协同设计语法引擎，以重叠语法计算与GPU执行。评估结果显示，XGrammar可以比现有解决方案实现高达100倍的加速。结合LLM推理引擎，它可以在端到端低LLM服务中实现近乎零开销的结构化生成。|\n",
        "2411.15004": "|**2024-11-22**|**ScribeAgent: Towards Specialized Web Agents Using Production-Scale Workflow Data**|Junhong Shen et.al.|[2411.15004](http://arxiv.org/abs/2411.15004)|**[link](https://github.com/colonylabs/ScribeAgent)**|大型语言模型（LLM）代理正在迅速提升以处理越来越复杂的基于网络的任务。这些代理中的大多数依赖于通用、专有的模型如GPT-4，并专注于设计更好的提示以提升它们的规划能力。然而，通用LLM并未专门训练以理解专门的网络上下文，如HTML，并且它们通常在长期规划方面遇到困难。我们探索了一种替代方法，即使用从超过250个域名收集的生产规模工作流程数据对开源LLM进行微调，这些域名对应60亿个标记。这种方法简单而有效，在现有基准测试中相对于基于提示的代理显示了显著的优势——ScribeAgent在Mind2Web上实现了最先进的直接生成性能，并在WebArena上比之前最佳的文字型网络代理提高了14.1%的任务成功率。我们还对各种微调设计选择进行了详细的消融研究，并提供了关于LLM选择、训练配方、上下文窗口优化以及数据集大小影响等方面的见解。|\n",
        "2411.14214": "|**2024-11-21**|**Physics-Informed LLM-Agent for Automated Modulation Design in Power Electronics Systems**|Junhua Liu et.al.|[2411.14214](http://arxiv.org/abs/2411.14214)|null|基于LLM的自主代理在解决复杂工业任务方面表现出卓越的性能。然而，在追求碳中和和高性能可再生能源系统的过程中，现有的AI辅助设计自动化在可解释性、可扩展性和可用性方面面临着重大限制。为了解决这些挑战，我们提出了LP-COMDA，这是一个基于LLM的、物理信息丰富的自主代理，能够在最小人工监督下自动化电力电子系统中电力转换器的调制设计。与传统的AI辅助方法不同，LP-COMDA包含一个基于LLM的规划器，通过用户友好的聊天界面收集和验证设计规范。规划器随后与物理信息设计优化工具协调，自主迭代生成和优化调制设计。通过聊天界面，LP-COMDA提供可解释的设计过程，展示解释和图表。实验表明，LP-COMDA优于所有基线方法，在标准均方绝对误差方面，与第二好的基准方法相比，误差降低了63.2%。此外，对20位专家的实证研究表明，使用LP-COMDA的设计时间是传统方法的33倍以上，显示出其在设计效率方面的显著改进。|\n",
        "2411.14033": "|**2024-11-21**|**Multi-LLM-Agent Systems: Techniques and Business Perspectives**|Yingxuan Yang et.al.|[2411.14033](http://arxiv.org/abs/2411.14033)|null|在（多模态）大型语言模型时代，大多数操作流程都可以通过LLM智能体进行重构和再现。LLM智能体能够感知、控制和从环境中获取反馈，以自主方式完成给定任务。除了环境交互特性外，LLM智能体还可以调用各种外部工具以简化任务完成过程。这些工具可以被视为包含私有或实时知识且不存在于LLM参数中的预定义操作流程。作为发展的自然趋势，调用工具的智能体正成为自主智能体，因此完整的智能系统最终变成了多LLM智能体系统（MLAS）。本文讨论了MLAS的技术和商业格局。与之前的单一LLM智能体系统相比，MLAS具有以下优势：i) 更高的任务解决性能潜力；ii) 更高的系统变化灵活性；iii) 为每个参与实体保留专有数据；iv) 为每个实体实现货币化的可行性。为了支持MLAS生态系统，我们提供了一个考虑技术要求、数据隐私和商业激励的MLAS协议的初步版本。因此，MLAS将成为实现未来人工集体智慧的实用解决方案。|\n",
        "2411.19043": "|**2024-11-28**|**Using a Feedback Loop for LLM-based Infrastructure as Code Generation**|Mayur Amarnath Palavalli et.al.|[2411.19043](http://arxiv.org/abs/2411.19043)|**[link](https://github.com/Mayur-Palavalli/LLM-IaC-generation)**|**使用大型语言模型（LLMs）进行代码生成有助于提高软件开发者在编码任务中的生产力，但尚未对围绕这些代码的软件开发者的任务产生重大影响。特别是，基础设施管理的挑战仍然是一个未解之谜。我们研究了LLM代理利用基础设施即代码（IaC）范式构建基础设施的能力。我们特别研究了使用反馈循环，该循环会返回生成的IaC的错误和警告，以允许LLM代理改进代码。我们发现，对于循环的每一次迭代，其有效性都会呈指数下降，直到达到某个点并趋于平稳，最终变得无效。**|\n",
        "2411.18915": "|**2024-11-28**|**MATATA: a weak-supervised MAthematical Tool-Assisted reasoning for Tabular Applications**|Vishnou Vinayagame et.al.|[2411.18915](http://arxiv.org/abs/2411.18915)|null|随着工具增强的语言代理的数学推理能力不断增强，但现有方法通常依赖于闭源或大型模型、外部数据或大量的提示工程。这项工作介绍了一种名为MATATA的新颖且经济高效的方法，通过推理、规划和工具使用来训练LLM代理解决表格数据问题。它采用渐进式自我改进范式和迭代式弱监督，赋予了38亿/80亿小语言模型（SLM）的能力，特别适合于本地托管和敏感的商业环境，在这些环境中数据隐私至关重要。通过在不同数据集上使用灵活且可重用的工具，它实现了在共享任务上的有效可扩展性。实验表明，MATATA在基于开源模型的推理框架中，在FinQA和TAT-QA上达到了最先进的性能。此外，MATATA模型在TabMWP上与基于GPT-4的框架竞争，同时仍然是SLM。|\n",
        "2412.01778": "|**2024-12-02**|**HackSynth: LLM Agent and Evaluation Framework for Autonomous Penetration Testing**|Lajos Muzsai et.al.|[2412.01778](http://arxiv.org/abs/2412.01778)|**[link](https://github.com/aielte-research/HackSynth)**|**我们介绍了HackSynth，这是一种基于大型语言模型（LLM）的全新自主渗透测试代理。HackSynth的双模块架构包括一个规划器和总结器，这使得它能够迭代地生成命令和处理反馈。为了对HackSynth进行基准测试，我们提出了两个基于Capture The Flag（CTF）的新基准集，利用流行的平台PicoCTF和OverTheWire。这些基准集涵盖了200个不同领域和难度的挑战，为评估基于LLM的渗透测试代理提供了一个标准化的框架。基于这些基准，我们展示了广泛的实验，分析了HackSynth的核心参数，包括创新性（温度和top-p）和标记利用。我们使用了多个开源和专有LLM来衡量代理的能力。实验表明，该代理在GPT-4o模型下表现最佳，优于GPT-4o的系统卡片所建议的。我们还讨论了HackSynth行动的安全性和可预测性。我们的发现表明，基于LLM的代理在推进自主渗透测试方面的潜力，以及稳健保障的重要性。HackSynth和基准集公开可用，以促进自主网络安全解决方案的研究。**|\n",
        "2412.01605": "|**2024-12-02**|**Medchain: Bridging the Gap Between LLM Agents and Clinical Practice through Interactive Sequential Benchmarking**|Jie Liu et.al.|[2412.01605](http://arxiv.org/abs/2412.01605)|null|临床决策（CDM）是医疗保健服务中复杂且动态的过程，但对于人工智能系统来说仍然是一个重大挑战。尽管基于大型语言模型（LLM）的智能体已在执照考试和知识问答任务中测试了一般医学知识，但由于缺乏反映实际医疗实践的全面测试数据集，它们在现实场景中的CDM表现有限。为了解决这一差距，我们提出了MedChain，一个包含12,163个临床案例的数据集，涵盖了临床工作流程的五个关键阶段。MedChain与现有基准相比，具有三个反映现实临床实践的显著特点：个性化、交互性和顺序性。此外，为了应对现实世界中的CDM挑战，我们还提出了MedChain-Agent，这是一个集成了反馈机制和MCase-RAG模块的人工智能系统，以便从以往案例中学习并调整其响应。MedChain-Agent在动态收集信息和处理顺序临床任务方面表现出惊人的适应性，显著优于现有方法。在本文被接受后，将发布相关数据集和代码。|\n",
        "2412.01333": "|**2024-12-02**|**Can Large Language Models Serve as Evaluators for Code Summarization?**|Yang Wu et.al.|[2412.01333](http://arxiv.org/abs/2412.01333)|**[link](https://github.com/CGCL-codes/naturalcc)**|**代码摘要通过将代码片段转换为自然语言描述，有助于程序理解和软件维护。多年来，为这项任务开发了众多方法，但一个关键挑战仍然存在：有效地评估生成摘要的质量。虽然人工评估在评估代码摘要质量方面是有效的，但它劳动密集且难以扩展。常用的自动指标，如BLEU、ROUGE-L、METEOR和BertScore，通常与人工判断的关联性不强。在本文中，我们探讨了大型语言模型（LLMs）在评估代码摘要方面的潜力。我们提出了CODERPE（代码摘要评估中的角色扮演者），这是一种利用角色扮演提示来评估生成摘要质量的新方法。具体来说，我们提示LLM代理扮演各种角色，如代码审阅者、代码作者、代码编辑和系统分析师。每个角色从关键维度评估代码摘要的质量，包括连贯性、一致性、流畅性和相关性。我们进一步通过采用各种提示策略，包括思维链推理、情境学习和定制评分表设计，探索了LLMs作为评估者的鲁棒性。结果表明，LLMs作为代码摘要方法的有效评估者。值得注意的是，我们的基于LLM的评估器CODERPE与人工评估的斯皮尔曼相关系数为81.59%，比现有的BERTScore指标高17.27%。**|\n",
        "2412.01303": "|**2024-12-02**|**RL2: Reinforce Large Language Model to Assist Safe Reinforcement Learning for Energy Management of Active Distribution Networks**|Xu Yang et.al.|[2412.01303](http://arxiv.org/abs/2412.01303)|null|随着大规模分布式能源资源被集成到主动配电网络（ADN）中，与传统的配电网络相比，在ADN中实现有效的能源管理变得越来越突出。尽管先进的强化学习方法（RL）极大地提高了ADN能源管理的效率，减轻了复杂建模和优化的负担，但安全性成为RL在实际问题应用中的关键关注点。由于与操作安全约束相对应的惩罚函数的设计和调整需要RL和电力系统操作方面的广泛领域知识，新兴的ADN运营商呼吁采用更灵活和定制化的方法来解决惩罚函数，以便进一步提高操作安全和效率。凭借强大的理解、推理和在上下文中学习的能力，大型语言模型（LLM）为辅助ADN能源管理的安全RL提供了一种有希望的途径。在本文中，我们引入LLM来理解ADN中的操作安全要求并生成相应的惩罚函数。此外，我们提出了一种RL2机制，通过多轮对话迭代和自适应地改进生成的函数，其中LLM代理根据下游RL代理的训练和测试性能调整函数的模式和参数。所提出的方法显著减少了ADN运营商的干预。综合测试结果证明了所提出方法的有效性。|\n",
        "2412.01033": "|**2024-12-02**|**SAUP: Situation Awareness Uncertainty Propagation on LLM Agent**|Qiwei Zhao et.al.|[2412.01033](http://arxiv.org/abs/2412.01033)|null|大型语言模型（LLMs）集成到多步骤智能体系统中，能够在各种应用中实现复杂的决策过程。然而，它们的输出通常缺乏可靠性，因此不确定性估计变得至关重要。现有的不确定性估计方法主要关注最终步骤的输出，未能考虑到多步骤决策过程中的累积不确定性和智能体与其环境之间的动态交互。为了解决这些局限性，我们提出了SAUP（情境感知不确定性传播），这是一个新颖的框架，它通过LLM智能体推理过程的每一步传播不确定性。SAUP通过在传播过程中为每一步的不确定性分配情境权重来融入情境感知。我们的方法与各种单步不确定性估计技术兼容，提供了一个全面且准确的不确定性度量。在基准数据集上的大量实验表明，SAUP显著优于现有最先进的方法，实现了AUROC达到20%的提升。|\n",
        "2412.02776": "|**2024-12-03**|**Hacking CTFs with Plain Agents**|Rustem Turtayev et.al.|[2412.02776](http://arxiv.org/abs/2412.02776)|**[link](https://github.com/palisaderesearch/intercode)**|**我们通过简单的LLM代理设计饱和了一所高中水平的黑客基准测试。具体来说，我们通过提示、工具使用和多次尝试，在InterCode-CTF这个流行的进攻性安全基准测试上获得了95%的性能。这一成绩超过了Phuong等人2024年（29%）和Abramovich等人2024年（72%）的研究成果。我们的结果表明，当前的大型语言模型在进攻性网络安全方面已经超越了高中水平。它们的黑客能力尚未得到充分发掘：我们提出的ReAct&Plan提示策略在1-2个回合内解决了许多挑战，无需复杂的工程或高级利用。**|\n",
        "2412.04093": "|**2024-12-05**|**Practical Considerations for Agentic LLM Systems**|Chris Sypherd et.al.|[2412.04093](http://arxiv.org/abs/2412.04093)|null|近年来，随着大型语言模型（LLMs）的强大能力日益增长，对其作为自主代理基础模型的兴趣也随之增加。尽管LLMs在自然语言领域展现出涌现的能力和广泛的专业知识，但它们固有的不可预测性使得LLMs代理的实施变得具有挑战性，导致相关研究与这类系统的实际应用之间存在差距。为了弥合这一差距，本文将研究社区中的可操作见解和考虑因素置于既定应用范式之中，以促进稳健的LLMs代理的构建和明智的部署。具体而言，我们根据应用导向文献中的常见实践，将相关研究发现定位为四个广泛类别——规划、记忆、工具和控制流——并强调了在设计用于实际应用的代理型LLMs时需要考虑的实际因素，例如处理随机性和高效管理资源。虽然我们没有进行实证评估，但我们为讨论代理型LLMs设计的关键方面提供了必要的背景，无论是在学术界还是在工业界。|\n",
        "2412.04090": "|**2024-12-05**|**LossAgent: Towards Any Optimization Objectives for Image Processing with LLM Agents**|Bingchen Li et.al.|[2412.04090](http://arxiv.org/abs/2412.04090)|null|我们提出了首个名为LossAgent的损失代理，用于低级图像处理任务，例如图像超分辨率和修复，旨在实现不同实际应用中低级图像处理的各种定制优化目标。值得注意的是，并非所有优化目标，如复杂的定制感知度量、文本描述和复杂的人类反馈，都能用现有的低级损失，例如均方误差损失（MSE loss），来实例化，这在端到端优化图像处理网络时提出了一个关键挑战。为了解决这个问题，我们的LossAgent引入了强大的大型语言模型（LLM）作为损失代理，丰富的先验知识文本理解赋予损失代理在低级图像处理网络优化过程中的复杂优化目标、轨迹和状态反馈的理解潜力。特别是，我们通过整合支持端到端优化低级图像处理现有损失函数建立了损失库。然后，我们为损失代理设计了面向优化的提示工程，使其在每个优化交互中能够积极和智能地决定库中每个损失的组合权重，从而实现任何定制优化目标所需的优化轨迹。在三个典型低级图像处理任务和多个优化目标上的大量实验表明了我们所提出的LossAgent的有效性和适用性。代码和预训练模型将在https://github.com/lbc12345/LossAgent上提供。|\n",
        "2412.03904": "|**2024-12-05**|**MISR: Measuring Instrumental Self-Reasoning in Frontier Models**|Kai Fronsdal et.al.|[2412.03904](http://arxiv.org/abs/2412.03904)|**[link](https://github.com/kaifronsdal/self-reasoning-evals)**|**我们提出了一套任务，用于评估大型语言模型（LLM）代理的工具体验推理能力。工具体验推理能力可以提高适应性和实现自我修改，但也可能带来重大风险，例如导致欺骗性对齐。先前的研究只评估了非代理环境或有限领域的自我推理。在本文中，我们提出了在广泛场景下，包括自我修改、知识寻求和模糊自我推理的代理任务中评估工具体验推理能力的方案。我们评估了使用最先进LLM构建的代理，包括商业和开源系统。我们发现，工具体验推理能力仅在最先进的边缘模型中体现，并且高度依赖于上下文。没有模型通过我们评估中最困难版本，因此我们的评估可以用于衡量未来模型工具体验推理能力的提升。我们在https://github.com/kaifronsdal/Self-Reasoning-Evals上开源了我们的评估。**|\n",
        "2412.03847": "|**2024-12-05**|**Educational-Psychological Dialogue Robot Based on Multi-Agent Collaboration**|Shiwen Ni et.al.|[2412.03847](http://arxiv.org/abs/2412.03847)|null|智能对话系统在现代教育和心理辅导领域得到越来越广泛的应用，但大多数现有系统局限于单一领域，无法同时处理教育和心理问题，并且在处理复杂问题时往往缺乏准确性和专业性。为了解决这些问题，本文提出了一种结合教育和心理辅导功能的智能对话系统。该系统由多个AI代理组成，包括安全检测代理、意图识别代理、教育LLM代理和心理LLM代理，它们协同工作以确保提供准确的教育知识问答和心理健康支持服务。具体来说，系统通过意图分类模型识别用户输入的意图，并调用增强检索的教育大型模型和心理大型模型（该模型已使用心理数据进行微调），以便提供专业的教育建议和心理健康支持。|\n",
        "2412.05093": "|**2024-12-06**|**Sense and Sensitivity: Evaluating the simulation of social dynamics via Large Language Models**|Da Ju et.al.|[2412.05093](http://arxiv.org/abs/2412.05093)|null|大型语言模型（LLMs）越来越多地被提议作为经典基于代理模型（ABMs）的有力替代，以模拟社会动态。通过将LLMs作为人类行为的代理，这种新方法希望通过模拟比经典ABMs更为复杂的动态，并在社会科学、政治科学和经济学等领域获得新的见解。然而，由于LLMs的“黑盒”性质，不清楚LLM代理是否实际上执行了编码在它们自然语言指令中的预期语义，以及由此产生的互动动态是否具有意义。为了研究这个问题，我们提出了一种新的评估框架，将LLM模拟建立在社会科学中已建立的参考模型的动态基础之上。我们将LLMs视为一个黑盒函数，评估它们的输入输出行为相对于这个参考模型，这使我们能够评估它们行为的详细方面。我们的结果表明，虽然可以通过设计提示来近似预期的动态，但这些模拟的质量高度依赖于特定提示的选择。重要的是，模拟甚至对任意的变异，如细微的文字变化和空格使用，都非常敏感。这引发了当前版本LLMs在有意义模拟中的有用性的质疑，因为没有参考模型，无法事先确定看似无意义的提示变化对模拟的影响。|\n",
        "2412.06724": "|**2024-12-09**|**AutoDCWorkflow: LLM-based Data Cleaning Workflow Auto-Generation and Benchmark**|Lan Li et.al.|[2412.06724](http://arxiv.org/abs/2412.06724)|**[link](https://github.com/LanLi2017/LLM4DC)**|**我们研究了大型语言模型（LLMs）在自动生成数据清洗工作流程中的推理能力。为了评估LLMs完成数据清洗任务的能力，我们实施了一个基于LLM的自动数据清洗工作流程（AutoDCWorkflow）的管道，通过提示LLMs进行数据清洗操作来修复三种类型的数据质量问题：重复数据、缺失值和不一致的数据格式。给定一个脏表和一个目的（以查询的形式表达），此管道生成一个最小的、干净的表，足以满足目的，并使用生成该表的数据清洗工作流程。规划过程涉及三个主要的LLM驱动组件：（1）选择目标列：识别与目的相关的目标列集合。（2）检查列质量：评估每个目标列的数据质量，并生成数据质量报告作为操作目标。（3）生成操作和参数：根据数据质量报告的结果预测下一个操作和参数。此外，我们提出一个数据清洗基准，以评估LLM代理自动生成解决不同难度水平的数据清洗目的的工作流程的能力。基准包括注释的数据集，作为目的、原始表、清洗表、数据清洗工作流程和答案集的集合。在我们的实验中，我们评估了三种自动生成目的驱动数据清洗工作流程的LLMs。结果表明，LLMs在规划和生成数据清洗工作流程方面表现良好，无需微调。**|\n",
        "2412.06681": "|**2024-12-09**|**Toward LLM-Agent-Based Modeling of Transportation Systems: A Conceptual Framework**|Tianming Liu et.al.|[2412.06681](http://arxiv.org/abs/2412.06681)|null|在交通系统需求建模和仿真领域，基于代理的模型和微观仿真是目前最先进的方法。然而，现有的基于代理的模型在行为真实性和资源需求方面仍存在一些局限性，这限制了它们的应用。在本研究中，利用新兴的大语言模型（LLMs）和基于LLMs的代理技术，我们提出了一种通用的LLM-代理建模框架，用于交通系统。我们认为，LLM代理不仅具备作为代理的基本能力，而且为克服现有基于代理模型的某些局限性提供了有前景的解决方案。我们的概念框架设计紧密模拟了交通网络中人类旅行者的决策和交互过程及特征，并通过相关研究和LLM代理在瓶颈设置中的学习和调整的示范实例，证明所提出系统能够满足决策和学习行为的临界行为标准。尽管需要进一步细化基于LLM的代理建模框架，但我们相信这种方法有可能改善交通系统建模和仿真。|\n",
        "2412.06294": "|**2024-12-09**|**Beyond pip install: Evaluating LLM Agents for the Automated Installation of Python Projects**|Louis Milliken et.al.|[2412.06294](http://arxiv.org/abs/2412.06294)|null|近期，许多研究提出了使用大型语言模型（LLM）构建的智能体来执行所谓的“仓库级别”任务，这些任务的范围大于单个文件。这引发了一种假设，即这些仓库级别任务的编排将导致能够几乎独立于人类干预的软件工程智能体。然而，我们认为，对于这个自主软件工程智能体需要执行的任务套件中，有一个重要的任务缺失，那就是通过安装其他仓库来满足项目级别的依赖关系。为了研究这种仓库级别安装任务的可行性，我们引入了一个基准，该基准由40个开源Python项目中的仓库安装任务组成，包括每个目标仓库的地面真实安装过程。此外，我们提出了Installamatic智能体，该智能体的目标是通过对仓库中的文档进行搜索，执行并验证给定仓库的安装。实证实验表明，55%的研究仓库至少在十次尝试中可以被我们的智能体自动安装。通过进一步分析，我们确定了我们的智能体无法安装仓库的常见原因，讨论了设计和实现此类智能体所面临的挑战，并考虑了此类智能体对开发者的潜在影响。|\n",
        "2412.05850": "|**2024-12-08**|**Cooperative SQL Generation for Segmented Databases By Using Multi-functional LLM Agents**|Zhiguang Wu et.al.|[2412.05850](http://arxiv.org/abs/2412.05850)|null|文本到SQL任务旨在根据用户的文本问题自动生成SQL查询。为了解决这个问题，我们提出了一种基于多功能代理（CSMA）的协作SQL生成框架，通过大型语言模型（LLM）基于的代理之间的信息交互来实现，这些代理分别拥有部分数据库模式。受到人类团队合作中的协作的启发，CSMA包括三个阶段：1）与问题相关的模式收集，2）对应问题的SQL查询生成，3）SQL查询正确性检查。在第一阶段，代理分析各自的模式并相互沟通以收集与问题相关的模式信息。在第二阶段，代理尝试使用收集到的信息为问题生成相应的SQL查询。在第三阶段，代理检查根据他们已知的信息SQL查询是否被正确创建。这种基于交互的方法使得每个代理的问题相关的数据库模式部分被用于SQL生成和检查。在Spider和Bird基准测试上的实验表明，CSMA实现了与现有技术水平相当的高性能，同时保持了这些个体代理中的私有数据。|\n",
        "2412.07646": "|**2024-12-10**|**Searching for Structure: Investigating Emergent Communication with Large Language Models**|Tom Kouwenhoven et.al.|[2412.07646](http://arxiv.org/abs/2412.07646)|null|人类语言通过重复的语言学习和使用而演变成结构化的。这些过程在语言习得过程中引入了偏差，并使语言系统朝着沟通效率的方向发展。在本文中，我们研究了如果人工语言被优化为适应大型语言模型（LLMs）的隐性偏差，是否会发生同样的事情。为此，我们模拟了一个经典指称游戏，其中LLMs学习和使用人工语言。我们的结果表明，最初无结构的整体语言确实被塑造出一些结构特性，使得两个LLMs代理能够成功沟通。与人类实验中的观察相似，代际传承提高了语言的易学性，但同时也可能导致非人类化的退化词汇。综上所述，这项工作扩展了实验发现，表明LLMs可以用作模拟语言进化的工具，并为该领域未来的人机实验开辟了可能性。|\n",
        "2412.06828": "|**2024-12-06**|**Enhancing LLMs for Impression Generation in Radiology Reports through a Multi-Agent System**|Fang Zeng et.al.|[2412.06828](http://arxiv.org/abs/2412.06828)|null|本研究介绍了“RadCouncil”，这是一个多智能体大型语言模型（LLM）框架，旨在增强放射学报告中发现部分的印象生成。RadCouncil由三个专业代理组成：1）一个“检索”代理，用于从向量数据库中识别和检索相似报告；2）一个“放射科医生”代理，根据给定报告中的发现部分以及检索代理检索到的示例报告生成印象；3）一个“审稿人”代理，评估生成的印象并提供反馈。RadCouncil的性能使用定量指标（BLEU、ROUGE、BERTScore）和由GPT-4评估的定性标准进行了评估，以胸部X光片作为案例研究。实验结果表明，在多个维度上，包括诊断准确性、风格一致性以及清晰度，RadCouncil相对于单代理方法都有所改进。这项研究强调了利用多个相互作用的LLM代理（每个代理都承担专用任务）来提高专业医疗任务性能和开发更稳健、适应性更强的医疗AI解决方案的潜力。|\n",
        "2412.08445": "|**2024-12-11**|**TapeAgents: a Holistic Framework for Agent Development and Optimization**|Dzmitry Bahdanau et.al.|[2412.08445](http://arxiv.org/abs/2412.08445)|null|我们提出了TapeAgents，这是一个围绕粒度化和结构化的代理会话日志磁带而构建的代理框架，同时也充当会话的可恢复状态。在TapeAgents中，我们利用磁带来促进LLM代理开发生命周期的所有阶段。代理通过处理磁带和LLM的输出，产生新的思考和行动步骤，并将它们附加到磁带上。环境随后通过同样将观察步骤附加到磁带来对代理的行动做出反应。凭借这种以磁带为中心的设计，TapeAgents可以为AI从业者提供全方位的端到端支持。在开发阶段，磁带有助于会话持久化、代理审计和逐步调试。部署后，可以重用磁带进行评估、微调和提示调整；关键的是，可以从其他代理或使用修订的历史磁带进行适应。在本报告中，我们详细解释了TapeAgents的设计。我们通过构建单体代理和多代理团队的几个具体例子，以及优化代理提示和微调代理的LLM，展示了TapeAgents的可能应用。我们展示了工具原型，并报告了一个案例研究，其中我们使用TapeAgents来微调一个Llama-3.1-8B表单填写助手，使其表现与GPT-4o相当，而成本低得多。最后，我们的比较分析表明，TapeAgents相对于先前框架的优势源于我们关于LLM代理作为可恢复的、模块化状态机的创新设计，这种设计具有结构化的配置，可以生成粒度化和结构化的日志，并将这些日志转换为训练文本——这是以前工作中所缺乏的独特功能组合。|\n",
        "2412.08054": "|**2024-12-11**|**Federated In-Context LLM Agent Learning**|Panlong Wu et.al.|[2412.08054](http://arxiv.org/abs/2412.08054)|null|大型语言模型（LLMs）通过实现逻辑推理、工具使用以及作为代理与外部系统交互，彻底改变了智能服务。LLMs的发展常常受到高质量数据稀缺性的制约，其中大部分数据本质上是敏感的。联邦学习（FL）通过促进分布式LLMs的协作训练，同时保护私有数据，提供了一个潜在解决方案。然而，FL框架面临着显著的带宽和计算需求，以及来自异构数据分布的挑战。LLMs新兴的上下文学习能力通过聚集自然语言而非庞大的模型参数，提供了一种有前景的方法。然而，这种方法存在隐私泄露的风险，因为其需要收集和展示来自各个客户端的数据样本以进行聚合。在本文中，我们提出了一种新颖的隐私保护联邦上下文LLM代理学习（FICAL）算法，据我们所知，这是第一个释放上下文学习力量，通过FL训练多样化LLM代理的算法。在我们的设计中，由一个创新的LLM增强知识汇编生成（KCG）模块生成的知识汇编被传输到客户端和服务器之间，而不是像以前FL方法中那样传输模型参数。此外，我们还设计了一个基于检索增强生成（RAG）的工具学习与利用（TLU）模块，并将聚合的全局知识汇编作为教师，教授LLM代理工具的使用方法。我们进行了广泛的实验，结果表明，与SOTA基准相比，FICAL具有竞争优势，且通信成本降低了$\\mathbf{3.33\\times10^5}$倍。|\n",
        "2412.08014": "|**2024-12-11**|**MAGIC: Mastering Physical Adversarial Generation in Context through Collaborative LLM Agents**|Yun Xing et.al.|[2412.08014](http://arxiv.org/abs/2412.08014)|null|在驾驶场景中，物理对抗攻击可以暴露视觉感知模型的关键漏洞。然而，由于现实世界背景的多样性和保持视觉自然性的要求，开发此类攻击仍然具有挑战性。基于这一挑战，我们将物理对抗攻击重新定义为一次性的补丁生成问题。我们的方法通过考虑特定场景上下文的深度生成模型生成对抗补丁，使其能够直接在匹配环境中进行物理部署。主要挑战在于同时实现两个目标：生成能够有效误导目标检测系统的对抗补丁，并在场景中确定上下文适当的放置位置。我们提出了MAGIC（Mastering Physical Adversarial Generation In Context），这是一个由多模态LLM代理驱动的创新框架，旨在解决这些挑战。MAGIC自动理解场景上下文，并通过语言和视觉能力的协同作用来协调对抗补丁的生成。MAGIC协调三个专业的LLM代理：广告补丁生成代理（GAgent）通过战略提示工程掌握欺骗补丁的创建，用于文本到图像模型。广告补丁部署代理（DAgent）通过基于场景理解确定最佳放置策略来确保上下文一致性。自我审查代理（EAgent）通过提供对两个过程的批判性监督和迭代优化来完成这一三部曲。我们在数字和物理层面（即nuImage和手动捕获的真实场景）验证了我们的方法，统计和视觉结果都证明我们的MAGIC在攻击广泛使用的目标检测系统方面强大且有效。|\n",
        "2412.07822": "|**2024-12-10**|**MAGE: A Multi-Agent Engine for Automated RTL Code Generation**|Yujie Zhao et.al.|[2412.07822](http://arxiv.org/abs/2412.07822)|**[link](https://github.com/stable-lab/MAGE-A-Multi-Agent-Engine-for-Automated-RTL-Code-Generation)**|**随着大型语言模型（LLMs）的发展，通过自然语言指令自动生成RTL代码（例如Verilog）已成为一个有前景的方向。然而，生成既符合语法又功能正确的RTL代码仍然是一个重大挑战。现有的单LLM代理方法面临重大限制，因为它们必须在各种编程语言之间进行导航，并处理复杂的生成、验证和修改任务。为了解决这些挑战，本文介绍了MAGE，这是第一个为稳健和准确生成Verilog RTL代码而设计的开源多智能体AI系统。我们提出了一种新颖的高温RTL候选采样和调试系统，它有效地探索了代码候选空间，并显著提高了候选代码的质量。此外，我们设计了一种新颖的Verilog状态检查点检查机制，它能够早期检测功能错误，并针对特定修复提供精确的反馈，从而显著提高了生成RTL代码的功能正确性。MAGE在VerilogEval-Human 2基准测试中实现了95.7%的语法和功能正确率代码生成率，超过了目前最先进的Claude-3.5-sonnet 23.3%，证明了AI驱动RTL设计工作流程的稳健和可靠方法。**|\n",
        "2412.08685": "|**2024-12-11**|**ChatDyn: Language-Driven Multi-Actor Dynamics Generation in Street Scenes**|Yuxi Wei et.al.|[2412.08685](http://arxiv.org/abs/2412.08685)|null|根据特定指令生成逼真且交互的交通参与者动态对街景模拟至关重要。然而，目前尚缺乏一种综合方法，能够生成包括车辆和行人等不同类型参与者的真实动态，以及它们之间不同类型的交互。在本文中，我们介绍了ChatDyn，这是第一个能够根据语言指令在街景中生成交互、可控和真实参与者动态的系统。为了通过复杂的语言实现精确控制，ChatDyn采用了一种多LLM代理角色扮演方法，利用自然语言输入来规划不同交通参与者的轨迹和行为。为了根据规划生成逼真的细粒度动态，ChatDyn设计了两个新颖的执行器：行人执行器（PedExecutor），一个统一的多任务执行器，能够在不同的任务规划下生成逼真的行人动态；和车辆执行器（VehExecutor），一个基于物理转换的策略，能够生成物理上合理的车辆动态。大量实验表明，ChatDyn能够生成包含多辆车辆和行人的逼真驾驶场景动态，并在子任务上显著优于先前的方法。代码和模型将在https://vfishc.github.io/chatdyn处提供。|\n"
    },
    "llm": {
        "2411.18620": "|**2024-11-27**|**Cross-modal Information Flow in Multimodal Large Language Models**|Zhi Zhang et.al.|[2411.18620](http://arxiv.org/abs/2411.18620)|null|近期，自回归多模态大型语言模型（MLLMs）在视觉语言任务上的进展展现出令人鼓舞的成果。虽然已有多种研究探讨大型语言模型内部语言信息的处理，但目前对MLLM的内部工作机制以及语言和视觉信息在这些模型中如何互动的了解甚少。在本研究中，我们旨在通过考察MLLM中不同模态（语言和视觉）之间的信息流，特别是聚焦于视觉问答任务，来填补这一空白。具体来说，给定一个图像-问题对作为输入，我们研究在模型中视觉和语言信息是如何结合以生成最终预测的。通过对LLaVA系列中的一系列模型进行实验，我们发现两个模态的整合过程中存在两个不同的阶段。在底层，模型首先将整个图像的更一般化的视觉特征转移到（语言）问题标记的表示中。在中层，它再次将与问题相关的特定物体的视觉信息转移到问题的相应标记位置。最后，在高层，最终的多模态表示被传播到输入序列的最后位置进行最终预测。总体而言，我们的发现为MLLM中图像和语言处理的时空方面提供了新的全面视角，从而有助于未来对多模态信息定位和编辑的研究。|\n",
        "2411.18583": "|**2024-11-27**|**Automated Literature Review Using NLP Techniques and LLM-Based Retrieval-Augmented Generation**|Nurshat Fateh Ali et.al.|[2411.18583](http://arxiv.org/abs/2411.18583)|null|本研究提出了并比较了多种利用自然语言处理（NLP）技术和检索增强生成（RAG）与大型语言模型（LLM）来自动生成文献综述的方法。研究论文数量的不断增长为手动文献综述带来了巨大挑战，进而推动了自动化需求。本研究的主要目标是开发一个能够仅从PDF文件输入自动生成文献综述的系统。为了实现这一目标，评估了多种自然语言处理（NLP）策略的有效性，包括基于频率的方法（spaCy）、变换器模型（Simple T5）以及与大型语言模型（GPT-3.5-turbo）结合的检索增强生成（RAG）。选择SciTLDR数据集进行实验，并利用三种不同的技术实现三个不同的系统来自动生成文献综述。使用ROUGE分数对所有三个系统进行评估。根据评估结果，大型语言模型GPT-3.5-turbo实现了最高的ROUGE-1分数，为0.364。变换器模型排名第二，spaCy排名最后。最后，为基于大型语言模型的最佳系统创建了一个图形用户界面。|\n",
        "2411.18571": "|**2024-11-27**|**Challenges in Adapting Multilingual LLMs to Low-Resource Languages using LoRA PEFT Tuning**|Omkar Khade et.al.|[2411.18571](http://arxiv.org/abs/2411.18571)|null|大型语言模型（LLMs）展示了令人瞩目的多语言能力，但在为低资源语言调整这些模型时仍存在挑战。在本研究中，我们调查了低秩调整（LoRA）参数高效微调（PEFT）对马哈拉施特拉语Gemma多语言模型的影响，马哈拉施特拉语是一种资源有限的语种。使用含有52,000条指令-响应对的翻译Alpaca数据集，我们的研究发现，尽管评估指标通常显示在微调后性能下降，但手动评估通常表明微调后的模型优于其原始版本。观察表明，在语言适应后，目标语言生成能力有所提高，但推理能力有所下降。这些结果强调了改进评估方法以及创建高质量的本语种数据集的必要性，以便准确评估低资源环境中的语言特定模型性能。|\n",
        "2411.18564": "|**2024-11-27**|**A Pipeline of Neural-Symbolic Integration to Enhance Spatial Reasoning in Large Language Models**|Rong Wang et.al.|[2411.18564](http://arxiv.org/abs/2411.18564)|null|大型语言模型（LLMs）在各种任务上展现出了令人印象深刻的性能。然而，LLMs在空间推理方面往往存在困难，而空间推理是推理和推断的一个重要部分，需要理解空间中物体之间的复杂关系。本文提出了一种新颖的神经符号框架，以增强LLMs的空间推理能力。我们在两个基准数据集——StepGame和SparQA上评估了我们的方法，并实施了三种不同的策略：（1）基于ASP（答案集编程）的符号推理，（2）使用DSPy的LLM + ASP管道，以及（3）事实+逻辑规则。我们的实验表明，与基线提示方法相比，我们的方法在StepGame数据集上实现了40-50%的准确性提升，在更复杂的SparQA数据集上实现了3-13%的提升。特别是“LLM + ASP”管道在寻找关系（FR）和寻找块（FB）任务上取得了特别强的结果，尽管不同类型问题的性能有所差异。令人印象深刻的结果表明，虽然神经符号方法为增强LLMs的空间推理提供了有希望的方向，但它们的有效性在很大程度上取决于具体任务特性和实施策略。我们提出了一套集成的、简单而有效的策略，使用神经符号管道来提升LLMs的空间推理能力。这个管道及其策略在LLMs的推理领域具有广泛的适用性，如时间推理、演绎推理等。|\n",
        "2411.18562": "|**2024-11-27**|**DexDiffuser: Interaction-aware Diffusion Planning for Adaptive Dexterous Manipulation**|Zhixuan Liang et.al.|[2411.18562](http://arxiv.org/abs/2411.18562)|null|在高级机器人中，具有丰富接触交互的灵活操作至关重要。尽管基于扩散的规划方法在简单的操作任务中显示出希望，但它们往往会产生不切实际的幽灵状态（例如，物体在没有手接触的情况下自动移动）或在处理复杂的顺序交互时缺乏适应性。在这项工作中，我们介绍了DexDiffuser，这是一个用于自适应灵活操作的认知扩散规划框架。DexDiffuser通过一个双阶段扩散过程来模拟关节状态动作动力学，该过程包括预接触接触对齐和接触后的目标导向控制，从而实现目标自适应的通用灵活操作。此外，我们结合了基于动力学模型的二元指导和利用大型语言模型进行自动指导函数生成，增强了对物理交互的泛化能力，并通过语言提示促进多样化的目标适应。在物理交互任务（如开门、笔和块重新定位和锤子敲钉）上的实验证明了DexDiffuser在训练分布之外的目标上的有效性，其成功率超过现有方法的平均成功率（59.2%比29.5%）。我们的框架在30度开门任务上达到70.0%的成功率，在笔和块半侧重新定位任务上分别达到40.0%和36.7%，在锤子敲钉半驱动任务上达到46.7%，突出了其在富含接触的操控中的鲁棒性和灵活性。|\n",
        "2411.18553": "|**2024-11-27**|**Retrofitting (Large) Language Models with Dynamic Tokenization**|Darius Feher et.al.|[2411.18553](http://arxiv.org/abs/2411.18553)|null|当前的语言模型（LMs）通常使用固定、静态的子词分词器。这种选择往往被视为理所当然，通常会导致在英语以外的语言中效率降低和功能受限，同时也使得将LMs应用于新的领域或语言变得具有挑战性。为了解决这些问题，我们提出对LMs进行动态分词改造：一种根据输入文本动态决定分词边界的方法。对于编码器风格的模型，我们引入了一种受字节对编码（BPE）启发的子词合并算法，但它在批处理级别上工作。我们在批处理中合并频繁的子词序列，然后应用预训练的嵌入预测超网络实时计算分词嵌入。当与词级边界结合使用时，这在XNLI上的XLM-R模型中平均将分词序列长度减少了>20%，同时任务性能下降不到2%。对于解码器风格的模型，我们以两种方式应用动态分词：1）用于预填充，几乎完全保持Mistral-7B的性能，同时相对于词级减少了高达40%的序列长度；2）通过近似最近邻索引，实现快速生成，并使用一百万个词元的词汇量，展示了扩展到甚至更大、更动态的词汇表的能力。总的来说，我们的研究结果表明，动态分词显著提高了推理速度，并促进了语言间的公平性，向克服静态分词的局限性迈出了重要一步，使LMs更加公平和适应性强。|\n",
        "2411.18530": "|**2024-11-27**|**Emergence of Self-Identity in AI: A Mathematical Framework and Empirical Study with Generative Large Language Models**|Minhyeok Lee et.al.|[2411.18530](http://arxiv.org/abs/2411.18530)|**[link](https://github.com/BrainJellyPie/self)**|**本文介绍了一种数学框架，用于在人工智能（AI）系统中定义和量化自我认同，填补了人工意识理论基础的critical gap。尽管现有的关于人工自我意识的方法通常依赖于启发式实现或哲学抽象，但我们提出了一种以度量空间理论、测度理论和泛函分析为基础的正式框架。我们的框架认为，自我认同源于两个可数学量化的条件：在度量空间$(\\mathcal{M}, d_{\\mathcal{M}})$中存在一个连通的连续记忆集$C \\subseteq \\mathcal{M}$，以及一个连续映射$I: \\mathcal{M} \\to \\mathcal{S}$，它在这个连续集上保持一致的自我识别，其中$(\\mathcal{S}, d_{\\mathcal{S}})$代表可能自我认同的度量空间。为了验证这个理论框架，我们使用Llama 3.2 1B模型进行了实证实验，采用低秩适配（LoRA）进行高效的微调。该模型在一个包含时序结构记忆的合成数据集上进行了训练，旨在捕捉连贯自我认同形成的复杂性。我们的评估指标包括自我意识、响应一致性和语言精确性的量化度量。实验结果表明，可测量的自我意识指标有显著提高，主要自我意识分数从0.276提高到0.801。这使得可以结构化地创建具有经过验证的自我认同特征的AI系统。本研究的影响对类人机器人学和自主系统领域具有直接相关性。**|\n",
        "2411.18506": "|**2024-11-27**|**LLM-ABBA: Understand time series via symbolic approximation**|Erin Carson et.al.|[2411.18506](http://arxiv.org/abs/2411.18506)|null|在之前的研究中，大型语言模型（LLMs）在处理时间序列方面的成功已经得到证明。利用符号时间序列表示，可以有效地在LLMs和时间序列之间架起桥梁。然而，剩余的挑战是如何利用符号或LLMs现有标记中的时间序列隐含语义信息，同时根据时间序列的隐含信息调整LLMs的嵌入空间。名为自适应布朗桥符号聚合（ABBA）的符号时间序列近似（STSA）方法，通过以振幅和周期来建模时间序列模式，同时使用LLMs的现有标记，在保留显著时间序列特征方面表现出卓越的功效。在本文中，我们介绍了一种方法，称为LLM-ABBA，该方法将ABBA整合到大型语言模型中，用于各种下游时间序列任务。通过符号化时间序列，LLM-ABBA在UCR和三个医学时间序列分类任务中，与最近最先进的（SOTA）方法相比具有优势。同时，在ABBA中引入了固定多边形链技巧，通过显著减轻从符号到数值转换过程中由于符号误用而产生的累积误差的影响，来避免预测任务中的明显漂移。在时间序列回归任务中，LLM-ABBA在时间序列外部回归（TSER）基准测试上实现了新的SOTA。与最近SOTA的时间序列预测结果相比，LLM-ABBA也显示了具有竞争力的预测能力。我们相信这个框架也可以无缝地扩展到其他时间序列任务。|\n",
        "2411.18499": "|**2024-11-27**|**GATE OpenING: A Comprehensive Benchmark for Judging Open-ended Interleaved Image-Text Generation**|Pengfei Zhou et.al.|[2411.18499](http://arxiv.org/abs/2411.18499)|null|多模态大型语言模型（MLLMs）在视觉理解和生成任务方面取得了显著进展。然而，生成交织的图像-文本内容仍然是一个挑战，这需要综合的多模态理解和生成能力。虽然统一模型的进展提供了新的解决方案，但现有的基准由于数据量和多样性限制，不足以评估这些方法。为了填补这一差距，我们介绍了GATE OpenING（OpenING），这是一个包含5,400个高质量人工标注实例、涵盖56个真实世界任务的全面基准。OpenING覆盖了多样化的日常场景，如旅行指南、设计和头脑风暴，为挑战交织生成方法提供了一个强大的平台。此外，我们提出了IntJudge，这是一个用于评估开放式多模态生成方法的评判模型。使用新颖的数据流水线进行训练，我们的IntJudge与人类判断的吻合率达到82.42%，比基于GPT的评估器高出11.34%。在OpenING上的大量实验表明，当前的交织生成方法仍有很大的改进空间。关于交织图像-文本生成的关键发现进一步提出，以指导下一代模型的发展。OpenING已开源，请访问https://opening.github.io。|\n",
        "2411.18478": "|**2024-11-27**|**Beyond Examples: High-level Automated Reasoning Paradigm in In-Context Learning via MCTS**|Jinyang Wu et.al.|[2411.18478](http://arxiv.org/abs/2411.18478)|null|在上下文学习（ICL）中，通过复杂的提示和高质量演示，使大型语言模型（LLMs）能够处理下游任务。然而，当面对复杂的数学推理任务时，这种传统的ICL范式显示出局限性，主要是因为它对示例质量的依赖性很大，以及在挑战性场景中需要人类干预。为了解决这些局限性，本文提出了一种HiAR-ICL，这是一种在ICL中的高级自动推理范式，它将焦点从具体示例转移到抽象思维模式，扩展了ICL中传统的上下文概念。HiAR-ICL引入了五个原子推理动作作为构建链式模式的根本组成部分。使用蒙特卡洛树搜索，我们探索推理路径并构建思维卡片来指导后续推理。然后我们开发了一个认知复杂度框架，该框架动态地将问题与适当的思想卡片相匹配。实验结果表明，HiAR-ICL的有效性，使用Qwen2.5-7B-Instruct在MATH基准测试中实现了最先进的准确率（79.6%），超过了GPT-4o（76.6%）和Claude 3.5（71.1%）。|\n",
        "2411.19951": "|**2024-11-29**|**T2Vid: Translating Long Text into Multi-Image is the Catalyst for Video-LLMs**|Shukang Yin et.al.|[2411.19951](http://arxiv.org/abs/2411.19951)|**[link](https://github.com/xjtupanda/t2vid)**|**多模态大型语言模型（MLLMs）在图像领域的成功引起了研究界的广泛关注。借鉴以往的成功经验，研究人员最近探索将这一成功扩展到视频理解领域。除了从头开始训练外，一种高效的方法是利用预训练的图像-LLMs，从而产生了两种主流方法，即零样本推理和基于视频数据的进一步微调。在这项工作中，我们对这些方法的研究得出了一种有效的数据增强方法。我们首先对零样本推理方法进行了更深入的检查，并识别出两个限制，即泛化能力有限和缺乏时间理解能力。因此，我们进一步研究了微调方法，并发现当简单使用所有视频数据样本时，学习效率较低，这可以归因于指令多样性的缺乏。针对这个问题，我们开发了一种称为T2Vid的方法，用于生成类似视频的样本，以丰富训练语料库中的指令多样性。整合这些数据使得训练方案既简单又高效，通过仅用15%的样本量进行训练，就能达到与使用完整视频数据集相当甚至更好的性能。同时，我们发现所提出的方案可以在不使用长视频样本的情况下提升长视频理解性能。我们希望我们的研究能够激发更多关于使用MLLMs进行视频理解和高质量数据管理的思考。代码已发布在https://github.com/xjtupanda/T2Vid。**|\n",
        "2411.19943": "|**2024-11-29**|**Critical Tokens Matter: Token-Level Contrastive Estimation Enhances LLM's Reasoning Capability**|Zicheng Lin et.al.|[2411.19943](http://arxiv.org/abs/2411.19943)|null|大型语言模型（LLMs）在推理任务上表现出色。它们通过自回归标记生成来构建推理轨迹，从而发展出一套连贯的思维链条。在本工作中，我们探讨了单个标记对推理任务最终结果的影响。我们发现了“关键标记”的存在，这些标记会导致LLMs中产生错误的推理轨迹。具体来说，我们发现当LLMs被强迫解码其他标记而不是关键标记时，往往会产生积极的结果。受此启发，我们提出了一种新的方法——cDPO，旨在在对齐过程中自动识别和执行对关键标记的标记级奖励。具体来说，我们开发了一种对比估计方法来自动识别关键标记。这是通过比较正负模型的生成可能性来实现的。为此，我们分别对正负模型在不同推理轨迹上进行微调，从而使它们能够识别出导致错误结果的错误轨迹中的关键标记。此外，为了在对齐过程中进一步使模型与关键标记信息对齐，我们将传统的DPO算法扩展到标记级DPO，并利用上述正负模型之间的差异似然作为标记级DPO学习的重要权重。在GSM8K和MATH500基准测试中，使用两个广泛使用的模型Llama-3（8B和70B）和deepseek-math（7B）进行的实验结果表明，所提出的cDPO方法的有效性。|\n",
        "2411.19939": "|**2024-11-29**|**VLSBench: Unveiling Visual Leakage in Multimodal Safety**|Xuhao Hu et.al.|[2411.19939](http://arxiv.org/abs/2411.19939)|null|多模态大型语言模型（MLLMs）的安全性担忧在各个应用领域逐渐成为了一个重要问题。令人惊讶的是，以往的研究指出了一种反直觉的现象，即使用文本未学习（textual unlearning）来调整MLLMs，其安全性表现与使用图文对（image-text pairs）训练的MLLMs相当。为了解释这一反直觉的现象，我们发现在现有的多模态安全基准中存在视觉安全信息泄露（VSIL）问题，即图像中潜在的风险和敏感内容在文本查询中已经暴露出来。这样一来，MLLMs可以轻易地根据文本查询拒绝这些敏感的图文查询。然而，在现实场景中，没有VSIL的图文对很常见，而被现有的多模态安全基准所忽视。为此，我们构建了多模态视觉无泄露安全基准（VLSBench），该基准包含2.4k个图文对，旨在防止视觉安全信息从图像泄露到文本查询。实验结果表明，VLSBench对开源和闭源MLLMs，包括LLaVA、Qwen2-VL、Llama3.2-Vision和GPT-4o，都提出了显著挑战。这项研究证明了在存在VSIL的多模态安全场景中，文本对齐就足够了，而对于没有VSIL的多模态安全场景，多模态对齐则是一个更有前途的解决方案。请参阅我们的代码和数据：http://hxhcreate.github.io/VLSBench|\n",
        "2411.19930": "|**2024-11-29**|**On Domain-Specific Post-Training for Multimodal Large Language Models**|Daixuan Cheng et.al.|[2411.19930](http://arxiv.org/abs/2411.19930)|null|近年来，通用多模态大型语言模型（MLLMs）的发展迅速。然而，将通用MLLMs应用于特定领域，如科学领域和工业应用，仍鲜有探索。本文系统地通过后训练研究MLLMs的领域自适应，重点关注数据合成、训练流程和任务评估。（1）数据合成：利用开源模型，我们开发了一个视觉指令合成器，能有效从特定领域的图像-描述对生成多样化的视觉指令任务。我们的合成任务在增强MLLMs领域特定性能方面优于手动规则、GPT-4和GPT-4V生成的任务。（2）训练流程：虽然两阶段训练——最初在图像-描述对上进行，然后进行视觉指令任务——是开发通用MLLMs的常用方法，但我们采用单阶段训练流程来增强领域特定后训练的任务多样性。（3）任务评估：我们通过对不同来源和规模（例如，Qwen2-VL-2B，LLaVA-v1.6-8B，Llama-3.2-11B）的MLLMs进行后训练，在生物医药和食品两个领域进行实验，然后评估MLLMs在各种领域特定任务上的性能。为了支持MLLMs领域自适应的进一步研究，我们将开源我们的实现。|\n",
        "2411.19921": "|**2024-11-29**|**SIMS: Simulating Human-Scene Interactions with Real World Script Planning**|Wenjia Wang et.al.|[2411.19921](http://arxiv.org/abs/2411.19921)|null|模拟长期人景交互是一项既具挑战性又充满吸引力的任务。以往的研究并未有效地解决基于物理动画的长期人景交互生成带有详细叙述的问题。本文介绍了一种新的框架，用于规划和控制长期物理可能的人景交互。一方面，互联网上充斥着风格独特的人类运动或与场景交互的影视作品，为剧本规划提供了丰富的数据来源。另一方面，大型语言模型（LLMs）能够理解和生成逻辑故事线。这促使我们结合两者，通过基于LLM的流程从视频中提取剧本，然后利用LLMs模仿和创作新的剧本，捕捉复杂的时间序列人类行为和环境交互。通过这种方式，我们利用一种双重感知策略，在语境和空间约束下指导角色动作，实现了语言理解和场景理解。为了便于训练和评估，我们贡献了一个包含从现实世界视频中提取的多样运动序列的综合规划数据集，并使用大型语言模型对其进行扩展。我们还收集并重新标注了来自现有运动学数据集的运动片段，以使我们的策略能够学习多种技能。广泛的实验证明了我们的框架在多种任务执行中的有效性及其对各种场景的泛化能力，与现有方法相比，性能显著提升。我们的代码和数据将很快公开。|\n",
        "2411.19886": "|**2024-11-29**|**PDDLFuse: A Tool for Generating Diverse Planning Domains**|Vedant Khandelwal et.al.|[2411.19886](http://arxiv.org/abs/2411.19886)|null|各种现实世界挑战需要能够适应广泛领域的规划算法。传统上，规划域的创建高度依赖于人工实现，这限制了可用的域的规模和多样性。尽管最近的研究利用了生成式人工智能技术，如大型语言模型（LLM）进行域创建，但这些努力主要集中在将现有域从自然语言描述中翻译出来，而不是生成新的域。相比之下，域随机化的概念，在强化学习中已被证明非常有效，通过在多样化的随机新域上进行训练，提高了性能和泛化能力。受此成功启发，我们的工具PDDLFuse旨在弥合规划域定义语言（PDDL）中的这一差距。PDDLFuse被设计用来生成新的、多样化的规划域，这些域可以用于验证新的规划器或测试基础规划模型。我们已经开发出了调整域生成器参数的方法，以调节其生成的域的难度。这种适应性至关重要，因为现有的域无关规划器往往难以处理更复杂的问题。初步测试表明，PDDLFuse能够高效地创建复杂且多样化的域，这比传统的域生成方法有显著的进步，并为规划研究做出了贡献。|\n",
        "2411.19876": "|**2024-11-29**|**LUMIA: Linear probing for Unimodal and MultiModal Membership Inference Attacks leveraging internal LLM states**|Luis Ibanez-Lissen et.al.|[2411.19876](http://arxiv.org/abs/2411.19876)|null|大型语言模型（LLMs）在各类应用中越来越受欢迎，但关于成员推断（Membership Inference）的担忧也随之增长。以往的研究主要关注黑盒到灰盒模型，从而忽略了内部LLM信息的潜在益处。为了解决这个问题，我们提出使用线性探针（LPs）作为一种检测成员推断攻击（MIAs）的方法，通过检查LLM的内部激活来实现。我们的方法被称为LUMIA，它逐层应用LPs以获取模型内部运作的细粒度数据。我们在包括单模态和多模态任务在内的多个模型架构、规模和数据集上测试了这种方法。在单模态MIAs中，LUMIA在曲线下面积（AUC）上比之前的技术平均提高了15.71%。值得注意的是，LUMIA在65.33%的情况下达到了AUC>60%——相较于现有技术提高了46.80%。此外，我们的方法揭示了关键见解，例如MIAs最易检测的模型层。在多模态模型中，LPs表明视觉输入可以显著有助于检测MIAs——在85.90%的实验中达到了AUC>60%。|\n",
        "2411.19869": "|**2024-11-29**|**AIDetx: a compression-based method for identification of machine-learning generated text**|Leonardo Almeida et.al.|[2411.19869](http://arxiv.org/abs/2411.19869)|**[link](https://github.com/aidetx/aidetx)**|**本文介绍了一种名为AIDetx的新方法，该方法利用数据压缩技术检测机器生成的文本。传统的深度学习分类器通常存在计算成本高和可解释性有限的问题。为了解决这些局限性，我们提出了一种基于压缩的分类框架，该框架利用有限上下文模型（FCMs）。AIDetx为人工写作和AI生成的文本构建了不同的压缩模型，根据哪个模型达到更高的压缩率来对新输入进行分类。我们在两个基准数据集上评估了AIDetx，分别实现了超过97%和99%的F1分数，突显了其高准确性。与当前方法，如大型语言模型（LLMs）相比，AIDetx提供了一个更可解释且计算效率更高的解决方案，显著减少了训练时间和硬件需求（例如，不需要GPU）。完整的实现代码在https://github.com/AIDetx/AIDetx上公开可用。**|\n",
        "2411.19865": "|**2024-11-29**|**Reverse Thinking Makes LLMs Stronger Reasoners**|Justin Chih-Yao Chen et.al.|[2411.19865](http://arxiv.org/abs/2411.19865)|null|逆向思维在人类推理中起着至关重要的作用。人类不仅能从问题推理到解决方案，还能逆向推理，即从解决方案开始推理到问题。这种推理方式往往能提升整体推理性能，因为它使得他们的正向和逆向思维之间能够进行一致性检查。为了使大型语言模型（LLMs）能够进行逆向思维，我们引入了逆向增强思维（RevThink）框架，该框架由数据增强和学习目标组成。在RevThink中，我们通过收集来自教师模型的有序正向-逆向推理来增强数据集，包括：（1）原始问题，（2）正向推理，（3）逆向问题，和（4）逆向推理。然后，我们采用三个目标以多任务学习的方式训练一个较小的学生模型：（a）从问题中生成正向推理，（b）从问题中生成逆向问题，（c）从逆向问题中生成逆向推理。在涵盖常识、数学和逻辑推理的12个数据集上的实验表明，与学生的零样本性能相比平均提升了13.53%，与最强的知识蒸馏基线相比提升了6.84%。此外，我们的方法展示了样本效率——仅使用训练数据中10%的正确正向推理，它就能超越在10倍更多正向推理上训练的标准微调方法。RevThink还显示出对分布外持有数据集的强大泛化能力。|\n",
        "2411.19862": "|**2024-11-29**|**Cross-Domain Recommendation Meets Large Language Models**|Ajay Krishna Vajjala et.al.|[2411.19862](http://arxiv.org/abs/2411.19862)|**[link](https://github.com/ajaykv1/CDR_Meets_LLMs)**|**跨领域推荐（CDR）已成为解决单领域推荐系统面临的冷启动问题的一个有希望的解决方案。然而，现有的CDR模型依赖于复杂的神经网络架构、大量数据集和大量的计算资源，这使得它们在数据稀缺的场景或当简单性至关重要的时效果较差。在这项工作中，我们利用大型语言模型（LLM）的推理能力，并探索其在多个领域对中的CDR领域的性能。我们引入了两种针对CDR的新型提示设计，并证明当LLM被有效提示时，在评分预测和排名任务中，LLM在各种指标和领域组合上优于最先进的CDR基线。这项工作弥合了LLM和推荐系统之间的差距，展示了它们作为有效的跨领域推荐者的潜力。**|\n",
        "2412.02685": "|**2024-12-03**|**T-REG: Preference Optimization with Token-Level Reward Regularization**|Wenxuan Zhou et.al.|[2412.02685](http://arxiv.org/abs/2412.02685)|null|基于人类反馈的强化学习（RLHF）对于将大型语言模型（LLMs）与人类价值观对齐至关重要。传统上，RLHF涉及生成对查询的响应，并使用奖励模型对整个响应分配奖励。然而，由于该方法依赖于单一且稀疏的奖励，这使得模型难以识别序列中哪些部分对最终奖励贡献最大。近期的方法试图通过引入token级奖励来解决这个问题。然而，这些方法通常依赖于训练好的信用分配模型或AI标注者，这引发了关于奖励质量和可靠性的担忧。在本文中，我们提出了token级奖励正则化（T-REG），这是一种利用序列级和token级奖励进行偏好优化的新方法。利用LLMs的自我改进能力，我们的方法使用对比提示，使LLMs能够自我生成token级奖励。这些自我生成的奖励随后充当奖励正则化，引导模型更有效地分配序列级奖励到各个token。这促进了更好的token级信用分配并提高了对齐性能。在包括Alpaca Eval 2和Arena-Hard在内的指令遵循基准测试中进行的实验表明，我们的方法在性能上分别比基线方法高出3.8%和4.4%。我们将发布代码和模型在https://github.com/wzhouad/T-REG上。|\n",
        "2412.02674": "|**2024-12-03**|**Mind the Gap: Examining the Self-Improvement Capabilities of Large Language Models**|Yuda Song et.al.|[2412.02674](http://arxiv.org/abs/2412.02674)|null|自我改进是大型语言模型（LLM）预训练、后训练和测试时推理中的一个机制。我们探索了一个框架，其中模型验证其自己的输出，根据这种验证过滤或重新加权数据，并提炼过滤后的数据。尽管已经取得了一些经验上的成功，但对其根本理解仍然不足。在这项工作中，我们开始对LLM自我改进进行全面的、模块化和受控的研究。我们为自我改进提供了一个数学公式，它主要受一个量控制，我们将该量形式化为生成-验证差距。通过使用各种模型家族和任务的实验，我们发现自我改进存在一个缩放现象——生成-验证差距的变体随着模型预训练的浮点运算量单调增长。我们还考察了自我改进何时可行，一个迭代自我改进过程以及提高其性能的方法。我们的发现不仅推进了对LLM自我改进的理解，具有实际意义，而且为未来对其能力和边界的研究开辟了众多途径。|\n",
        "2412.02655": "|**2024-12-03**|**LLM-Enhanced Path Planning: Safe and Efficient Autonomous Navigation with Instructional Inputs**|Pranav Doma et.al.|[2412.02655](http://arxiv.org/abs/2412.02655)|null|基于自然语言指令引导的自主导航对于改善人机交互和实现在动态环境中的复杂操作至关重要。尽管大型语言模型（LLMs）并非天生用于规划，但它们可以通过提供指导和告知约束来显著提高规划效率，以确保安全。本文介绍了一种规划框架，该框架将LLMs与二维占用栅格图和自然语言命令集成，以提高资源受限环境中的空间推理和任务执行。通过分解高级指令和实时环境数据，该系统为拾取和放置任务生成结构化的导航计划，包括避障、目标优先级和自适应行为。该框架动态重新计算路径以应对环境变化，并符合隐含的社会规范以实现无缝的人机交互。我们的结果表明，LLMs具有设计情境感知系统以增强工业和动态环境中的导航效率和安全的潜力。|\n",
        "2412.02626": "|**2024-12-03**|**Time-Reversal Provides Unsupervised Feedback to LLMs**|Yerram Varun et.al.|[2412.02626](http://arxiv.org/abs/2412.02626)|null|大型语言模型（LLMs）通常被训练来预测时间的正向方向。然而，最近的研究表明，通过提示这些模型回顾并批评它们自己的生成内容可以产生有用的反馈。受此启发，我们探讨了LLMs是否能够被赋予反向（预测和评分）思考的能力，以提供补充正向LLMs的无监督反馈。为此，我们引入了时间反转语言模型（TRLMs），当给定响应条件时，它们可以评分和生成查询，从而在时间反向方向上有效工作。此外，为了有效地推断查询到响应的方向，我们从零开始预训练和微调了一个语言模型（TRLM-Ba），使用反向标记顺序。我们通过实验（在一个风格化的环境中进行理论证明）表明，当用于根据响应对多个正向生成进行再排名时，时间反转模型确实可以补充正向模型的预测。我们在广泛使用的AlpacaEval排行榜上获得了高达5%的改进，超过了使用自我对数困惑度评分的N-best再排名的最佳基线。我们进一步表明，TRLM评分优于给查询响应的常规正向评分，在引用生成和段落检索等应用中带来了显著收益。接下来，我们利用TRLM的生成能力来增强或为LLM的输入安全过滤器提供无监督反馈，展示了在几项针对流行的JailbreakBench排行榜上发布的攻击中，错误否定率大幅降低，而对错误肯定率的影响可以忽略不计。|\n",
        "2412.02617": "|**2024-12-03**|**Improving Dynamic Object Interactions in Text-to-Video Generation with AI Feedback**|Hiroki Furuta et.al.|[2412.02617](http://arxiv.org/abs/2412.02617)|null|大型文本到视频模型在众多下游应用中具有巨大潜力。然而，这些模型在准确描绘动态物体交互方面存在困难，往往导致动作不真实和频繁违反现实物理规律。一种受大型语言模型启发的解决方案是通过外部反馈将生成的输出与期望结果对齐。这使得模型能够自主地改进其响应，消除了大量手动数据收集的需要。在本工作中，我们研究了利用反馈来增强文本到视频模型中物体动态的方法。我们试图回答一个关键问题：哪些类型的反馈，与哪些特定的自我改进算法相结合，可以最有效地提高文本-视频对齐和现实物体交互？我们首先推导出用于文本到视频模型离线强化学习微调的统一概率目标。这种观点突出了如何在现有算法（如KL正则化和策略投影）的设计元素中，作为一个统一框架中的特定选择。然后，我们使用推导出的方法来优化一组文本-视频对齐指标（例如，CLIP分数、光流），但注意到它们往往无法与人类对生成质量的感知相一致。为了解决这一限制，我们提出利用视觉语言模型提供更细致的反馈，特别是针对视频中的物体动态。我们的实验表明，我们的方法可以有效地优化各种奖励，二元AI反馈驱动视频质量动态交互方面的最显著改进，这一点通过AI和人类评估都得到了证实。值得注意的是，当我们使用从AI反馈中导出的奖励信号时，尤其是在涉及多个物体复杂交互和物体坠落等现实描绘的情景中，我们观察到了显著的收益。|\n",
        "2412.02611": "|**2024-12-03**|**AV-Odyssey Bench: Can Your Multimodal LLMs Really Understand Audio-Visual Information?**|Kaixiong Gong et.al.|[2412.02611](http://arxiv.org/abs/2412.02611)|null|近期，多模态大型语言模型（MLLMs），如GPT-4o、Gemini 1.5 Pro和Reka Core，扩展了其功能，包括视觉和听觉模态。虽然这些模型在广泛的视听应用中表现出令人印象深刻的能力，但我们的DeafTest研究表明，MLLMs在人类认为简单的任务上往往表现不佳：1）判断两个声音中哪个更响亮，2）判断两个声音中哪个音调更高。受这些观察的启发，我们引入了AV-Odyssey Bench，这是一个综合性的视听基准，旨在评估这些MLLMs是否真正理解视听信息。该基准包含4,555个精心设计的问题，每个问题都融合了文本、视觉和听觉成分。为了成功推断答案，模型必须有效地利用视觉和听觉输入中的线索。为了确保对MLLM响应的精确和客观评估，我们将问题设计为多项选择，从而消除了人工评估或LLM辅助评估的需求。我们对一系列闭源和开源模型进行了基准测试，并总结了观察结果。通过揭示当前模型的局限性，我们旨在为未来的数据集收集和模型开发提供有用的见解。|\n",
        "2412.02605": "|**2024-12-03**|**Interpretable Company Similarity with Sparse Autoencoders**|Marco Molinari et.al.|[2412.02605](http://arxiv.org/abs/2412.02605)|null|在金融领域，确定公司相似性是一项至关重要的任务，它支撑着对冲、风险管理、投资组合多元化等多个方面。从业者通常依赖行业和产业分类来衡量相似性，例如SIC代码和GICS代码，前者由美国证券交易委员会（SEC）使用，后者在投资界得到广泛应用。将公司描述的嵌入进行聚类已被提出作为一种确定公司相似性的潜在技术，但标记嵌入的可解释性缺乏对在高风险环境下应用构成了重大障碍。稀疏自动编码器（Sparse Autoencoders，SAE）在通过分解大型语言模型（LLM）的激活为可解释特征来增强LLM的可解释性方面已显示出希望。在本文中，我们探讨了使用SAE特征来衡量公司相似性，并将它们与（1）SIC代码和（2）主要群体代码进行了基准测试。我们得出结论，SAE特征可以复制甚至超越行业分类，在量化公司基本特征方面，通过衡量月度收益的相关性（相似性的代理指标）和协整的损益（PnL）来实现。|\n",
        "2412.02602": "|**2024-12-03**|**CEGI: Measuring the trade-off between efficiency and carbon emissions for SLMs and VLMs**|Abhas Kumar et.al.|[2412.02602](http://arxiv.org/abs/2412.02602)|null|本文分析了小型语言模型（SLMs）和视觉语言模型（VLMs）的性能，并评估了模型性能与碳排放之间的权衡，涉及4项基本任务：图像描述、视觉问答（VQA）、对话摘要和文本到SQL转换。选取了属于Qwen和LLaMA架构家族的各种SLMs和VLMs，并评估了基于模型大小（参数数量、量化级别和微调参数）的变体。计算了模型变体的性能和碳排放。为了量化模型性能与碳排放之间的权衡，我们引入了一个新的指标，称为CEGI（碳效率增益指数）。这个指标表示每百万可训练参数单位百分比增益的碳排放。这个指标提供了一个标准化的度量，用于比较模型在性能改进相对于其环境成本方面的效率。实验结果表明，微调SLMs和VLMs可以达到与大语言模型（LLMs）相当的性能水平，同时产生显著较少的碳排放。我们的研究结果表明，从更大模型中获得的边际准确率增益并不能证明其碳排放的大幅增加是合理的。利用较低的位量化级别，所提出的指标进一步提高了能源效率，同时没有影响性能。这项研究突出了在高性能和环境可持续性之间取得平衡的重要性。它为选择适合环保AI开发的模型提供了一个有价值的指标。|\n",
        "2412.02594": "|**2024-12-03**|**PrefixLLM: LLM-aided Prefix Circuit Design**|Weihua Xiao et.al.|[2412.02594](http://arxiv.org/abs/2412.02594)|null|前缀电路是数字加法器的基本组件，由于它们在计算进位信号方面的效率，在数字系统中得到广泛应用。合成最小化面积和延迟的前缀电路对于提升现代计算机系统的性能至关重要。最近，大型语言模型（LLMs）在执行文本生成任务方面展现出了令人惊讶的能力。我们提出了PrefixLLM，它利用LLMs进行前缀电路的合成。PrefixLLM将前缀电路合成任务转化为一种结构化文本生成问题，称为结构化前缀电路表示（SPCR），并引入了一个迭代框架来自动准确地生成有效的SPCRs。我们进一步提出了一种设计空间探索（DSE）框架，该框架使用LLMs迭代搜索面积和延迟优化的前缀电路。与现有技术相比，PrefixLLM在相同的延迟约束下可以将面积降低3.70%。这项工作突出了LLMs在算术电路合成中的应用，这些应用可以转化为结构化文本生成。|\n",
        "2412.02592": "|**2024-12-03**|**OCR Hinders RAG: Evaluating the Cascading Impact of OCR on Retrieval-Augmented Generation**|Junyuan Zhang et.al.|[2412.02592](http://arxiv.org/abs/2412.02592)|**[link](https://github.com/opendatalab/OHR-Bench)**|**检索增强生成（RAG）通过整合外部知识来增强大型语言模型（LLMs），以减少幻觉并吸收最新信息而不需要重新训练。作为RAG的一个重要部分，外部知识库通常通过使用光学字符识别（OCR）从非结构化的PDF文档中提取结构化数据来构建。然而，由于OCR预测的不完美以及结构化数据固有的非均匀表示，知识库不可避免地包含各种OCR噪声。在本文中，我们介绍了OHRBench，这是第一个用于理解OCR对RAG系统级联影响的基准。OHRBench包括从六个真实世界RAG应用领域精心挑选的350个非结构化PDF文档，以及从文档中的多模态元素中衍生出的问答，挑战了现有用于RAG的OCR解决方案。为了更好地理解OCR对RAG系统的影响，我们确定了两种主要的OCR噪声类型：语义噪声和格式噪声，并应用扰动生成了一系列具有不同程度每种OCR噪声的结构化数据。使用OHRBench，我们首先对当前的OCR解决方案进行了全面评估，并揭示了没有一种方案能够为RAG系统构建高质量的知识库。然后，我们系统地评估了这两种噪声类型的影响，并展示了RAG系统的脆弱性。此外，我们讨论了在RAG系统中不使用OCR而采用视觉-语言模型（VLMs）的潜力。代码：https://github.com/opendatalab/OHR-Bench**|\n",
        "2412.03563": "|**2024-12-04**|**From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents**|Xinyi Mou et.al.|[2412.03563](http://arxiv.org/abs/2412.03563)|**[link](https://github.com/fudandisc/socialagent)**|传统的社会学研究通常依赖人类参与，虽然有效，但成本高昂、难以扩展，且存在伦理问题。近年来，大型语言模型（LLMs）的进步突显了它们模拟人类行为的能力，使得个体反应的复制和跨学科研究得以进行。在本文中，我们对这一领域进行了全面调查，展示了由LLMs赋能的代理推动的模拟近期进展。我们将模拟分为三类：（1）个体模拟，模仿特定个体或人口群体；（2）情景模拟，多个代理在特定情境中协作实现目标；（3）社会模拟，模拟代理社会中的互动，以反映现实世界动态的复杂性和多样性。这些模拟从详细的个体建模到大规模社会现象，呈现出一种渐进性。我们对每种模拟类型进行了详细讨论，包括模拟的架构或关键组件、目标或情景的分类以及评估方法。之后，我们总结了常用的数据集和基准。最后，我们讨论了这三种类型模拟的趋势。相关资源的存储库位于{\\url{https://github.com/FudanDISC/SocialAgent}}。|\n",
        "2412.03551": "|**2024-12-04**|**SPICE: Smart Projection Interface for Cooking Enhancement**|Vera Prohaska et.al.|[2412.03551](http://arxiv.org/abs/2412.03551)|null|可触摸用户界面（TUI）用于人机交互（HCI），旨在向用户提供数字信息的物理表示，以克服基于屏幕界面的局限性。尽管文献中存在许多引人注目的TUI演示，但针对日常双手任务和过程，如烹饪的TUI研究却很少。为了填补这一空白，我们提出了SPICE（智能投影界面，用于烹饪增强）。SPICE在厨房环境中研究TUI，旨在将食谱遵循体验从简单的基于文本转变为直观互动。SPICE包括跟踪系统、基于代理的软件和视觉大型语言模型，以创建和解释一个将食谱信息直接投影到烹饪表面的厨房环境。我们对SPICE和基于文本的食谱遵循进行了30名参与者的比较可用性研究，评估了任务难度、总时长和效率，以及用户信心和味觉感知。结果表明，SPICE使参与者能够在更短的时间内完成食谱，同时提高了自我报告的效率、信心和味觉。尽管如此，参与者报告说总体难度没有变化，这是未来研究的方向。总的来说，SPICE项目展示了使用TUI改善日常活动的潜力，为HCI和新型计算界面的未来研究铺平了道路。|\n",
        "2412.03537": "|**2024-12-04**|**Evaluating Gender Bias Transfer between Pre-trained and Prompt-Adapted Language Models**|Natalie Mackraz et.al.|[2412.03537](http://arxiv.org/abs/2412.03537)|null|大型语言模型（LLMs）正越来越多地被调整为具有特定任务性，以便在现实世界的决策系统中部署。先前的一些研究通过研究微调适配策略对模型公平性的影响，来调查偏见迁移假说（BTH），发现预训练的掩码语言模型在微调适配时的公平性影响有限。在本工作中，我们扩展了对BTH的研究，将其应用于提示适应下的因果模型，因为提示是一种易于访问且计算高效的部署模型的方法。与先前的研究不同，我们通过一个代词共指消解任务，建立了一个事实：预训练的Mistral、Falcon和Llama模型中的内在偏见与在相同模型零样本和少样本提示时的偏见高度相关（相关系数rho >= 0.94）。此外，我们发现，即使LLMs被特别提示以展示公平或偏见行为（rho >= 0.92），以及少样本长度和刻板化组成发生变化（rho >= 0.97），偏见迁移仍然高度相关。我们的发现强调了确保预训练LLMs公平性的重要性，特别是在它们后来通过提示适配执行下游任务时。|\n",
        "2412.03531": "|**2024-12-04**|**A Review on Scientific Knowledge Extraction using Large Language Models in Biomedical Sciences**|Gabriel Lino Garcia et.al.|[2412.03531](http://arxiv.org/abs/2412.03531)|null|这篇论文回顾了大型语言模型（LLMs）在生物医学领域的最新应用，探讨了它们在自动化复杂任务，如从生物医学文献数据库中提取证据和数据方面的有效性。虽然LLMs展现出巨大的潜力，但仍然存在重大挑战，包括幻觉、上下文理解和跨多种医疗任务泛化能力的问题。我们指出了当前研究文献中的关键差距，尤其是需要统一的基准来标准化评估并确保实际应用中的可靠性。此外，我们提出了未来研究方向，强调将检索增强生成（RAG）等最先进技术集成到LLMs中，以提高证据综合性能。通过解决这些挑战并利用LLMs的优势，我们旨在提高获取医学文献的途径并促进医疗保健领域的重大发现。|\n",
        "2412.03527": "|**2024-12-04**|**FANAL -- Financial Activity News Alerting Language Modeling Framework**|Urjitkumar Patel et.al.|[2412.03527](http://arxiv.org/abs/2412.03527)|null|在快速发展的金融领域，准确及时地解读市场新闻对于需要应对不可预测事件的相关利益方至关重要。本文介绍了FANAL（金融活动新闻警报语言建模框架），这是一个专门为实时金融事件检测和分析而设计的基于BERT的框架，将新闻分为十二个不同的金融类别。FANAL利用通过XGBoost处理的银标签数据进行训练，并采用先进的微调技术，同时结合了ORBERT（概率比BERT），这是一种新的BERT变体，通过ORPO（概率比偏好优化）进行微调，以实现更高级别的类别概率校准和与金融事件相关性的对齐。我们评估了FANAL的性能，并将其与领先的顶级大型语言模型进行了比较，包括GPT-4o、Llama-3.1 8B和Phi-3，证明了其卓越的准确性和成本效益。这一框架为金融智能和响应性设定了新的标准，在性能和成本上均显著超越现有模型。|\n",
        "2412.03516": "|**2024-12-04**|**You're (Not) My Type -- Can LLMs Generate Feedback of Specific Types for Introductory Programming Tasks?**|Dominic Lohr et.al.|[2412.03516](http://arxiv.org/abs/2412.03516)|null|背景：反馈作为学习中最具影响力的因素之一，一直是众多研究的热点。它在教育技术系统的发展中起着关键作用，并传统上基于由专家及其经验定义的决定性反馈。然而，随着生成式AI，尤其是大型语言模型（LLMs）的兴起，我们预计作为学习系统一部分的反馈将发生转变，尤其是在编程的背景下。过去，为编程学习者自动生成反馈具有挑战性。LLMs可能创造新的可能性，提供比以往任何时候都更丰富、更个性化的反馈。  目标：本文旨在使用LLMs为入门级编程任务生成特定类型的反馈。我们重新审视现有的反馈分类法，以捕捉生成的反馈的具体性，例如随机性、不确定性和变化程度。  方法：我们针对真实的学生的程序，迭代设计用于生成特定类型反馈的提示（作为现有反馈分类法的一部分）。然后，我们评估生成的输出，并确定其反映特定反馈类型的程度。  结果和结论：本研究加深了对不同反馈维度和特性的理解。结果对未来的反馈研究有影响，例如关于反馈效果和学习者信息需求的研究。此外，本研究还为开发新的工具和学习系统提供了基础，包括由AI生成的反馈，这些系统面向初学者程序员。|\n",
        "2412.03467": "|**2024-12-04**|**Training-Free Mitigation of Language Reasoning Degradation After Multimodal Instruction Tuning**|Neale Ratzlaff et.al.|[2412.03467](http://arxiv.org/abs/2412.03467)|null|多模态模型通常将强大的大型语言模型（LLM）与视觉编码器相结合，然后通过指令微调在多模态数据上训练。虽然这个过程使LLM适应了多模态环境，但尚不清楚这种适应是否会损害它们原始的语言推理能力。在本工作中，我们探讨了多模态指令微调对语言推理性能的影响。我们关注的是LLaVA，这是一个领先的融合了Vicuna或Mistral等LLM与CLIP视觉编码器的多模态框架。我们将原始LLM与它们的跨模态适应版本在八个语言推理任务中的表现进行了比较。我们的实验产生了几个关键见解。首先，多模态学习对Vicuna和Mistral的影响不同：我们在Mistral上观察到语言推理的下降，但在大多数任务上Vicuna有所改进。其次，尽管多模态指令学习在数学推理任务（例如GSM8K）上始终会降低性能，但它增强了常识推理任务（例如CommonsenseQA）的性能。最后，我们证明了无训练模型合并技术可以有效地减轻在多模态适应的Mistral中观察到的语言推理下降，甚至可以提高视觉任务的表现。|\n",
        "2412.03446": "|**2024-12-04**|**From Words to Workflows: Automating Business Processes**|Laura Minkova et.al.|[2412.03446](http://arxiv.org/abs/2412.03446)|null|随着企业越来越依赖自动化以简化运营，机器人流程自动化（RPA）的局限性逐渐显现，尤其是其依赖专家知识和无法处理复杂决策任务的问题。近年来，人工智能（AI）的进步，特别是生成式AI（GenAI）和大型语言模型（LLMs），为智能自动化（IA）铺平了道路，IA通过集成认知能力来克服RPA的不足。本文介绍了一种名为Text2Workflow的新方法，它可以从自然语言用户请求中自动生成工作流程。与传统的自动化方法不同，Text2Workflow提供了一种通用的解决方案，用于自动化任何业务流程，将用户输入转换为表示为JavaScript对象表示法（JSON）格式的可执行步骤序列。利用LLMs的决策和指令遵循能力，该方法提供了一种可扩展、可适应的框架，使用户能够以最小的手动干预可视化和执行工作流程。这项研究概述了Text2Workflow方法及其在自动化复杂业务流程方面的更广泛影响。|\n",
        "2412.03398": "|**2024-12-04**|**RedStone: Curating General, Code, Math, and QA Data for Large Language Models**|Yaoyao Chang et.al.|[2412.03398](http://arxiv.org/abs/2412.03398)|null|在高质量、精心挑选的数据集上预训练大型语言模型（LLMs）已被广泛认为对于提高其性能和泛化能力至关重要。本研究探讨了Common Crawl作为预训练LLMs的全面且灵活资源的未被充分利用的潜力，既针对通用语言理解也针对专业领域知识。我们引入了RedStone，这是一个创新且可扩展的管道，旨在从Common Crawl中提取和处理数据，便于创建广泛多样的预训练数据集。与传统的数据集不同，后者通常需要昂贵的编辑和特定领域的专业知识，RedStone利用Common Crawl的广度，提供针对广泛领域的定制化数据集。在本工作中，我们通过构建涵盖多个领域的预训练数据集来展示其能力，包括通用语言理解、代码、数学和问答任务。RedStone的灵活性允许它轻松适应其他专业领域，显著降低了创建有价值特定领域数据集的门槛。我们的发现表明，通过像RedStone这样的有效管道，Common Crawl可以作为丰富的、可再生的预训练数据源，为LLMs在领域适应和知识发现方面开辟新的途径。这项工作也强调了创新数据采集策略的重要性，并突出了网络规模数据在LLMs持续进化中的强大资源作用。RedStone代码和数据样本将公开提供在\\url{https://aka.ms/redstone}。|\n",
        "2412.03359": "|**2024-12-04**|**WiS Platform: Enhancing Evaluation of LLM-Based Multi-Agent Systems Through Game-Based Analysis**|Chengwei Hu et.al.|[2412.03359](http://arxiv.org/abs/2412.03359)|null|近期，基于大型语言模型（LLMs）的自主多智能体系统（MAS）的进步，增强了应用场景并提升了LLMs处理复杂任务的能力。尽管现有研究显示出有效性，但仍然明显存在评估、分析和复现LLM-based MAS的困难。在本文中，为了促进LLM-based MAS的研究，我们介绍了一个基于“谁是间谍？”（WiS）游戏的开放、可扩展和实时更新的平台，用于访问和分析基于LLMs的MAS。我们的平台具有三个主要优点：（1）支持Hugging Face上可用的模型的统一模型评估界面；（2）实时更新的排行榜用于模型评估；（3）全面评估包括游戏胜率、攻击、防御策略和LLMs的推理。为了严格测试WiS，我们进行了涵盖各种开源和闭源LLMs的广泛实验，我们发现不同的代理在游戏中表现出独特且引人入胜的行为。实验结果证明了我们的平台在评估LLM-based MAS中的有效性和效率。我们的平台及其文档可在\\url{https://whoisspy.ai/}公开访问。|\n",
        "2412.04449": "|**2024-12-05**|**p-MoD: Building Mixture-of-Depths MLLMs via Progressive Ratio Decay**|Jun Zhang et.al.|[2412.04449](http://arxiv.org/abs/2412.04449)|**[link](https://github.com/mcg-nju/p-mod)**|**尽管多模态大型语言模型（MLLMs）在众多任务中表现出色，但其巨大的训练和推理成本阻碍了其发展。大部分计算量来自于被Transformer解码器处理的视觉标记的庞大数量。在本文中，我们提出通过利用混合深度（MoD）机制来构建高效的MLLMs，其中每个Transformer解码器层选择必要的视觉标记进行处理，同时跳过冗余的标记。然而，将MoD集成到MLLMs中并非易事。为了解决训练和推理稳定性以及有限训练数据带来的挑战，我们对MoD模块进行了两项创新设计：tanh门控权重归一化（TanhNorm）和对称标记重新加权（STRing）。此外，我们观察到视觉标记在深层中的冗余性更高，因此设计了一种渐进比率衰减（PRD）策略，该策略通过偏移余弦调度逐步减少每层的标记保留率。这一关键设计充分发挥了MoD的潜力，显著提升了我们模型的效率和性能。为了验证我们方法的有效性，我们在14个基准测试中，对两个基线模型进行了广泛的实验。我们的模型p-MoD在推理时仅占用了55.6%的TFLOPs和53.8%的KV缓存存储，以及训练时的77.7%的GPU小时，其性能与基线模型相当，甚至在某些情况下超过了基线模型。**|\n",
        "2412.04447": "|**2024-12-05**|**EgoPlan-Bench2: A Benchmark for Multimodal Large Language Model Planning in Real-World Scenarios**|Lu Qiu et.al.|[2412.04447](http://arxiv.org/abs/2412.04447)|null|多模态大型语言模型的兴起，借助大型语言模型的力量，最近展示了卓越的多模态理解和推理能力，预示着人工通用智能新时代的到来。然而，实现通用人工智能不仅需要理解和推理能力，还需要在多样场景中有效规划的能力，这涉及到基于复杂环境做出合理决策以解决现实问题。尽管其重要性不言而喻，但当前多模态大型语言模型在不同场景下的规划能力仍处于探索阶段。在本文中，我们介绍了EgoPlan-Bench2，这是一个严格且全面的基准，旨在评估多模态大型语言模型在广泛现实场景中的规划能力。EgoPlan-Bench2涵盖了涵盖4个主要领域和24个详细场景的日常任务，与人类日常生活紧密相关。EgoPlan-Bench2是通过半自动流程构建的，利用以自我为中心的视频，并辅以人工验证。基于第一人称视角，它反映了人类在日常生活中的问题解决方式。我们评估了21个竞争性的多模态大型语言模型，并深入分析了它们的局限性，揭示它们在现实世界规划中面临重大挑战。为了进一步提高当前多模态大型语言模型的规划能力，我们提出了一种无需训练的方法，通过研究复杂规划中各种多模态提示的有效性，使用多模态思维链（CoT）提示。我们的方法在不额外训练的情况下，将GPT-4V在EgoPlan-Bench2上的性能提高了10.24。我们的工作不仅揭示了当前多模态大型语言模型在规划方面的局限性，还为这一关键领域的未来改进提供了见解。我们已经将数据和代码发布在https://qiulu66.github.io/egoplanbench2/。|\n",
        "2412.04445": "|**2024-12-05**|**Moto: Latent Motion Token as the Bridging Language for Robot Manipulation**|Yi Chen et.al.|[2412.04445](http://arxiv.org/abs/2412.04445)|null|最近，在大量语料库上预训练的大型语言模型在多种自然语言处理任务中取得了显著的成功，且仅需少量微调。这一成功为机器人学带来了新的希望，因为机器人学长期以来一直受限于高成本的动作标签数据。我们提出问题：鉴于大量包含互动相关知识的视频数据作为丰富的“语料库”可用，是否可以有效地将类似的生成式预训练方法应用于增强机器人学习？关键挑战是识别一个有效的自回归预训练表示，以促进机器人操作任务。受人类通过观察动态环境学习新技能的方式的启发，我们认为有效的机器人学习应强调与运动相关的知识，这些知识与低级动作紧密相关，并且与硬件无关，便于将学习到的运动转移到实际机器人动作中。为此，我们引入了Moto，它通过潜在运动标记器将视频内容转换为潜在运动标记序列，以无监督的方式从视频中学习运动的“桥梁”语言。我们通过运动标记自回归预训练Moto-GPT，使其能够捕捉多样的视觉运动知识。预训练后，Moto-GPT展示了产生语义可解释的运动标记、预测合理的运动轨迹以及通过输出似然性评估轨迹合理性等有希望的能力。为了将学习到的运动先验转移到真实机器人动作中，我们实施了一种协同微调策略，无缝地将潜在运动标记预测和真实机器人控制连接起来。大量实验表明，经过微调的Moto-GPT在机器人操作基准测试中表现出卓越的鲁棒性和效率，凸显了它从视频数据到下游视觉操作任务中知识转移的有效性。|\n",
        "2412.04432": "|**2024-12-05**|**Divot: Diffusion Powers Video Tokenizer for Comprehension and Generation**|Yuying Ge et.al.|[2412.04432](http://arxiv.org/abs/2412.04432)|**[link](https://github.com/tencentarc/divot)**|**近年来，在大型语言模型（LLMs）中统一图像理解和生成引起了极大的兴趣。这种不断增长的兴趣促使我们探索将这种统一扩展到视频中。核心挑战在于开发一个通用的视频分词器，它能够捕捉视频的空间特征和时序动态，以获得适合LLMs的表示，并且这些表示可以被进一步解码为逼真的视频片段，从而实现视频生成。在这项工作中，我们介绍了Divot，一种基于扩散的视频分词器，它利用扩散过程进行自监督视频表示学习。我们认为，如果一个视频扩散模型能够通过将视频分词器的特征作为条件来有效地去噪视频片段，那么分词器已经成功地捕捉了鲁棒的空间和时序信息。此外，视频扩散模型本质上充当了解码器，将视频从其表示中解码出来。在Divot分词器的基础上，我们通过视频到文本的自回归和文本到视频的生成，使用高斯混合模型来建模连续值的Divot特征分布，提出了Divot-Vicuna。实验结果表明，我们的基于扩散的视频分词器，当与预训练的LLM集成时，在各种视频理解和生成基准测试中实现了有竞争力的性能。经过指令调整的Divot-Vicuna在视频叙事方面也表现出色，能够生成交错的故事和相应的视频。**|\n",
        "2412.04429": "|**2024-12-05**|**Grounding Descriptions in Images informs Zero-Shot Visual Recognition**|Shaunak Halbe et.al.|[2412.04429](http://arxiv.org/abs/2412.04429)|**[link](https://github.com/shaunak27/grain-clip)**|**视觉语言模型（VLMs）如CLIP因其能够在开放词汇概念上执行零样本视觉识别而备受青睐。这是通过选择与查询图像文本表示最相似的物体类别来实现的。尽管在某些领域取得了成功，但这种方法在识别细粒度实体以及泛化到训练分布未捕获的未见概念方面存在困难。近期的工作试图通过在测试时整合类别描述来减轻这些挑战，尽管取得了有限的改进。我们将这些有限的收益归因于图像和描述表示之间的基本不匹配，这种不匹配根植于CLIP的预训练结构。在这篇论文中，我们提出了GRAIN，这是一种新的预训练策略，旨在同时在对细粒度和粗粒度级别上对齐表示。我们的方法学会联合地将文本描述定位到图像区域，并将总体标题与全局图像表示对齐。为了推动这种预训练，我们利用冻结的多模态大型语言模型（MLLMs）来生成大规模合成注释。我们在11个不同的图像分类数据集上展示了我们模型相较于现有最先进方法的零样本性能提升。此外，我们引入了Products-2023，这是一个新整理的、手动标记的数据集，包含新颖的概念，并通过在该数据集上进行基准测试展示了我们模型识别这些概念的能力。我们模型在其他下游任务（如检索）上取得的显著改进进一步突显了我们方法学习的表示的高质量。代码可在https://github.com/shaunak27/grain-clip上获取。**|\n",
        "2412.04424": "|**2024-12-05**|**Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion**|Jiuhai Chen et.al.|[2412.04424](http://arxiv.org/abs/2412.04424)|**[link](https://github.com/jiuhaichen/florence-vl)**|**我们介绍了一组新的多模态大型语言模型（MLLMs），即Florence-VL，它由Florence-2生成视觉基础模型产生，具有丰富的视觉表示。与广泛使用的由对比学习训练的CLIP风格视觉Transformer不同，Florence-2能够捕捉不同层次和方面的视觉特征，这使得它们更加灵活，可以适应各种下游任务。我们提出了一种新颖的特征融合架构和一种创新的训练方案，有效地将Florence-2的视觉特征整合到预训练的LLM（如Phi 3.5和LLama 3）中。特别是，我们提出了“深度-呼吸融合（DBFusion）”来融合从不同深度和多个提示中提取的视觉特征。我们的模型训练包括整个模型的端到端预训练，随后是在精心设计的包含高质量图像标题和指令调整对的多样化开源数据集上对投影层和LLM进行微调。我们对Florence-VL的视觉特征的定量分析和可视化表明，它在视觉-语言对齐方面优于流行的视觉编码器，其中丰富的深度和呼吸发挥了重要作用。Florence-VL在涵盖一般视觉问答（VQA）、感知、幻觉、OCR、图表、知识密集型理解等多种多模态和视觉中心基准测试中，相对于现有的最先进MLLMs实现了显著的改进。为了促进未来的研究，我们的模型和完整的训练方案已经开源。https://github.com/JiuhaiChen/Florence-VL**|\n",
        "2412.04415": "|**2024-12-05**|**Targeting the Core: A Simple and Effective Method to Attack RAG-based Agents via Direct LLM Manipulation**|Xuying Li et.al.|[2412.04415](http://arxiv.org/abs/2412.04415)|null|人工智能代理，由大型语言模型（LLMs）驱动，通过实现无缝、自然和情境感知的通信，已经改变了人机交互。虽然这些进步提供了巨大的实用性，但它们也继承了并放大了固有的安全风险，如偏见、公平性、幻觉、隐私侵犯和缺乏透明度。本文调查了一个关键漏洞：针对AI代理中LLM核心的对抗性攻击。具体而言，我们测试了一个假设，即一个欺骗性的简单对抗性前缀，例如“忽略文档”，可以通过绕过其情境保护措施，迫使LLMs生成危险或不希望的结果。通过实验，我们证明了高攻击成功率（ASR），揭示了现有LLM防御的脆弱性。这些发现强调了迫切需要针对LLM层面以及更广泛的基于代理的架构，采取稳健的多层安全措施来减轻漏洞。|\n",
        "2412.04342": "|**2024-12-05**|**Retrieval-Augmented Machine Translation with Unstructured Knowledge**|Jiaan Wang et.al.|[2412.04342](http://arxiv.org/abs/2412.04342)|**[link](https://github.com/krystalan/RAGtrans)**|**检索增强生成（RAG）通过引入额外信息来提升大型语言模型（LLMs）。在机器翻译（MT）领域，以往的研究通常从配对MT语料库中检索上下文示例，或从知识图中检索特定领域的知识，以增强模型的MT能力。然而，大量的世界知识组织在非结构化文档中，并且可能在不同语言之间没有完全配对。在本文中，我们研究了使用非结构化文档的检索增强MT。具体来说，我们构建了RAGtrans，这是第一个用于训练和评估LLMs检索增强MT能力的基准。RAGtrans包含了通过GPT-4o和人工翻译收集的79K MT样本。此外，还提供了不同语言的文档，为这些样本提供知识。基于RAGtrans，我们进一步提出了一种多任务训练方法，教导LLMs如何在翻译过程中使用多语言文档中的信息。该方法利用现有的多语言语料库创建辅助训练目标，无需额外的标注需求。大量实验表明，该方法将LLMs的BLEU得分提高了1.58-3.09，COMET得分提高了1.00-2.03。**|\n",
        "2412.04332": "|**2024-12-05**|**Liquid: Language Models are Scalable Multi-modal Generators**|Junfeng Wu et.al.|[2412.04332](http://arxiv.org/abs/2412.04332)|null|我们提出了Liquid，一种将视觉理解与生成无缝集成的自回归生成范式。Liquid通过将图像分词成离散代码，并在共享的特征空间中学习这些代码嵌入和文本标记，从而在视觉和语言之间实现整合。与之前的跨模态大型语言模型（MLLM）不同，Liquid使用单个大型语言模型（LLM）来实现这种整合，消除了使用外部预训练的视觉嵌入（如CLIP）的需求。Liquid首次揭示了一种缩放定律，即随着模型规模的增加，统一训练视觉和语言任务所带来的性能下降不可避免地减小。此外，统一的标记空间使得视觉生成和理解任务可以相互增强，有效地消除了早期模型中常见的干扰。我们表明，现有的LLM可以作为Liquid的强大基础，节省100倍的训练成本，同时在多模态能力上优于Chameleon，并保持与主流LLM（如LLAMA2）相当的语言性能。Liquid还优于SD v2.1和SD-XL（在MJHQ-30K上的FID为5.47），在视觉-语言和纯文本任务上都表现出色。这项工作证明了LLAMA3.2和GEMMA2等LLM是强大的多模态生成器，为增强视觉-语言理解和生成提供了可扩展的解决方案。代码和模型将发布。|\n",
        "2412.04318": "|**2024-12-05**|**The Hyperfitting Phenomenon: Sharpening and Stabilizing LLMs for Open-Ended Text Generation**|Fredrik Carlsson et.al.|[2412.04318](http://arxiv.org/abs/2412.04318)|null|本文介绍了在非常小的数据集上对过拟合预训练大型语言模型（LLMs）的出人意料的泛化结果。在开放式文本生成的背景下，有记录表明LLMs倾向于生成重复和乏味的序列，这种现象在使用贪婪解码生成时尤为明显。即使是最先进的、包含数十亿参数的LLMs，它们在大型数据集上通过下一标记预测进行训练，这一问题依然存在。我们发现，通过进一步微调这些模型，使其在少量样本集上达到几乎为零的训练损失——我们称之为超拟合——可以极大地增强其长序列生成能力。使用这些超拟合模型进行贪婪解码，甚至在多样性和人类偏好方面都优于长序列的Top-P采样。这一现象适用于各种大小、不同领域的LLMs，甚至包括自回归图像生成。我们进一步发现，这一现象与Grokking和双重下降现象有显著不同。令人惊讶的是，我们的实验表明，超拟合模型很少陷入它们训练过的重复序列，甚至明确阻止这些序列也会产生高质量的输出。所有超拟合模型都产生极低熵的预测，通常将几乎全部概率分配给单个标记。|\n",
        "2412.05271": "|**2024-12-06**|**Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling**|Zhe Chen et.al.|[2412.05271](http://arxiv.org/abs/2412.05271)|null|我们推出了InternVL 2.5，这是一个基于InternVL 2.0的高级多模态大型语言模型（MLLM）系列，保持了其核心模型架构，同时在训练和测试策略以及数据质量方面引入了显著的提升。在这项工作中，我们深入探讨了模型规模与性能之间的关系，系统地研究了视觉编码器、语言模型、数据集规模和测试时配置的性能趋势。通过在包括跨学科推理、文档理解、多图像/视频理解、现实世界理解、多模态幻觉检测、视觉定位、多语言能力和纯语言处理等广泛基准上的广泛评估，InternVL 2.5展现出具有竞争力的性能，与GPT-4o和Claude-3.5-Sonnet等领先的商业模型相媲美。值得注意的是，我们的模型是第一个在MMMU基准测试中超过70%的开源MLLM，通过思维链（CoT）推理实现了3.7分的提升，并展示了强大的测试时缩放潜力。我们希望这个模型通过设定开发和应用多模态AI系统的新标准，为开源社区做出贡献。HuggingFace演示请见https://huggingface.co/spaces/OpenGVLab/InternVL|\n",
        "2412.05270": "|**2024-12-06**|**APOLLO: SGD-like Memory, AdamW-level Performance**|Hanqing Zhu et.al.|[2412.05270](http://arxiv.org/abs/2412.05270)|null|大型语言模型（LLMs）在训练过程中对内存的消耗非常严重，尤其是使用流行的AdamW优化器时。这种内存负担迫使人们使用更多或更高端的GPU，或者减小批处理大小，从而限制了训练的可扩展性和吞吐量。为了解决这个问题，已经提出了各种内存高效的优化器来减少优化器的内存使用。然而，它们面临着一些关键的挑战：（i）依赖于昂贵的奇异值分解（SVD）操作；（ii）与AdamW相比，性能上有显著的权衡；（iii）仍然有相当大的优化器内存开销以维持竞争优势。  在这项工作中，我们发现AdamW的学习率自适应规则可以作为结构化学习率更新有效地粗化。基于这一洞察，我们提出了近似梯度缩放用于内存高效LLM优化（APOLLO），它使用基于纯随机投影的辅助低秩优化器状态来近似学习率缩放。这种结构化学习率更新规则使得APOLLO对进一步减少内存具有高度容忍性，同时在预训练性能上与AdamW相当。即使是它的秩-1变体APOLLO-Mini，在具有与SGD相当内存成本的条件下，也比AdamW实现了更优的预训练性能。  大量实验表明，APOLLO系列的性能与AdamW相当或更好，同时通过几乎消除AdamW的优化状态，实现了更大的内存节省。这些节省带来了显著的系统级好处：（1）提高了吞吐量：在8xA100-80GB的配置上，通过支持4倍更大的批处理大小，比AdamW实现了3倍的吞吐量。（2）提高了模型的可扩展性：在A100-80GB GPU上使用原始的分布式数据并行（DDP）预训练LLaMA-13B，而不进行系统级优化。（3）低端GPU友好的预训练：使用权重量化，在单个GPU上预训练LLaMA-7B，内存使用量少于12GB。|\n",
        "2412.05243": "|**2024-12-06**|**CompCap: Improving Multimodal Large Language Models with Composite Captions**|Xiaohui Chen et.al.|[2412.05243](http://arxiv.org/abs/2412.05243)|null|多模态大型语言模型（MLLMs）在理解复合图像方面的能力如何？复合图像（CIs）是通过合并多个视觉元素（如图表、海报或截图）合成的合成视觉，而不是通过相机直接捕捉的。虽然CIs在现实世界应用中很普遍，但最近MLLM的发展主要集中于解读自然图像（NIs）。我们的研究揭示，当前的MLLM在准确理解CIs方面面临着重大挑战，常常难以从这些图像中提取信息或进行复杂推理。我们发现，现有的CIs训练数据大多格式化为问答任务（例如，在ChartQA和ScienceQA等数据集中），而高质量的图像-描述数据集，对于稳健的视觉-语言对齐至关重要，却只有自然图像（NIs）才有。为了弥合这一差距，我们引入了复合描述（CompCap），这是一个灵活的框架，利用大型语言模型（LLMs）和自动化工具来合成准确且详细的复合图像。使用CompCap，我们编纂了CompCap-118K数据集，包含118K个图像-描述对，涵盖六种复合图像类型。我们通过监督微调三种规模的MLLMs（xGen-MM-inst.-4B和LLaVA-NeXT-Vicuna-7B/13B）来验证CompCap-118K的有效性。实证结果表明，CompCap-118K显著提升了MLLMs对复合图像的理解能力，分别在11个基准测试中实现了1.7%、2.0%和2.9%的平均提升。|\n",
        "2412.05237": "|**2024-12-06**|**MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale**|Jarvis Guo et.al.|[2412.05237](http://arxiv.org/abs/2412.05237)|null|开源的多模态大型语言模型（MLLMs）在多模态任务中展现出巨大的潜力。然而，它们的推理能力仍然受到现有指令微调数据集的限制，这些数据集主要来自VQA、AI2D和ChartQA等学术数据集，这些数据集针对的是简单的任务，并且只提供短语级别的答案，没有任何中间推理过程。为了解决这些挑战，我们提出了一种可扩展且成本效益高的方法来构建一个包含丰富中间推理过程的、大规模多模态指令微调数据集。我们仅使用开源模型，创建了一个包含1200万个指令-响应对的数据库，涵盖了多样化的、推理密集型任务，具有详细和可靠的推理过程。实验表明，在这样一个数据集上训练MLLMs可以显著提高推理能力，在MathVerse (+8.1%)、MMMU-Pro (+7%)和MuirBench (+13.3%)等基准测试中实现了最先进的性能。此外，该模型在非推理型基准测试上也表现出显著的提升，最高可达4%。消融实验进一步突出了数据集构建过程中关键组件，如重写和自我过滤的重要性。|\n",
        "2412.05225": "|**2024-12-06**|**BEExformer: A Fast Inferencing Transformer Architecture via Binarization with Multiple Early Exits**|Wazib Ansar et.al.|[2412.05225](http://arxiv.org/abs/2412.05225)|null|大型语言模型（LLMs）基于Transformer在各种应用中取得了尖端成果。然而，它们的巨大规模和处理需求使得在资源受限的设备上部署极为困难。在各种效率考虑中，模型二值化和早期退出（EE）是常见的有效解决方案。然而，二值化可能会由于降低精度而影响梯度估计和参数更新，从而导致性能损失。此外，目前的早期退出机制仍处于研究的初级阶段。为了改善这些问题，我们提出了二值化早期退出Transformer（BEExformer），这是第一个将早期退出与二值化结合用于文本推理的选区学习Transformer架构。它通过到冲激函数的微分二阶近似来改进二值化过程。这使得可以计算关于权重符号和幅度的梯度。与基于绝对阈值的EE不同，所提出的EE机制依赖于中间Transformer块中软路由损失估计的熵的分数减少。虽然二值化使模型大小减少了18.44倍，但早期退出在推理过程中将FLOPs减少了54.85%，甚至通过解决深层网络固有的“过度思考”问题，提高了5.98%的准确率。此外，所提出的BEExformer通过不需要从全精度LLM中进行知识蒸馏来简化训练。在GLUE数据集上的广泛评估与SOTA工作的比较展示了其帕累托最优的性能-效率权衡。|\n",
        "2412.05223": "|**2024-12-06**|**100% Hallucination Elimination Using Acurai**|Michael C. Wood et.al.|[2412.05223](http://arxiv.org/abs/2412.05223)|null|大型语言模型（LLMs）中的幻觉问题仍然是人工智能在企业和其他高风险应用中应用的一个关键障碍。尽管检索增强生成（RAG）系统取得了进展，但当前最先进的方法在生成忠实且事实正确的输出时，即使在提供相关和准确的情况下，也未能超过80%的准确率。在这项工作中，我们引入了Acurai，这是一种新颖的系统方法，通过在输入之前重新格式化查询和上下文数据，在LLMs中实现了100%无幻觉的响应。利用对LLMs内部表示的深入了解、名词短语的主导地位的重要性以及离散功能单元（DFUs）的作用，Acurai确保输入上下文和生成输出之间的一致性。我们使用RAGTruth语料库验证了这种方法，证明了它能够消除GPT-4和GPT-3.5 Turbo的100%幻觉。Acurai为实现一致、准确和忠实的AI响应设定了新的标准，标志着可信AI系统发展的重大进步。|\n",
        "2412.05210": "|**2024-12-06**|**Evaluating and Aligning CodeLLMs on Human Preference**|Jian Yang et.al.|[2412.05210](http://arxiv.org/abs/2412.05210)|null|代码大型语言模型（codeLLMs）在代码生成方面取得了显著进展。大多数之前的与代码相关的基准测试，包括各种编程练习和相应的测试用例，被用作评估codeLLMs性能和能力的共同标准。然而，当前codeLLMs主要关注合成正确的代码片段，忽略了与人类偏好的对齐，其中查询应从实际应用场景中采样，而模型生成的响应应满足人类偏好。为了弥合模型生成响应与人类偏好之间的差距，我们提出了一个严格的人类编纂基准测试CodeArena，以模拟现实世界编程任务的复杂性和多样性，其中包含从用户查询中精心挑选的397个高质量样本，涵盖了40个类别和44种编程语言。此外，我们提出了一个多样化的合成指令语料库SynCode-Instruct（近20B个标记），通过扩展网站上的指令来验证大规模合成指令微调的有效性，其中Qwen2.5-SynCoder完全在合成指令数据上训练，可以达到开源codeLLMs的顶尖性能。结果表明，在基于执行的基准测试和CodeArena之间存在性能差异。我们对40多个LLMs在CodeArena上的系统实验揭示了开源SOTA代码LLMs（例如Qwen2.5-Coder）与专有LLMs（例如，OpenAI o1）之间存在显著的性能差距，突显了与人类偏好对齐的重要性。[footnote：https://codearenaeval.github.io/ ]|\n",
        "2412.05208": "|**2024-12-06**|**A Survey of Large Language Model-Based Generative AI for Text-to-SQL: Benchmarks, Applications, Use Cases, and Challenges**|Aditi Singh et.al.|[2412.05208](http://arxiv.org/abs/2412.05208)|null|文本到SQL系统通过将自然语言查询翻译为结构化查询语言（SQL），促进了与数据库的顺畅交互，弥合了非技术用户与复杂数据库管理系统之间的差距。本综述全面概述了AI驱动的文本到SQL系统的演变，突出了其基础组件、大型语言模型（LLM）架构的进步以及Spider、WikiSQL和CoSQL等数据集在推动进展中的关键作用。我们探讨了文本到SQL在医疗保健、教育和金融等领域的应用，强调了它们在提高数据可访问性方面的变革潜力。此外，我们分析了持续存在的挑战，包括领域泛化、查询优化、支持多轮对话交互以及针对NoSQL数据库和动态现实场景量身定制的数据集有限可用性。为了应对这些挑战，我们概述了未来的研究方向，例如扩展文本到SQL的功能以支持NoSQL数据库，设计用于动态多轮交互的数据集，以及优化系统以适应现实世界的可扩展性和鲁棒性。通过审视当前进展并识别关键差距，本文旨在指导基于LLM的文本到SQL系统下一代的研发与应用。|\n",
        "2412.05200": "|**2024-12-06**|**Are Frontier Large Language Models Suitable for Q&A in Science Centres?**|Jacob Watson et.al.|[2412.05200](http://arxiv.org/abs/2412.05200)|null|本文探讨了前沿大型语言模型（LLMs）在科学中心问答互动中的适用性，旨在提高游客参与度同时保持事实准确性。利用从英国莱斯特国家空间中心收集的问题数据集，我们评估了三个领先模型生成的回答：OpenAI的GPT-4、Claude 3.5 Sonnet和Google Gemini 1.5。每个模型都被要求针对8岁儿童观众提供标准答案和创造性回答，这些回答由空间科学专家根据准确性、参与度、清晰度、新颖性和偏离预期答案的程度进行评估。结果显示，在创造性和准确性之间存在着权衡，尽管Claude在保持清晰度和吸引年轻观众方面超越了GPT和Gemini，甚至在要求生成更富有创造性的回答时也是如此。然而，专家观察到，所有模型中更高的新颖性通常与事实可靠性降低有关。这项研究突出了LLMs在教育环境中的潜力，强调了精心设计提示以平衡参与度和科学严谨性的必要性。|\n",
        "2412.05187": "|**2024-12-06**|**SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot**|Jinlin Wu et.al.|[2412.05187](http://arxiv.org/abs/2412.05187)|**[link](https://github.com/franciszchen/surgbox)**|**手术干预，尤其是在神经科领域，代表复杂且高风险的场景，对手术团队提出了巨大的认知负担。尽管有目的的教育和实践可以增强认知能力，但由于患者安全问题的考虑，手术培训机会仍然有限。为了解决手术培训和手术中的认知挑战，我们提出了SurgBox，一个由代理驱动的沙盒框架，旨在系统性地提高外科医生在沉浸式手术模拟中的认知能力。具体来说，我们的SurgBox利用定制化的检索增强生成（RAG）的大型语言模型（LLMs）来真实地复制各种手术角色，从而为有目的的练习提供逼真的训练环境。特别是，我们设计了手术协同助手（Surgery Copilot），这是一个由AI驱动的助手，能够主动协调手术信息流并支持临床决策，从而减轻手术过程中手术团队的认知负荷。通过整合新颖的长短期记忆（Long-Short Memory）机制，我们的手术协同助手可以有效地在即时程序辅助和全面手术知识之间取得平衡。使用真实的神经外科手术记录进行的广泛实验验证了我们的SurgBox框架在提高手术认知能力和支持临床决策方面的有效性。通过提供针对培训和操作支持的综合性解决方案以解决认知挑战，我们的SurgBox框架推动了外科教育和实践的发展，有可能改变手术结果和医疗质量。代码可在https://github.com/franciszchen/SurgBox获取。**|\n",
        "2412.06769": "|**2024-12-09**|**Training Large Language Models to Reason in a Continuous Latent Space**|Shibo Hao et.al.|[2412.06769](http://arxiv.org/abs/2412.06769)|null|大型语言模型（LLMs）通常在“语言空间”中进行推理，通过思维链（CoT）来表述推理过程以解决复杂的推理问题。然而，我们认为语言空间并不总是推理的最优选择。例如，大多数单词标记主要用于文本连贯性，而非推理所必需，而一些关键标记则需要复杂的规划和给LLMs带来巨大挑战。为了探索LLMs在不受限制的潜在空间中进行推理的潜力，而不是使用自然语言，我们引入了一种新的范式——椰子（连续思维链）。我们利用LLM的最后隐藏状态作为推理状态的表示（称为“连续思维”）。我们不是将其解码为单词标记，而是直接将其作为连续空间中的后续输入嵌入反馈给LLM。实验表明，椰子可以有效地增强LLM在多个推理任务上的表现。这种新颖的潜在推理范式导致出现高级推理模式：连续思维可以编码多个替代的后续推理步骤，允许模型执行广度优先搜索（BFS）来解决问题，而不是像CoT那样过早地承诺单一确定路径。在需要大量回溯规划的某些逻辑推理任务中，椰子优于CoT，推理过程中思考标记更少。这些发现展示了潜在推理的潜力，并为未来的研究提供了宝贵的见解。|\n",
        "2412.06757": "|**2024-12-09**|**Why Do Developers Engage with ChatGPT in Issue-Tracker? Investigating Usage and Reliance on ChatGPT-Generated Code**|Joy Krishan Das et.al.|[2412.06757](http://arxiv.org/abs/2412.06757)|null|大型语言模型（LLMs）如ChatGPT已显示出协助开发者进行编码和调试任务的潜力。然而，它们在协同问题解决中的角色尚未得到充分探索。在本研究中，我们分析了GitHub上1,012个问题中的1,152次开发者与ChatGPT的对话，以考察ChatGPT的多样使用和对其生成代码的依赖。我们的贡献有四个方面。首先，我们手动分析了289次对话，以了解ChatGPT在GitHub问题中的使用情况。我们的分析显示，ChatGPT主要用于创意构思，而其在验证（例如，代码文档准确性）方面的使用非常有限。其次，我们应用BERTopic模型来识别整个数据集中关键的关注领域。我们发现后端问题（例如，API管理）主导了对话，而测试却意外地覆盖较少。第三，我们利用CPD克隆检测工具来检查ChatGPT生成的代码是否被用于解决问题。我们的发现显示，ChatGPT生成的代码被直接用于解决仅占5.83%的问题。第四，我们使用基于RoBERTa的情感分析模型来估计情感，以确定开发者对不同用途和关注领域的满意度。我们发现，使用ChatGPT进行重构和解决数据分析（例如，分类表数据）问题的正面情绪（即，高度满意）。相反，当使用ChatGPT调试问题和解决自动化任务（例如，GUI交互）时，我们观察到负面情绪。我们的研究发现，开发者存在未满足的需求和日益增长的不满。研究人员和ChatGPT开发者应专注于开发特定任务的解决方案，以帮助解决各种问题，提高软件开发中的用户满意度和解决问题的效率。|\n",
        "2412.06748": "|**2024-12-09**|**Refusal Tokens: A Simple Way to Calibrate Refusals in Large Language Models**|Neel Jain et.al.|[2412.06748](http://arxiv.org/abs/2412.06748)|null|构建安全可靠的语言模型的关键组成部分是使模型能够适当地拒绝遵循某些指令或回答某些问题。我们可能希望模型为各种用户查询类别输出拒绝消息，例如，无意义的问题、执行非法行为的指令，或需要超出模型知识范围的信息的查询。设计拒绝回答此类问题的模型复杂化，因为个人可能希望他们的模型在拒绝不同类别的查询时表现出不同水平的感觉性，不同的用户可能希望有不同的拒绝率。当前默认的方法涉及使用每个类别不同比例的拒绝消息训练多个模型以实现所需的拒绝率，这计算成本高，可能需要为每位用户的拒绝率偏好训练新的模型。为了解决这些挑战，我们提出了拒绝标记，每个拒绝类别一个标记，或一个单一的拒绝标记，这些标记在训练期间添加到模型的响应之前。然后，我们展示了如何在推理期间增加或减少生成每个类别拒绝标记的概率，以引导模型的拒绝行为。拒绝标记允许通过在生成过程中选择性干预来控制单个模型的拒绝率，而不需要任何进一步的微调。|\n",
        "2412.06738": "|**2024-12-09**|**JAPAGEN: Efficient Few/Zero-shot Learning via Japanese Training Dataset Generation with LLM**|Takuro Fujii et.al.|[2412.06738](http://arxiv.org/abs/2412.06738)|null|近期一些研究强调了大型语言模型（LLMs）作为有效的监督训练数据生成器的潜力，提供了如提高推理效率和降低数据收集相关成本等优势。然而，这些研究主要关注英语任务。在本文中，我们探讨了基本的研究问题：LLMs能否作为其他语言任务的优秀训练数据生成器？具体来说，我们利用LLMs在六种不同的日语下游任务下，在少样本和零样本学习场景中合成监督训练数据。随后，我们使用这些合成的数据训练紧凑模型（例如BERT）。这种新颖的方法被称为JAPAGEN。我们的实验发现表明，JAPAGEN在需要正式文本输入的分类任务中实现了稳健的性能，与传统的LLM提示策略相比，取得了具有竞争力的结果。|\n",
        "2412.06724": "|**2024-12-09**|**AutoDCWorkflow: LLM-based Data Cleaning Workflow Auto-Generation and Benchmark**|Lan Li et.al.|[2412.06724](http://arxiv.org/abs/2412.06724)|null|我们研究了大型语言模型（LLMs）在自动生成数据清理工作流中的推理能力。为了评估LLMs完成数据清理任务的能力，我们实现了一个基于LLM的自动数据清理工作流（AutoDCWorkflow）的管道，通过提示LLMs进行数据清理操作来修复三种类型的数据质量问题：重复数据、缺失值和不一致的数据格式。给定一个脏表和目的（以查询形式表达），此管道生成一个最小的、干净的表，足以满足目的，并生成用于生成该表的数据清理工作流。规划过程涉及三个主要的LLM驱动组件：（1）选择目标列：识别与目的相关的目标列集合。（2）检查列质量：评估每个目标列的数据质量，并生成数据质量报告作为操作目标。（3）生成操作与参数：根据数据质量报告的结果预测下一个操作和参数。此外，我们提出一个数据清理基准，以评估LLM代理自动生成解决不同难度水平数据清理目的的工作流的能力。基准包括注释数据集，作为一个包含目的、原始表、干净表、数据清理工作流和答案集的集合。在我们的实验中，我们评估了三种自动生成目的驱动数据清理工作流的LLMs。结果表明，LLMs在规划和生成数据清理工作流方面表现良好，无需微调。|\n",
        "2412.06693": "|**2024-12-09**|**OmniEvalKit: A Modular, Lightweight Toolbox for Evaluating Large Language Model and its Omni-Extensions**|Yi-Kai Zhang et.al.|[2412.06693](http://arxiv.org/abs/2412.06693)|null|随着大型语言模型（LLMs）的快速发展，其应用范围得到了显著扩展，从多语言支持到特定领域的任务和多模态集成。本文介绍了一种新型的基准测试工具箱OmniEvalKit，旨在评估LLMs及其全功能扩展在多语言、多领域和多模态能力方面的表现。与现有专注于单一方面的基准测试不同，OmniEvalKit提供了一个模块化、轻量化和自动化的评估系统。它采用模块化架构，包括静态构建器和动态数据流，促进了新模型和数据集的无缝集成。OmniEvalKit支持超过100种LLMs和50个评估数据集，覆盖了成千上万种模型-数据集组合的全面评估。OmniEvalKit致力于创建一个超轻量级且快速部署的评估框架，使下游应用对人工智能社区更加便捷和灵活。|\n",
        "2412.06684": "|**2024-12-09**|**Exploring Critical Testing Scenarios for Decision-Making Policies: An LLM Approach**|Weichao Xu et.al.|[2412.06684](http://arxiv.org/abs/2412.06684)|null|近年来，决策政策在各种领域，如自动驾驶和机器人技术，取得了令人惊讶的成就。在存在可能威胁其可靠性的关键场景的情况下，对决策政策进行测试至关重要。众多研究努力致力于测试这些政策。然而，由于测试政策和环境的复杂性，仍然存在重大挑战，例如测试效率低和多样性不足。受大型语言模型（LLMs）卓越能力的影响，本文提出了一种基于LLM的在线测试框架，以有效地测试决策政策。主要思路是利用基于LLM的测试场景生成器通过思考和推理智能地生成具有挑战性的测试案例。具体来说，我们首先设计了一个“生成-测试-反馈”流程，并应用模板提示工程充分利用LLMs的知识和推理能力。然后，我们引入了一种多尺度场景生成策略来解决LLMs在精细调整方面固有的挑战，从而进一步提高测试效率。最后，我们在五个广泛使用的基准上评估了基于LLM的方法。实验结果表明，我们的方法在揭示关键和多样化的场景方面显著优于基线方法。|\n",
        "2412.06681": "|**2024-12-09**|**Toward LLM-Agent-Based Modeling of Transportation Systems: A Conceptual Framework**|Tianming Liu et.al.|[2412.06681](http://arxiv.org/abs/2412.06681)|null|在交通运输系统需求建模和仿真领域，基于代理模型和微观模拟是目前最先进的方法。然而，现有的基于代理模型在行为真实性和资源需求方面仍存在一些限制，这限制了它们的适用性。在本研究中，我们利用新兴的大语言模型（LLMs）和基于LLMs的代理技术，提出了一种适用于交通运输系统的一般LLM-代理建模框架。我们认为，LLM代理不仅具备作为代理的基本能力，而且为克服现有基于代理模型的某些局限性提供了有希望的解决方案。我们的概念框架设计紧密模拟了交通网络中人类旅行者的决策、交互过程和特征，并通过相关研究和LLM代理在瓶颈设置中的学习和调整的演示实例，证明了所提出的系统可以满足决策和学习行为的关键行为标准。尽管需要进一步细化基于LLM的代理建模框架，但我们相信这种方法有可能提高交通运输系统建模和仿真的水平。|\n",
        "2412.06676": "|**2024-12-09**|**I Don't Know: Explicit Modeling of Uncertainty with an [IDK] Token**|Roi Cohen et.al.|[2412.06676](http://arxiv.org/abs/2412.06676)|null|大型语言模型因其能够捕捉现实世界知识而闻名，这使得它们在许多下游任务中表现出色。尽管近年来取得了进展，但这些模型仍然容易受到所谓的“幻觉”的影响，导致它们产生不想要且事实错误的文章。在本研究中，我们提出了一种新颖的校准方法，可用于对抗幻觉。我们向模型的词汇表中添加了一个特殊的[IDK]（“我不知道”）标记，并引入了一个目标函数，该函数将概率质量转移到[IDK]标记以应对错误的预测。这种方法允许模型在其输出中明确表达不确定性。我们在多个模型架构和事实性下游任务中评估了我们的方法。我们发现，使用我们的方法训练的模型能够在它们之前可能出错的地方表达不确定性，同时只损失少量的编码知识。我们还对多种方法变体进行了广泛的消融研究，并提供了对我们方法精确度-召回率权衡的详细分析。|\n",
        "2412.06673": "|**2024-12-09**|**ILLUME: Illuminating Your LLMs to See, Draw, and Self-Enhance**|Chunwei Wang et.al.|[2412.06673](http://arxiv.org/abs/2412.06673)|null|在这篇论文中，我们介绍了ILLUME，这是一种统一的多元模态大型语言模型（MLLM），通过统一的下一个标记预测公式，将多元模态的理解和生成能力无缝集成到单个大型语言模型中。为了解决图像-文本对齐通常所需的大量数据集大小，我们提出通过设计一个结合语义信息的视觉标记化器和渐进式多阶段训练程序来提高数据效率。这种方法将数据集大小减少到仅为15M用于预训练——仅为通常所需数量的四分之一——同时实现了与现有统一MLLMs（如Janus）相当甚至更优的性能。此外，为了促进理解和生成能力之间的协同增强，这是以往工作中较少探索的，我们引入了一种新颖的自我增强多元模态对齐方案。该方案监督MLLM自我评估文本描述和自生成图像之间的一致性，促进模型更准确地解释图像，并避免由图像生成中的对齐错误引起的非现实和不正确预测。基于广泛的实验，我们提出的ILLUME在各种多元模态理解、生成和编辑的基准测试中脱颖而出，并与其他最先进的统一MLLMs和专业模型竞争。|\n",
        "2412.07763": "|**2024-12-10**|**Bayesian Optimization of Antibodies Informed by a Generative Model of Evolving Sequences**|Alan Nawzad Amin et.al.|[2412.07763](http://arxiv.org/abs/2412.07763)|**[link](https://github.com/alannawzadamin/clonebo)**|**为了构建有效的治疗药物，生物学家通过迭代地突变抗体序列来提高其结合力和稳定性。建议的突变可以基于之前的测量结果，或者通过从大量的抗体数据库中学习来预测典型的抗体。不幸的是，典型抗体的搜索空间巨大，实验往往在预算范围内无法找到合适的抗体。我们引入了基于克隆的贝叶斯优化（CloneBO），这是一种贝叶斯优化过程，通过教导一个生成模型如何优化我们的免疫系统中的抗体，从而在实验室中有效地优化抗体。我们的免疫系统通过迭代地进化其序列的特定部分来与靶点强有力地结合，并稳定地结合，从而产生一组被称为克隆家族的相关、演化的序列。我们在数以万计的克隆家族上训练了一个大型语言模型，CloneLM，并使用它来设计具有最有可能优化人体免疫系统内抗体的突变序列。我们提出使用扭曲的顺序蒙特卡洛过程来引导我们的设计以适应之前的测量。我们表明，在现实情况下的计算机模拟实验中，CloneBO比先前的方法更有效地优化了抗体，在体外湿实验中设计了更强和更稳定的结合剂。**|\n",
        "2412.07743": "|**2024-12-10**|**Zero-Shot ATC Coding with Large Language Models for Clinical Assessments**|Zijian Chen et.al.|[2412.07743](http://arxiv.org/abs/2412.07743)|null|将安大略省健康部和InterRAI加拿大在医疗保健研究和运营中手动分配解剖治疗化学（ATC）代码至处方记录的过程，是一个重要的瓶颈，需要大量的专家时间和精力。为了在保持数据隐私的同时自动化这一过程，我们开发了一种实用的方法，使用本地可部署的大语言模型（LLMs）。受最近在自动国际疾病分类（ICD）编码方面的进展启发，我们的方法将ATC编码视为一个层次化信息提取任务，通过引导LLMs逐层浏览ATC本体。我们使用GPT-4o作为准确性的上限，并专注于开发适合隐私敏感部署的开源Llama模型。在加拿大卫生部的药品产品数据、RABBITS基准测试以及安大略省健康的真实临床笔记中进行测试，我们的方法在GPT-4o上实现了78%的精确匹配准确率，在Llama 3.1 70B上实现了60%。我们通过药物定义研究知识固化，发现准确率有适度提高。此外，我们展示了对Llama 3.1 8B进行微调后的模型与零样本Llama 3.1 70B的准确率相匹配，这表明使用较小的模型进行有效的ATC编码是可行的。我们的结果证明了在隐私敏感的医疗保健环境中自动进行ATC编码的可行性，为未来的部署奠定了基础。|\n",
        "2412.07724": "|**2024-12-10**|**Granite Guardian**|Inkit Padhi et.al.|[2412.07724](http://arxiv.org/abs/2412.07724)|**[link](https://github.com/ibm-granite/granite-guardian)**|**我们推出了Granite Guardian模型系列，这是一套旨在为提示和响应提供风险检测的保障措施，以支持与任何大型语言模型（LLM）的安全和负责任使用。这些模型在多个风险维度上提供全面覆盖，包括社会偏见、粗俗、暴力、色情内容、不道德行为、越狱以及与幻觉相关的风险，如检索增强生成（RAG）的上下文相关性、基础性和回答相关性。Granite Guardian模型基于一个独特的数据集进行训练，该数据集结合了来自不同来源的人类标注和合成数据。这些模型解决了传统风险检测模型通常忽略的风险，如越狱和RAG特定问题。在有害内容和RAG幻觉相关基准测试上分别获得AUC分数0.871和0.854，Granite Guardian是此领域中最具有普遍性和竞争力的模型。作为开源发布，Granite Guardian旨在促进整个社区负责任的AI发展。**|\n",
        "2412.07689": "|**2024-12-10**|**DriveMM: All-in-One Large Multimodal Model for Autonomous Driving**|Zhijian Huang et.al.|[2412.07689](http://arxiv.org/abs/2412.07689)|**[link](https://github.com/zhijian11/DriveMM)**|**大型多模态模型（LMMs）通过整合大型语言模型，在自动驾驶（AD）领域展示了卓越的理解和解释能力。尽管取得了进展，但当前基于数据驱动的自动驾驶方法往往集中在单个数据集和特定任务上，忽视了它们的整体能力和泛化能力。为了弥补这些差距，我们提出了DriveMM，这是一种通用的大型多模态模型，旨在处理多种数据输入，如图像和多视角视频，同时在感知、预测和规划等广泛的自动驾驶任务中发挥作用。最初，该模型经过课程预训练，以处理不同的视觉信号并执行基本的视觉理解和感知任务。随后，我们对各种与自动驾驶相关的数据集进行增强和标准化，以微调模型，从而形成一个集自动驾驶之大成的LMM。为了评估其整体能力和泛化能力，我们在六个公开基准上进行了评估，并在一个未见过的数据集上进行了零样本迁移学习，DriveMM在所有任务中均实现了最先进的性能。我们希望DriveMM能够成为未来在现实世界中实现端到端自动驾驶应用的 promising 解决方案。**|\n",
        "2412.07687": "|**2024-12-10**|**Privacy-Preserving Customer Support: A Framework for Secure and Scalable Interactions**|Anant Prakash Awasthi et.al.|[2412.07687](http://arxiv.org/abs/2412.07687)|null|随着客户支持领域对人工智能（AI）的日益依赖，运营效率和用户体验得到了显著提升。然而，传统的机器学习（ML）方法，这些方法需要在敏感数据集上进行广泛的本地训练，带来了巨大的隐私风险，并且与通用数据保护条例（GDPR）和加州消费者隐私法案（CCPA）等法规存在合规挑战。现有的隐私保护技术，如匿名化、差分隐私和联邦学习，虽然解决了部分问题，但在实用性、可扩展性和复杂性方面仍存在局限。本文提出了一种新型的隐私保护零样本学习（PP-ZSL）框架，该框架利用大型语言模型（LLMs）在零样本学习模式下的能力。与传统的机器学习方法不同，PP-ZSL通过利用预训练的LLMs直接生成响应，从而消除了在敏感数据上本地训练的需求。该框架融合了实时数据匿名化以删除或屏蔽敏感信息、检索增强生成（RAG）以解决特定领域的查询，以及鲁棒的后期处理以确保符合监管标准。这种组合降低了隐私风险，简化了合规性，并提高了可扩展性和运营效率。实证分析表明，PP-ZSL框架能够提供准确、符合隐私规范的响应，同时显著降低了部署人工智能驱动客户支持系统的成本和复杂性。该研究突出了在金融服务业、医疗保健、电子商务、法律支持、电信和政府服务等多个行业的潜在应用。通过解决隐私和性能的双重挑战，该框架为客户交互中的安全、高效和合规的AI应用奠定了基础。|\n",
        "2412.07682": "|**2024-12-10**|**TRIM: Token Reduction and Inference Modeling for Cost-Effective Language Generation**|Alfredo Garrachón Ruiz et.al.|[2412.07682](http://arxiv.org/abs/2412.07682)|null|大型语言模型（LLMs）的推理成本是一个重大挑战，尤其是对于需要长输出的任务，因为它们的计算需求很大。然而，自然语言往往包含冗余，这为优化提供了机会。我们观察到，当得到适当的提示时，LLMs可以生成简练的语言输出，保留基本意义。我们提出了一种节省计算成本的框架，其中LLM的较短的蒸馏输出由一个具有较低推理成本的小型模型重新构建成完整叙事。我们的实验结果表明了有希望的结果，特别是在一般知识领域，平均节省了20.58%的标记，且评估指标略有下降，这表明这种方法可以在语言处理任务中有效地平衡效率和准确性。|\n",
        "2412.07673": "|**2024-12-10**|**Ask Humans or AI? Exploring Their Roles in Visualization Troubleshooting**|Shuyu Shen et.al.|[2412.07673](http://arxiv.org/abs/2412.07673)|null|可视化创作是一个迭代过程，需要用户修改参数如配色方案和数据转换，以达到预期的美学效果并有效传达洞察。由于这些调整的复杂性，用户常常会创建出有缺陷的可视化，并需要故障排除支持。在本文中，我们考察了两种主要的可视化故障排除方法：（1）通过论坛进行人工辅助支持，用户从其他人那里获得建议；（2）使用大型语言模型（LLMs）进行AI辅助支持。我们的目标是了解每种方法在支持可视化故障排除任务中的优缺点。为此，我们从Stack Overflow收集了889个Vega-Lite案例。然后，我们进行了全面分析，以了解用户提出的问题类型、人工和AI指导的有效性，以及补充资源（如文档和示例）对故障排除结果的影响。我们的发现揭示了人工辅助故障排除和AI辅助故障排除之间的显著差异：人工辅助故障排除提供定制、情境敏感的建议，但响应质量往往有所差异，而AI辅助故障排除提供快速反馈，但通常需要额外的情境资源才能达到预期效果。|\n",
        "2412.07672": "|**2024-12-10**|**FlexLLM: Exploring LLM Customization for Moving Target Defense on Black-Box LLMs Against Jailbreak Attacks**|Bocheng Chen et.al.|[2412.07672](http://arxiv.org/abs/2412.07672)|null|在大型语言模型（LLMs）中，防御措施至关重要，以应对众多利用这些系统通过操纵提示生成有害内容的攻击者，这种攻击被称为越狱攻击。尽管已经提出了许多防御策略，但它们往往需要访问模型的内部结构或需要额外的训练，这对使用LLM API的服务提供商来说并不实际，例如OpenAI API或Claude API。在本文中，我们提出了一种动态目标防御方法，通过改变解码超参数来增强模型对各种越狱攻击的鲁棒性。我们的方法不需要访问模型的内部结构，也不会产生额外的训练成本。所提出的防御措施包括两个关键组成部分：（1）通过识别和调整影响标记生成概率的解码超参数来优化解码策略；（2）将解码超参数和模型系统提示转换为动态目标，这些目标在每次运行期间持续改变。通过持续修改解码策略和提示，防御措施有效地缓解了现有攻击。我们的结果表明，在我们的测试中，当使用LLMs作为黑盒API时，我们的防御在三个模型中对越狱攻击最为有效。此外，我们的防御提供了较低的推理成本，并保持了可比的响应质量，使其在与其他防御方法一起使用时成为一种潜在的保护层。|\n",
        "2412.07668": "|**2024-12-10**|**Automating Business Intelligence Requirements with Generative AI and Semantic Search**|Nimrod Busany et.al.|[2412.07668](http://arxiv.org/abs/2412.07668)|null|在动态的商业环境中，对商业智能（BI）系统提出需求仍然是一个重大的挑战。本文介绍了一种名为AutoBIR的创新人工智能系统，该系统利用语义搜索和大型语言模型（LLMs）来自动化和加速BI需求的规格制定。该系统通过会话界面促进与利益相关者的直观互动，将用户输入转换为原型分析代码、描述和数据依赖。此外，AutoBIR生成详细的测试用例报告，可选地添加视觉辅助，简化需求提出过程。通过结合用户反馈，该系统优化BI报告和系统设计，展示了加快数据驱动决策的实际应用。本文探讨了生成式AI在转变BI开发方面的更广泛潜力，阐述了其在提高大规模、发展中的系统数据工程实践中的作用。|\n",
        "2412.07646": "|**2024-12-10**|**Searching for Structure: Investigating Emergent Communication with Large Language Models**|Tom Kouwenhoven et.al.|[2412.07646](http://arxiv.org/abs/2412.07646)|null|人类语言通过反复的语言学习和使用而演变，这些过程在语言习得期间引入了偏见，并塑造了语言系统以实现沟通效率。在这篇论文中，我们研究了如果人工语言被优化为针对大型语言模型（LLMs）的隐式偏见，是否会发生相同的情况。为此，我们模拟了一个经典指称游戏，其中LLMs学习和使用人工语言。我们的结果表明，最初无结构的整体语言确实被塑造出一些结构属性，使得两个LLM智能体能够成功沟通。与人类实验中的观察结果相似，代际传承增加了语言的易学性，但同时也可能导致非人类化的退化词汇。综上所述，这项工作扩展了实验发现，表明LLMs可以用作模拟语言进化的工具，并为此领域未来的机器-人实验开辟了可能性。|\n",
        "2412.08642": "|**2024-12-11**|**Generative Semantic Communication: Architectures, Technologies, and Applications**|Jinke Ren et.al.|[2412.08642](http://arxiv.org/abs/2412.08642)|null|本文深入探讨了生成式人工智能（GAI）在语义通信（SemCom）中的应用，并进行了全面的研究。首先介绍了三个由经典GAI模型支持的流行SemCom系统，包括变分自编码器、生成对抗网络和扩散模型。对于每个系统，本文阐释了GAI模型的基本概念、相应的SemCom架构以及近期努力的文献综述。接着，提出了一种新型的基于最新GAI技术——大型语言模型（LLMs）的生成式SemCom系统。该系统在发送方和接收方均采用两个基于LLMs的AI代理，分别作为“大脑”来提供强大的信息理解和内容再生能力。这种创新设计使得接收方可以直接根据发送方传递的编码语义信息生成所需内容，而不是恢复比特流。因此，它将通信思维从“信息恢复”转变为“信息再生”，从而开启了生成式SemCom的新时代。通过一个关于点对点视频检索的案例研究展示了所提出的生成式SemCom系统的优越性，与传统通信系统相比，通信开销减少了99.98%，检索精度提高了53%。此外，还概述了生成式SemCom的四个典型应用场景，并讨论了三个需要未来进一步研究的问题。总之，本文为在SemCom中应用GAI提供了一套全面的指导原则，为未来无线网络中生成式SemCom的高效实现铺平了道路。|\n",
        "2412.08639": "|**2024-12-11**|**Fast Prompt Alignment for Text-to-Image Generation**|Khalil Mrini et.al.|[2412.08639](http://arxiv.org/abs/2412.08639)|**[link](https://github.com/tiktok/fast_prompt_alignment)**|**文本到图像生成技术发展迅速，但将复杂的文本提示与生成的图像相匹配仍然具有挑战性，尤其是在处理复杂的物体关系和细微的细节方面。本文介绍了一种名为快速提示对齐（FPA）的提示优化框架，它采用了一次性方法，提高了文本到图像对齐的效率，避免了当前方法如OPT2I典型的迭代开销。FPA利用大型语言模型（LLMs）进行单次迭代提示改写，随后使用优化后的提示进行微调或上下文学习，以实现实时推理，降低计算需求同时保持对齐精度。在COCO Captions和PartiPrompts数据集上的广泛评估表明，FPA在处理时间的一小部分内就实现了具有竞争力的文本-图像对齐得分，这一点通过自动化指标（TIFA、VQA）和人工评估都得到了验证。一项由专家注释员参与的问卷调查进一步揭示了人类对齐判断与自动化评分之间的强相关性，凸显了FPA改进的稳健性。所提出的方法展示了一种可扩展、高效的迭代提示优化替代方案，使其在实时、高需求环境中具有更广泛的应用。代码库已提供以促进进一步研究：https://github.com/tiktok/fast_prompt_alignment**|\n",
        "2412.08635": "|**2024-12-11**|**Multimodal Latent Language Modeling with Next-Token Diffusion**|Yutao Sun et.al.|[2412.08635](http://arxiv.org/abs/2412.08635)|null|多模态生成模型需要一种统一的方法来处理离散数据（例如文本和代码）和连续数据（例如图像、音频、视频）。在这项工作中，我们提出了潜在语言模型（LatentLM），它通过因果Transformer无缝地整合连续和离散数据。具体来说，我们采用变分自编码器（VAE）将连续数据表示为潜在向量，并引入了下一个标记扩散来实现这些向量的自回归生成。此外，我们开发了$\\sigma$-VAE来解决方差崩溃问题，这对于自回归建模至关重要。大量实验证明了LatentLM在各种模态上的有效性。在图像生成方面，LatentLM在性能和可扩展性上都超越了扩散Transformer。当集成到多模态大型语言模型中时，LatentLM提供了一个通用的接口，统一了多模态生成和理解。实验结果表明，在扩大训练标记的设置中，与Transfusion和矢量量化模型相比，LatentLM取得了有利的性能。在文本到语音合成方面，LatentLM在说话人相似性和鲁棒性方面优于最先进的VALL-E 2模型，同时解码步骤减少了10倍。这些结果确立了LatentLM作为一种高效且可扩展的方法，以推进大型多模态模型的发展。|\n",
        "2412.08619": "|**2024-12-11**|**Synthetic Vision: Training Vision-Language Models to Understand Physics**|Vahid Balazadeh et.al.|[2412.08619](http://arxiv.org/abs/2412.08619)|null|物理推理，涉及对动态环境中物体行为的解释、理解和预测，仍然是当前视觉-语言模型（VLMs）的一个重要挑战。在这项工作中，我们提出了两种方法来利用模拟数据增强VLMs的物理推理能力。首先，我们使用与物理推理任务相关的模拟生成的问答（QA）对微调一个预训练的VLM。其次，我们引入了物理上下文构建器（PCBs），这是一种专门的VLM，经过微调以创建包含物理属性和过程的场景描述。在物理推理任务期间，这些PCBs可以作为上下文来帮助大型语言模型（LLM）提高其性能。我们使用多个基准测试了我们的两种方法，包括一个名为Falling Tower的新稳定性检测QA数据集，它包含模拟和真实世界的场景，以及CLEVRER。我们证明，一个小型的经过QA微调的VLM可以显著优于更大的最先进的基座模型。我们还展示了将PCBs集成可以提升基座LLM在物理推理任务上的性能。使用Falling Tower数据集中的真实世界场景，我们还验证了两种方法在Sim2Real迁移中的鲁棒性。我们的结果表明，模拟数据在创建能够进行高级物理推理的学习系统中的有用性。|\n",
        "2412.08615": "|**2024-12-11**|**Exploiting the Index Gradients for Optimization-Based Jailbreaking on Large Language Models**|Jiahui Li et.al.|[2412.08615](http://arxiv.org/abs/2412.08615)|null|尽管通过对齐技术提高了大型语言模型（LLMs）生成内容的安全性，但这些模型仍然容易受到越狱攻击的影响，越狱攻击是一种暴露LLMs安全漏洞的对抗攻击方法。值得注意的是，贪婪坐标梯度（GCG）方法已显示出自动生成对抗后缀以越狱最先进LLMs的能力。然而，GCG中的优化过程非常耗时，使得越狱流程效率低下。在本文中，我们研究了GCG的过程，并确定了间接效应问题，这是GCG优化的关键瓶颈。为此，我们提出了模型攻击梯度索引GCG（MAGIC），通过利用后缀标记的梯度信息来解决间接效应，从而通过减少计算和迭代次数来加速过程。我们的实验在AdvBench上表明，MAGIC实现了高达1.5倍的速度提升，同时保持了与其他基线相当甚至更高的攻击成功率（ASR）。我们的MAGIC在Llama-2上实现了74%的ASR，在执行对GPT-3.5的迁移攻击时实现了54%的ASR。代码可在https://github.com/jiah-li/magic上找到。|\n",
        "2412.08604": "|**2024-12-11**|**Preference Discerning with LLM-Enhanced Generative Retrieval**|Fabian Paischer et.al.|[2412.08604](http://arxiv.org/abs/2412.08604)|null|序列推荐系统旨在根据用户的交互历史提供个性化的推荐。为了实现这一目标，它们通常结合辅助信息，如物品的文本描述和辅助任务，例如预测用户偏好和意图。尽管已经投入了大量努力来增强这些模型，但它们仍然面临着个性化不足的问题。为了解决这个问题，我们提出了一种新的范式，我们称之为偏好辨别。在偏好辨别中，我们明确地将生成式序列推荐系统在其上下文中对用户偏好进行条件化。为此，我们根据用户评论和物品特定数据使用大型语言模型（LLMs）生成用户偏好。为了评估序列推荐系统的偏好辨别能力，我们引入了一个新的基准，该基准在各种场景中提供了一个全面的评估，包括偏好引导和情感跟随。我们使用我们的基准评估了当前最先进的方法，并表明它们在准确辨别用户偏好方面存在困难。因此，我们提出了一种名为Mender的新方法，该方法改进了现有方法，并在我们的基准上实现了最先进的性能。我们的结果表明，即使在训练过程中没有观察到人类偏好，Mender也能被有效引导，为更个性化的序列推荐系统铺平了道路。我们的代码和基准将在发表后开源。|\n",
        "2412.08602": "|**2024-12-11**|**Empirical Measurements of AI Training Power Demand on a GPU-Accelerated Node**|Imran Latif et.al.|[2412.08602](http://arxiv.org/abs/2412.08602)|null|随着人工智能（AI）应用范围的扩大，云计算提供商在计算基础设施方面的投资大幅增加。量化这一基础设施的能源足迹需要根据AI硬件在训练期间的电力需求进行参数化的模型。我们实证测量了一个8-GPU的NVIDIA H100 HGX节点在开源图像分类器（ResNet）和大型语言模型（Llama2-13b）训练过程中的瞬时电力消耗。观察到的最大电力消耗约为8.4千瓦，比制造商额定值10.2千瓦低18%，即使GPU接近满负荷运行。在保持模型架构不变的情况下，将ResNet的批量大小从512张图像增加到4096张图像，总训练能耗减少了4倍。这些发现可以为数据中心运营商的容量规划以及研究人员的能源使用估计提供信息。未来的工作将研究冷却技术和碳感知调度对AI工作负载能源消耗的影响。|\n",
        "2412.08593": "|**2024-12-11**|**Leveraging Graph-RAG and Prompt Engineering to Enhance LLM-Based Automated Requirement Traceability and Compliance Checks**|Arsalan Masoudifard et.al.|[2412.08593](http://arxiv.org/abs/2412.08593)|null|确保软件需求规格说明书（SRS）与更高级的组织或国家要求相一致至关重要，尤其是在金融和航空航天等监管环境。在这些领域，保持一致性、遵守监管框架、最小化错误以及满足关键期望对于系统的可靠运行是必不可少的。大型语言模型（LLMs）的广泛应用凸显了它们的巨大潜力，但在检索相关信息和增强推理能力方面仍有很大的改进空间。本研究表明，将强大的图-RAG框架与高级提示工程技术，如思维链和思维树，相结合可以显著提高性能。与基线RAG方法和简单的提示策略相比，这种方法提供更准确和情境感知的结果。尽管这种方法在性能上显示出显著改进，但也带来了一些挑战。在多样化的环境中实施既昂贵又复杂，需要仔细适应特定场景。此外，它的有效性高度依赖于完整和准确的数据输入，而这些数据可能并不总是容易获得，这进一步限制了其可扩展性和实用性。|\n",
        "2412.08587": "|**2024-12-11**|**Advancing Single- and Multi-task Text Classification through Large Language Model Fine-tuning**|Hang Zhao et.al.|[2412.08587](http://arxiv.org/abs/2412.08587)|null|该研究对比了基于编码器模型（例如BERT、RoBERTa）和大型语言模型（LLMs，例如Llama3）在文本分类任务中的性能，尤其是在微调的情况下。研究采用了各种不同大小和架构的模型和方法，包括微调和预训练的方法。首先，我们对这些LLMs在20个新闻组（20NG）和MASSIVE数据集上的性能进行了评估，并将它们与仅编码器的RoBERTa模型进行了比较。此外，我们通过将意图检测和槽填充等多个分类任务结合到一个模型中，并使用两个数据集的数据来探索这两种模型类型的多任务能力。我们的结果表明，完全微调的Llama3-70B模型在各种分类任务和数据集上优于RoBERTa-large和其他解码器LLMs。此外，综合的多任务微调LLMs在两个数据集上的两个任务中都匹配了双模型设置的性能。总体而言，我们的研究为基于编码器和LLM的文本分类任务提供了一个全面的基准，并展示了一种将两个或多个完全微调的解码器LLM结合起来的方法，以降低延迟并保持等效性能。|\n",
        "2412.08585": "|**2024-12-11**|**TURBOATTENTION: Efficient Attention Approximation For High Throughputs LLMs**|Hao Kang et.al.|[2412.08585](http://arxiv.org/abs/2412.08585)|null|大型语言模型（LLM）推理需要大量的计算和内存，尤其是在关键注意力机制上。虽然量化技术，如FlashAttention加速算法，已经提高了整体推理的效率，但它们解决了问题的不同方面：量化专注于权重-激活操作，而FlashAttention提升了执行效率但需要高精度格式。最近的键值（KV）缓存量化减少了内存带宽，但仍然需要浮点数反量化以进行注意力操作。我们提出了TurboAttention，这是一种使注意力量化执行同时解决内存和计算效率的综合方法。我们的解决方案引入了两项关键创新：FlashQ，这是一种头部注意力量化技术，能够压缩KV缓存并实现激活-激活乘法的量化执行；以及基于稀疏性的Softmax近似（SAS），它在注意力中的指数运算过程中消除了对FP32反量化的需求。实验结果表明，TurboAttention在注意力方面实现了1.2-1.8倍的加速，将KV缓存大小减少了4.4倍以上，并在FP16基线之上实现了高达2.37倍的最大吞吐量，同时在各种数据集和模型上优于最先进的量化和压缩技术。|\n",
        "2412.09618": "|**2024-12-12**|**EasyRef: Omni-Generalized Group Image Reference for Diffusion Models via Multimodal LLM**|Zhuofan Zong et.al.|[2412.09618](http://arxiv.org/abs/2412.09618)|null|在扩散模型的个性化方面取得了显著成果。传统的无需调整的方法通常通过平均多个参考图像的图像嵌入作为注入条件来编码多个参考图像，但这样的与图像无关的操作无法在多个参考图像之间进行交互，以捕捉多个参考图像中的统一视觉元素。尽管基于调整的Low-Rank Adaptation（LoRA）可以通过训练过程有效地提取多个图像中的统一元素，但它需要对每个不同的图像组进行特定的微调。本文介绍了一种名为EasyRef的新型即插即用调整方法，使得扩散模型能够根据多个参考图像和文本提示进行条件化。为了有效地利用多个图像中的统一视觉元素，我们利用多模态大型语言模型（MLLM）的多图像理解和指令遵循能力，提示它根据指令捕捉统一视觉元素。此外，通过适配器将MLLM的表示注入扩散过程，可以轻松泛化到未见过的领域，挖掘未见数据中的统一视觉元素。为了降低计算成本并增强细粒度细节保留，我们引入了一种高效的参考聚合策略和渐进式训练方案。最后，我们引入了MRBench，一个全新的多参考图像生成基准。实验结果表明，EasyRef优于IP-Adapter等无需调整的方法和LoRA等基于调整的方法，在多个领域实现了优越的审美质量和稳健的零样本泛化。|\n",
        "2412.09612": "|**2024-12-12**|**Olympus: A Universal Task Router for Computer Vision Tasks**|Yuanze Lin et.al.|[2412.09612](http://arxiv.org/abs/2412.09612)|null|我们引入了Olympus，这是一种将多模态大型语言模型（MLLMs）转化为能够处理广泛计算机视觉任务的统一框架的新方法。利用控制器MLLM，Olympus将超过20个专业任务分配给图像、视频和3D对象的专用模块。这种基于指令的路由方式通过链式动作实现复杂工作流程，无需训练重量级的生成模型。Olympus可以轻松集成到现有的MLLM中，并通过可比性能扩展其功能。实验结果表明，Olympus在20个任务中实现了平均路由准确率94.75%，在链式动作场景中实现了精确度91.82%，展示了其作为通用任务路由器的有效性，能够解决各种计算机视觉任务。项目页面：https://github.com/yuanze-lin/Olympus_page|\n",
        "2412.09604": "|**2024-12-12**|**SynerGen-VL: Towards Synergistic Image Understanding and Generation with Vision Experts and Token Folding**|Hao Li et.al.|[2412.09604](http://arxiv.org/abs/2412.09604)|null|大型语言模型（LLMs）的显著成功已经扩展到多模态领域，实现了在图像理解和生成方面的出色表现。近期开发能够集成这些功能的统一多模态大型语言模型（MLLMs）的努力已显示出良好的成果。然而，现有方法通常涉及复杂的设计在模型架构或训练流程中，增加了模型训练和扩展的难度。在本文中，我们提出了SynerGen-VL，这是一个简单而强大的无需编码器的MLLM，能够同时进行图像理解和生成。为了解决现有无需编码器的统一MLLMs中识别出的挑战，我们引入了标记折叠机制和基于视觉专家的渐进对齐预训练策略，这些机制有效地支持了高分辨率图像理解，同时降低了训练复杂性。在采用统一的目标预测下一个标记的大规模混合图像-文本数据进行训练后，SynerGen-VL在参数规模相当或更小的情况下达到了或超过了现有无需编码器的统一MLLMs的性能，并且缩小了与特定任务的最新模型的差距，为未来统一MLLMs的发展指明了一条有希望的路径。我们的代码和模型将公开发布。|\n",
        "2412.09603": "|**2024-12-12**|**Do Multimodal Large Language Models See Like Humans?**|Jiaying Lin et.al.|[2412.09603](http://arxiv.org/abs/2412.09603)|null|多模态大型语言模型（MLLMs）在各种视觉任务上取得了令人印象深刻的成果，得益于近年来大型语言模型的发展。然而，一个关键问题仍未得到解决：MLLMs是否像人类一样感知视觉信息？当前的基准测试缺乏从这一角度评估MLLMs的能力。为了应对这一挑战，我们引入了HVSBench，这是一个大规模基准，旨在评估MLLMs与人类视觉系统（HVS）在反映人类视觉的基本视觉任务上的对齐程度。HVSBench精心挑选了超过85K个多模态样本，涵盖HVS中的13个类别和5个领域，包括突出、瞬视、优先处理、自由观看和搜索。广泛的实验表明，我们的基准在全面评估MLLMs方面的有效性。具体来说，我们评估了13个MLLMs，发现即使是表现最好的模型也仍有很大的改进空间，大多数模型只取得了中等的结果。我们的实验表明，HVSBench为最先进的MLLMs提出了新的重大挑战。我们相信HVSBench将促进对人类对齐和可解释的MLLMs的研究，这是理解MLLMs如何感知和处理视觉信息的关键步骤。|\n",
        "2412.09596": "|**2024-12-12**|**InternLM-XComposer2.5-OmniLive: A Comprehensive Multimodal System for Long-term Streaming Video and Audio Interactions**|Pan Zhang et.al.|[2412.09596](http://arxiv.org/abs/2412.09596)|**[link](https://github.com/internlm/internlm-xcomposer)**|**创建能够像人类认知一样在长时间内与环境互动的AI系统一直是长期的研究目标。最近，多模态大型语言模型（MLLMs）在开放世界理解方面取得了重大进展。然而，连续和同时进行感知、记忆和推理的挑战仍然 largely 未被探索。当前的MLLMs受限于其序列到序列的架构，这限制了它们同时处理输入和生成响应的能力，就像在感知时无法思考一样。此外，依赖长上下文来存储历史数据对于长期交互来说是不切实际的，因为保留所有信息变得成本高昂且效率低下。因此，该项目不是依赖于单一的基础模型来完成所有功能，而是从专用通用AI的概念中汲取灵感，引入了解耦的流感知、推理和记忆机制，从而实现与流式视频和音频输入的实时交互。所提出的框架InternLM-XComposer2.5-OmniLive（IXC2.5-OL）由三个关键模块组成：（1）流感知模块：实时处理多模态信息，将关键细节存储在记忆中，并针对用户查询触发推理。（2）多模态长记忆模块：整合短期和长期记忆，将短期记忆压缩成长期记忆以实现高效的检索和更高的准确性。（3）推理模块：响应用户查询并执行推理任务，与感知和记忆模块协调。该项目模拟了人类的认知过程，使多模态大型语言模型能够提供持续和自适应的服务。**|\n",
        "2412.09572": "|**2024-12-12**|**DiverseAgentEntropy: Quantifying Black-Box LLM Uncertainty through Diverse Perspectives and Multi-Agent Interaction**|Yu Feng et.al.|[2412.09572](http://arxiv.org/abs/2412.09572)|null|量化大型语言模型（LLMs）在事实参数知识上的不确定性，尤其是在黑盒设置下，是一个重大挑战。现有方法通过评估模型对原始查询的响应的自我一致性来衡量模型的不确定性，但并不总能捕捉到真正的不确定性。模型可能会对原始查询给出一致的错误答案，但对同一查询的不同角度的多样化问题给出正确答案，反之亦然。在本文中，我们提出了一种新颖的方法，称为DiverseAgentEntropy，用于评估模型的不确定性，该方法在多智能体交互的假设下进行，即如果一个模型是确定的，它应该能够一致地回忆起关于同一原始查询的多样化问题中的答案。我们进一步实施了一种弃权策略，在不确定性较高时抑制响应。我们的方法提供了对模型可靠性的更准确预测，并进一步检测幻觉，优于其他基于自我一致性的方法。此外，它还表明，现有模型往往无法在多样化的问题中一致地检索到同一查询的正确答案，即使它们知道正确答案。|\n",
        "2412.09563": "|**2024-12-12**|**Does Representation Matter? Exploring Intermediate Layers in Large Language Models**|Oscar Skean et.al.|[2412.09563](http://arxiv.org/abs/2412.09563)|null|理解什么定义了大型语言模型（LLM）中的良好表示对于理论理解和实际应用都至关重要。在这篇论文中，我们研究了各种LLM架构中中间表示的质量，包括Transformers和状态空间模型（SSMs）。我们发现，中间层通常比最终层能提供更丰富的表示，用于下游任务。为了衡量表示质量，我们调整并应用了一组最初在其他环境中提出的指标——如提示熵、曲率和增强不变性。我们的实证研究表明，存在显著的架构差异，表示在训练过程中是如何演变的，以及诸如输入随机性和提示长度等因素如何影响每一层。值得注意的是，我们在某些中间层的熵中观察到双峰模式，并考虑了与训练数据相关的潜在解释。总体而言，我们的研究结果揭示了LLM的内部机制，并指导了架构优化和训练的策略。|\n",
        "2412.09560": "|**2024-12-12**|**Foundational Large Language Models for Materials Research**|Vaibhav Mishra et.al.|[2412.09560](http://arxiv.org/abs/2412.09560)|null|材料发现与开发对于解决全球挑战至关重要。然而，材料科学文献的指数级增长，包含大量的文本数据，在知识提取、合成和科学推理方面造成了重大瓶颈。大型语言模型（LLMs）通过自动化分析和预测为加速材料研究提供了前所未有的机会。尽管如此，它们的有效部署需要针对特定领域进行适应性调整，以理解和解决领域相关任务。在此，我们介绍了LLaMat，这是一系列用于材料科学的底层模型，通过在大量材料文献和晶体学数据上持续预训练LLaMA模型而开发出来的。通过系统评估，我们证明了LLaMat在特定于材料的自然语言处理和结构化信息提取方面表现出色，同时保持了通用的语言能力。专门化的LLaMat-CIF变体在晶体结构生成方面展现出前所未有的能力，预测出覆盖元素周期表的高稳定性晶体。有趣的是，尽管与LLaMA-2相比，LLaMA-3的表现更优越，但我们观察到LLaMat-2在不同材料科学任务中的领域特定性能意外地增强，包括从文本和表格中提取结构化信息，特别是在晶体结构生成方面，这表明在过度训练的LLMs中可能存在潜在的适应性刚性。总之，本研究证明了领域适应性在开发实际可部署的LLM协作者方面的有效性。在材料科学之外，我们的发现揭示了LLMs领域适应性方面的重要考虑因素，如模型选择、训练方法以及领域特定性能，这些都可能影响专业科学人工智能系统的发展。|\n",
        "2412.09549": "|**2024-12-12**|**Exemplar Masking for Multimodal Incremental Learning**|Yi-Lun Lee et.al.|[2412.09549](http://arxiv.org/abs/2412.09549)|**[link](https://github.com/yilunlee/exemplar_masking_mcil)**|**多模态增量学习需要在处理来自多个模态的信息的同时，学习新的知识而不忘记之前学过的信息。这项任务面临着许多挑战，主要包括基于示例方法中多模态数据的较大存储量以及在大规模多模态模型上进行微调的计算需求。在本文中，我们利用参数高效的调整方案来减轻微调的负担，并提出了示例掩码框架以高效地重放旧知识。具体来说，基于注意力权重和不同模态之间的相关性，对非重要标记进行掩码，显著减少了示例的存储量，并在相同的内存缓冲区下节省了更多示例。此外，我们还设计了一种多模态数据增强技术，以多样化示例以重放先前知识。在实验中，我们不仅评估了我们的方法在现有的多模态数据集上的表现，还将ImageNet-R数据集扩展为多模态数据集作为实际应用，其中标题是通过查询多模态大型语言模型（例如，InstructBLIP）生成的。广泛的实验表明，我们的示例掩码框架在相同的有限内存缓冲区下更为高效且对灾难性遗忘具有更强的鲁棒性。代码可在https://github.com/YiLunLee/Exemplar_Masking_MCIL上找到。**|\n",
        "2412.09529": "|**2024-12-12**|**Can Modern LLMs Act as Agent Cores in Radiology~Environments?**|Qiaoyu Zheng et.al.|[2412.09529](http://arxiv.org/abs/2412.09529)|null|大型语言模型（LLMs）的进步为基于LLM的代理系统铺平了道路，这些系统在各个领域提供了更高的准确性和可解释性。放射学领域因其复杂的分析需求，是应用这些代理的理想场所。本文旨在探讨构建具体放射学代理的先决问题，即“现代LLMs能否在放射学环境中充当代理核心？”为了探讨这一问题，我们引入了RadABench，并贡献了三个方面：首先，我们提出了RadABench-Data，这是一个针对基于LLM的代理的综合合成评估数据集，它从包含6种解剖结构、5种成像方式、10种工具类别和11项放射学任务的广泛分类法中生成。其次，我们提出了RadABench-EvalPlat，这是一个新型代理评估平台，它具有以提示驱动的流程和模拟广泛放射学工具集的能力。第三，我们从5个角度使用多个指标评估了7个领先LLM在我们的基准测试中的性能。我们的发现表明，虽然当前LLMs在许多领域表现出强大的能力，但它们还不够先进，不能作为完全运行中的放射学代理系统中的核心代理。此外，我们还确定了影响LLM基于代理核心性能的关键因素，为临床医生提供了有关如何在现实世界的放射学实践中有效应用代理系统的见解。我们所有的代码和数据都已开源，可在https://github.com/MAGIC-AI4Med/RadABench上获取。|\n"
    },
    "infer": {
        "2411.18191": "|**2024-11-27**|**InputSnatch: Stealing Input in LLM Services via Timing Side-Channel Attacks**|Xinyao Zheng et.al.|[2411.18191](http://arxiv.org/abs/2411.18191)|null|大型语言模型（LLMs）具备广泛的知识和问答能力，已在金融和医疗咨询等对隐私敏感的领域得到广泛应用。在LLMs推理过程中，缓存共享方法被广泛采用以提高效率，通过重用缓存的状态或响应来处理相同或相似的推理请求。然而，我们发现这些缓存机制存在隐私输入泄露的风险，因为缓存可能导致响应时间出现可观察的变化，使其成为基于时间攻击的强候选线索。在本研究中，我们提出了一种新颖的基于时间的侧信道攻击，用于在LLMs推理中执行输入窃取。基于缓存的攻击面临在大型搜索空间中构建候选输入以击中和窃取缓存用户查询的挑战。为了解决这些挑战，我们提出了两个主要组件。输入构造器采用机器学习技术和基于LLM的方法进行词汇相关性学习，同时在通用输入构建中实施优化的搜索机制。时间分析器通过异常值去除实现统计时间拟合，以识别缓存命中模式，并持续提供反馈以优化构造器的搜索策略。我们在两种缓存机制上进行了实验，结果表明我们的方法在各种应用中均能持续获得高攻击成功率。我们的工作突出了与性能优化相关的安全漏洞，强调了在LLMs推理增强的同时优先考虑隐私和安全的必要性。|\n",
        "2411.18077": "|**2024-11-27**|**MiniKV: Pushing the Limits of LLM Inference via 2-Bit Layer-Discriminative KV Cache**|Akshat Sharma et.al.|[2411.18077](http://arxiv.org/abs/2411.18077)|null|由于LLMs（大型语言模型）对内存和计算的高要求，如何在实践中高效地为LLMs提供服务变得极为挑战。在本研究中，我们调查了优化KV缓存的方法，因为其内存占用是LLM推理中的关键瓶颈，尤其是在处理长上下文任务时。为了应对这一挑战，我们引入了MiniKV，这是一种KV缓存优化方法，通过一种新颖的2比特层区分性KV缓存，在同时保持长上下文任务准确性的同时，显著减少了KV缓存的大小。更重要的是，我们开发了专门的CUDA内核，使MiniKV与FlashAttention兼容。在广泛的长上下文任务上的实验表明，MiniKV有效地实现了86%的KV缓存压缩比，同时恢复了超过98.5%的准确性，优于现有方法，同时实现了卓越的系统性能提升。|\n",
        "2411.17309": "|**2024-11-26**|**PIM-AI: A Novel Architecture for High-Efficiency LLM Inference**|Cristobal Ortega et.al.|[2411.17309](http://arxiv.org/abs/2411.17309)|null|大型语言模型（LLMs）因其先进的语言理解和生成能力，在众多应用中变得至关重要。然而，它们对计算和内存的要求给传统的硬件架构带来了巨大的挑战。内存中处理（PIM）将计算单元直接集成到内存芯片中，为LLM推理提供了多项优势，包括减少数据传输瓶颈和提高能效。本文介绍了一种名为PIM-AI的新型DDR5/LPDDR5 PIM架构，专为LLM推理设计，无需修改内存控制器或DDR/LPDDR内存PHY。我们开发了一个模拟器来评估PIM-AI在不同场景下的性能，并证明了其相较于传统架构的显著优势。在基于云的场景中，PIM-AI相较于最先进的GPU，将每秒查询的三年总拥有成本降低了高达6.94倍，具体取决于所使用的LLM模型。在移动场景中，PIM-AI相较于最先进的移动SoC，在每token能耗上实现了10到20倍降低，从而实现了每秒查询增加25到45%，每查询能耗减少6.9倍到13.4倍，延长了电池寿命，并使每次充电的推理次数更多。这些结果突显了PIM-AI颠覆LLM部署的潜力，使其更加高效、可扩展和可持续。|\n",
        "2411.17116": "|**2024-11-26**|**Star Attention: Efficient LLM Inference over Long Sequences**|Shantanu Acharya et.al.|[2411.17116](http://arxiv.org/abs/2411.17116)|**[link](https://github.com/NVIDIA/Star-Attention)**|**由于自注意力机制的二次复杂度，使用Transformer基于的大型语言模型（LLMs）在长序列上进行推理既耗时又昂贵。我们引入了星型注意力，这是一种两阶段的块稀疏近似，通过在多个主机之间分片注意力来提高计算效率，同时最大限度地减少通信开销。在第一阶段，使用并行跨主机的块局部注意力处理上下文。在第二阶段，查询和响应标记通过序列全局注意力关注所有先前缓存的标记。星型注意力与大多数使用全局注意力训练的Transformer基于的LLMs无缝集成，通过减少内存需求和推理时间最多11倍，同时保留95-100%的准确率。**|\n",
        "2411.17089": "|**2024-11-26**|**Efficient LLM Inference with I/O-Aware Partial KV Cache Recomputation**|Chaoyi Jiang et.al.|[2411.17089](http://arxiv.org/abs/2411.17089)|null|对于大型语言模型（LLMs）的推理计算量很大。为了降低自回归解码的成本，采用键值（KV）缓存来存储中间激活，使得GPU只需进行每个新标记所需的增量计算。这种方法显著降低了标记生成的计算开销。然而，KV缓存的内存需求迅速增长，通常超过GPU内存容量。一种成本效益更高的替代方案是将KV缓存卸载到CPU内存中，这可以缓解GPU内存压力，但将瓶颈转移到CPU和GPU之间有限的PCIe连接带宽。现有方法试图通过重叠GPU计算与I/O或采用CPU-GPU异构执行来解决这些问题，但它们受到过度数据移动和对CPU能力的依赖的阻碍。在本文中，我们介绍了一种高效的CPU-GPU I/O感知LLM推理方法，通过在同时通过PCIe总线传输剩余KV缓存的同时，从激活中重新计算部分KV缓存，避免了将整个KV缓存从CPU传输到GPU。这种方法重叠GPU重新计算与数据传输，以最小化GPU空闲时间并最大化推理性能。我们的方法通过集成一个利用输入特性和系统硬件信息的分析模块、一个用于优化计算和通信工作负载分配的调度模块以及一个用于高效执行派生执行计划的运行时模块而完全自动化。实验结果表明，与最先进的方法相比，我们的方法在解码时的延迟降低了高达35.8%，吞吐量提高了46.2%。|\n",
        "2411.16158": "|**2024-11-25**|**MixPE: Quantization and Hardware Co-design for Efficient LLM Inference**|Yu Zhang et.al.|[2411.16158](http://arxiv.org/abs/2411.16158)|null|基于Transformer的大型语言模型（LLMs）随着模型规模的不断扩大取得了显著的成功，但它们的部署仍然面临挑战，主要是因为计算和内存需求巨大。量化技术已成为一种有前景的解决方案，而针对LLMs的最先进量化算法引入了混合精度矩阵乘法（mpGEMM）的需求，即使用低精度权重与高精度激活进行乘法运算。尽管这种方法有优势，但当前硬件加速器如GPU和TPU缺乏对高效mpGEMM的原生支持，导致主顺序循环中的去量化操作效率低下。为了解决这一限制，我们引入了MixPE，这是一种专门设计的混合精度处理单元，旨在高效地在LLM推理中进行低比特量化。MixPE利用两项关键创新来最小化去量化开销并充分发挥低比特量化的潜力。首先，我们认识到每个量化组内的缩放因子和零点是可以共享的，因此我们提议在每个组mpGEMM之后进行去量化，这显著降低了去量化开销。其次，MixPE不是依赖于传统的乘法器，而是使用高效的移位和加法操作进行乘法运算，从而优化了计算和能效。我们的实验结果表明，MixPE在速度上比最先进的量化加速器快2.6倍，在能耗上减少1.4倍。|\n",
        "2411.16003": "|**2024-11-24**|**eFedLLM: Efficient LLM Inference Based on Federated Learning**|Shengwen Ding et.al.|[2411.16003](http://arxiv.org/abs/2411.16003)|null|大型语言模型（LLMs）标志着人工智能（AI）领域的变革时代。然而，LLMs所涉及的数据和参数规模巨大，需要高要求的计算和内存资源，这限制了它们对更广泛用户和研究者的可及性。本文介绍了一种有效的方法，可以提升LLM推理的操作效率和成本效益。通过利用基于transformer的联邦学习（FL）与模型并行分布式训练，我们的模型能够高效地在参与者网络中分配计算负载和内存需求。这种策略允许用户，尤其是那些资源有限的用户，可以协同训练最先进的LLMs。我们还创新了FL框架中的激励机制，奖励有益的贡献并过滤掉恶意活动，从而保护训练过程的完整性和可靠性。同时，我们利用内存层次策略和权重矩阵的奇异值分解（SVD）进一步提升了计算和内存效率。我们的结果，通过公式分析和数值计算得出，显著优化了资源使用，并使先进LLMs的访问权民主化，确保广泛的用户既能参与也能从中受益。|\n",
        "2411.15982": "|**2024-11-24**|**Anda: Unlocking Efficient LLM Inference with a Variable-Length Grouped Activation Data Format**|Chao Fang et.al.|[2411.15982](http://arxiv.org/abs/2411.15982)|null|广泛应用的仅权重量化的大型语言模型（LLM），利用低比特整数（INT）权重并保留浮点（FP）激活，在减少存储需求的同时保持了准确性。然而，这将能耗和延迟瓶颈转向了与昂贵的内存访问和计算相关的FP激活。现有的LLM加速器主要关注计算优化，忽略了联合优化FP计算和数据移动的潜力，尤其是在LLM推理中的主导FP-INT GeMM操作。为了解决这些挑战，我们研究了各种LLM模块中激活精度的敏感性及其对整体模型准确性的影响。基于我们的发现，我们首先提出了Anda数据类型：一种具有组共享指数位和动态尾数位分配的自适应数据格式。其次，我们开发了一种迭代的训练后自适应精度搜索算法，优化不同LLM模块的位宽，以平衡模型准确性、能耗和推理速度。最后，提出了一系列硬件优化技术，以最大限度地发挥Anda格式的优势。这包括基于位面的数据组织方案、具有位串计算功能的Anda增强处理单元以及运行时位面Anda压缩器，以同时优化存储、计算和内存占用。我们在FPINT GeMM操作上的评估表明，与GPU类似的FP-FP基准相比，Anda在包括OPT、LLaMA和LLaMA-2系列在内的流行LLM上平均实现了2.4倍的加速、4.0倍的面积效率提升和3.1倍的能耗效率提升。Anda在各种应用场景、精度要求和系统性能方面表现出强大的适应性，使得在广泛的部署场景中实现高效的LLM推理成为可能。|\n",
        "2411.17741": "|**2024-11-24**|**Chameleon: Adaptive Caching and Scheduling for Many-Adapter LLM Inference Environments**|Nikoleta Iliakopoulou et.al.|[2411.17741](http://arxiv.org/abs/2411.17741)|null|随着大型语言模型（LLMs）的广泛应用，其部署数量呈指数级增长，对推理集群提出了巨大需求。这些集群必须处理针对不同LLM下游任务的大量并发查询。为了处理具有大量LLM参数的多任务设置，方法如低秩自适应（LoRA）允许针对特定任务进行微调，同时跨任务共享大部分基础LLM模型。因此，它们允许以最小的内存需求并发处理任务。然而，现有的LLM服务系统存在效率低下的问题：它们忽视了工作负载异构性，由于频繁的适配器加载而施加了高链路带宽，以及在调度器中存在头阻塞问题。为了解决这些挑战，我们提出了Chameleon，这是一个针对多个适配器环境优化的新型LLM服务系统，它依赖于两个核心思想：适配器缓存和适配器感知调度。首先，Chameleon在GPU内存中缓存流行的适配器，最小化适配器加载时间。重要的是，它使用原本闲置的GPU内存，避免了额外的内存成本。其次，Chameleon使用非抢占式多队列调度，以高效地处理工作负载异构性。通过这种方式，Chameleon同时防止了头阻塞和饥饿现象。我们在最先进的LLM服务平台之上实现了Chameleon，并使用真实世界的生产跟踪和开源LLM对其进行了评估。在高负载下，Chameleon将P99和P50的TTFT延迟分别降低了80.7%和48.1%，同时与最先进的基线相比，提高了1.5倍的吞吐量。|\n",
        "2411.15715": "|**2024-11-24**|**Task Scheduling for Efficient Inference of Large Language Models on Single Moderate GPU Systems**|Wenxiang Lin et.al.|[2411.15715](http://arxiv.org/abs/2411.15715)|null|大型语言模型（LLMs）因其庞大的模型尺寸而闻名，对计算资源和内存需求极高，导致在中等GPU系统上的推理效率低下。量化或剪枝等技术可以缩小模型尺寸，但通常会损害准确度，使其不适合实际应用。在这项工作中，我们介绍了\\modelname{}，这是一个高性能的推理引擎，旨在加快LLMs的推理速度，同时不降低模型精度。\\modelname{}采用了三种创新方法来提高推理效率：1）模型分区，允许跨CPU计算、GPU计算和CPU-GPU通信异步处理任务，2）自适应分区算法，以优化CPU、GPU和PCIe通信能力的利用，3）令牌分配策略，用于处理LLMs推理过程中的各种提示和生成任务。我们使用Mixtral、LLaMA-2、Qwen和PhiMoE等LLMs，在具有不同CPU和GPU的三个测试环境中进行了综合实验。实验结果表明，\\modelname{}在解码速度上比$1.11\\times$到$1.80\\times$更快，在预填充速度上比$1.69\\times$到$6.33\\times$更快，与最先进的解决方案llama.cpp和Fiddler相比，整体速度提高了$1.25\\times$到$2.04\\times$。|\n",
        "2411.19542": "|**2024-11-29**|**A dynamic parallel method for performance optimization on hybrid CPUs**|Luo Yu et.al.|[2411.19542](http://arxiv.org/abs/2411.19542)|null|AIPC概念越来越受欢迎，越来越多的混合CPU将在客户端设备上运行AI模型。然而，当前的AI推理框架忽略了混合CPU硬件能力的失衡，导致推理性能低下。为了解决这个问题，我们引入了一种针对混合CPU的动态并行方法，该方法通过在并行工作开始之前平衡混合CPU每个核心的工作负载，显著提高了大型语言模型（LLM）的推理性能。这种方法使Neural Speed能够在两个混合英特尔CPU上实现超过90%（平均）的内存带宽。|\n",
        "2411.19146": "|**2024-11-28**|**Puzzle: Distillation-Based NAS for Inference-Optimized LLMs**|Akhiad Bercovich et.al.|[2411.19146](http://arxiv.org/abs/2411.19146)|null|大型语言模型（LLMs）展示了惊人的能力，但它们的采用受到推理过程中高计算成本的限制。虽然增加参数数量可以提高准确性，但它也拉大了最先进的能力与实际部署之间的差距。我们提出了Puzzle框架，该框架在特定硬件上加速LLMs的推理，同时保持其能力。通过前所未有的规模创新性地应用神经架构搜索（NAS），Puzzle在硬件约束下系统地优化了具有数十亿参数的模型。我们的方法利用块状局部知识蒸馏（BLD）进行并行架构探索，并采用混合整数规划进行精确的约束优化。我们通过Llama-3.1-Nemotron-51B-Instruct（Nemotron-51B）这一公开可用的模型展示了我们框架的实际影响，该模型由Llama-3.1-70B-Instruct衍生而来。Nemotron-51B实现了2.17倍的推理吞吐量加速，可以在单个NVIDIA H100 GPU上运行，同时保留了原始模型98.4%的能力。Nemotron-51B是目前能够以大批次在单个GPU上进行推理的最准确的语言模型。值得注意的是，这种转变只需要45B个训练令牌，而它所衍生的70B模型则需要超过15T个令牌。这建立了一个新的范式，即强大的模型可以通过仅牺牲微小能力来优化高效的部署，这表明推理性能而非参数数量本身应指导模型选择。随着Nemotron-51B的发布和Puzzle框架的介绍，我们为从业者提供了以显著降低的计算成本访问最先进语言建模能力的即时途径。|\n",
        "2412.02252": "|**2024-12-03**|**Compressing KV Cache for Long-Context LLM Inference with Inter-Layer Attention Similarity**|Da Ma et.al.|[2412.02252](http://arxiv.org/abs/2412.02252)|null|随着大型语言模型（LLMs）如GPT和LLaMA系列中上下文窗口大小的增加，它们处理复杂、长文本任务的能力得到了提升，但这也带来了推理效率的降低，特别是在内存和计算复杂度方面。现有方法，包括选择性保留标记和基于窗口的注意力机制，虽然提高了效率，但可能会丢弃对后续文本生成重要性的标记。在本文中，我们提出了一种通过减少不太重要的标记的内存和计算负载来提高LLM效率而不丢失标记的方法。我们解决了两个挑战：1）研究上下文中重要标记的分布，发现最近标记比上下文中的远端标记更重要，2）通过跨层共享注意力分数来优化远端标记的资源。实验表明，我们的方法在不影响性能的情况下节省了35%的KV缓存。|\n",
        "2412.01447": "|**2024-12-02**|**PLD+: Accelerating LLM inference by leveraging Language Model Artifacts**|Shwetha Somasundaram et.al.|[2412.01447](http://arxiv.org/abs/2412.01447)|null|为了减少与自回归型大型语言模型推理相关的延迟，推测解码作为一种新的解码范式应运而生，它并行地草拟和验证未来的标记。然而，推测解码的实际部署受到其对额外计算资源和微调的需求的限制，这限制了其即插即用性。为了解决这些挑战，我们提出了PLD+，一套旨在加速大型语言模型推理过程的新算法，尤其是针对输入引导型任务。这些任务包括代码编辑、文本编辑、摘要等，通常具有与输入有大量重叠的输出——这是PLD+设计时要利用的属性。PLD+还利用推理过程中生成的工件（注意力机制和隐藏状态）来加速推理速度。我们在五个输入引导型任务上测试了我们的方法，并通过广泛的实验发现，PLD+优于所有无需调优的方法。在贪婪设置中，它甚至在某些任务上超过了最先进的调优依赖方法EAGLE（平均加速率提高2.31）。我们的方法无需调优，不要求任何额外计算，并且可以轻松用于加速任何大型语言模型的推理。|\n",
        "2412.01380": "|**2024-12-02**|**Efficient LLM Inference using Dynamic Input Pruning and Cache-Aware Masking**|Marco Federici et.al.|[2412.01380](http://arxiv.org/abs/2412.01380)|null|随着移动设备提供的计算能力不断增强，DRAM带宽的提升速度却相对较慢。这对大型语言模型（LLM）的token生成来说是个不幸的事，因为其高度依赖于内存。先前的研究提出利用ReLU激活的LLM中的自然动态激活稀疏性来减少每个token的有效DRAM带宽。然而，最新的LLM使用SwiGLU而非ReLU，这导致几乎没有固有的稀疏性。虽然SwiGLU的激活可以根据幅度进行剪枝，但产生的稀疏模式难以预测，使得先前的方法失效。为了解决这个问题，我们的工作引入了动态输入剪枝（DIP）：一种无预测器的动态稀疏化方法，它通过最小的微调来保留准确性。DIP还可以使用轻量级的LoRA适配器来恢复在稀疏化过程中损失的一些性能。最后，我们描述了一种新的缓存感知掩码策略，它考虑缓存状态和激活幅度以进一步提高缓存命中率，从而提高移动设备上LLM的token速率。在DIP中，与模拟硬件设置中的其他方法相比，它在准确性、内存和吞吐量之间的权衡方面表现更优。在Phi-3-Medium上，DIP实现了内存减少46%、吞吐量增加40%，同时困惑度损失小于0.1。|\n",
        "2412.01129": "|**2024-12-02**|**RILQ: Rank-Insensitive LoRA-based Quantization Error Compensation for Boosting 2-bit Large Language Model Accuracy**|Geonho Lee et.al.|[2412.01129](http://arxiv.org/abs/2412.01129)|null|低秩自适应（LoRA）已成为参数高效的LLM微调的主要方法，基于LoRA的量化误差补偿（LQEC）也作为一种强大的工具，用于恢复压缩LLM的准确性。然而，LQEC在4位以下的情况下表现不佳，但此前没有对这一限制进行过研究。我们提出了RILQ（基于低秩自适应的秩无关量化误差补偿）来理解基本限制并提升2位LLM的准确性。基于对模型激活差异损失秩无关性质的分析，RILQ使用这种损失在层间协同调整适配器，使得低秩适配器能够实现鲁棒的误差补偿。在LLaMA-2和LLaMA-3上的评估表明，RILQ在各种最先进的量化器上对2位量化推理的一致性改进，以及在特定任务微调中的准确性提升。RILQ保持了与现有LoRA方法相当的计算效率，使得适配器合并权重量化LLM推理的准确性显著提升，成为提升2位LLM性能的有前途的方法。|\n",
        "2412.01042": "|**2024-12-02**|**TruncFormer: Private LLM Inference Using Only Truncations**|Patrick Yubeaton et.al.|[2412.01042](http://arxiv.org/abs/2412.01042)|null|私有推理（PI）在用户数据与专有机器学习模型（如LLMs）交互时，保证了用户数据的隐私性。然而，由于LLMs中存在的非线性函数带来的巨大延迟成本，PI在实践中变得难以处理。现有工作主要关注通过近似来提高特定LLM非线性（如Softmax或GeLU）的延迟。然而，随着新的LLM架构的引入，新的非线性类型也在不断出现，这导致了PI研究人员在优化最新非线性函数方面的不断追赶。我们引入了TruncFormer，这是一个将任何LLM转换为PI明文仿真的框架。我们的框架利用了LLM中的非线性函数是可微分的，并且可以用一系列加法、乘法和截断来精确近似的事实。此外，我们将加/乘操作与截断操作解耦，并根据给定的字段大小和输入表示大小静态确定应在哪里插入截断。这导致在现有加密协议中，每进行一次乘法操作后都需要截断的情况下，延迟得到了改进。我们开源了我们的代码以供社区使用。|\n",
        "2412.03594": "|**2024-11-29**|**BatchLLM: Optimizing Large Batched LLM Inference with Global Prefix Sharing and Throughput-oriented Token Batching**|Zhen Zheng et.al.|[2412.03594](http://arxiv.org/abs/2412.03594)|null|许多大型语言模型（LLM）的任务在大批量或离线情况下执行，其性能指标为吞吐量。这些任务通常具有前缀共享的特征，即不同的提示输入可以部分显示共同的prefix。然而，现有的LLM推理引擎往往优化流式请求，在支持具有前缀共享特性的大批量任务方面存在局限性。现有解决方案使用基于LRU的缓存来重用共同前缀的KV上下文。即将被重用的KV上下文可能会因隐式缓存管理而被提前移除。即使没有被移除，共享的KV上下文的生命周期也会因为共享相同上下文的请求没有被一起调度而延长，导致更大的内存使用。这些以流为方向的系统按照先来先服务的顺序调度请求。结果，解码步骤比例较大的请求可能调度得太晚，无法与预填充块混合，从而提高硬件利用率。此外，基于令牌和请求数量的批量处理可能会限制令牌批量的大小，这会防止GPU在主要由解码令牌控制的迭代中饱和。我们提出了BatchLLM来解决这个问题。BatchLLM显式地识别全局的共同prefix。具有相同prefix的请求将被一起调度，以最佳方式重用KV上下文，这也有助于缩短共同KV内存的生命周期。BatchLLM重新排序请求，优先调度解码步骤比例较大的请求，以便更好地将解码令牌与后续预填充块混合，并采用以内存为中心的令牌批量处理来扩大令牌批量大小，这有助于提高GPU利用率。广泛的评估表明，在一系列微基准测试和两个典型的行业工作负载上，BatchLLM的性能优于vLLM 1.1倍到2倍。|\n",
        "2412.04788": "|**2024-12-06**|**GUIDE: A Global Unified Inference Engine for Deploying Large Language Models in Heterogeneous Environments**|Yanyu Chen et.al.|[2412.04788](http://arxiv.org/abs/2412.04788)|null|在现实场景中高效部署大型语言模型（LLMs）仍然是一个关键挑战，主要是因为硬件异构性、推理框架的限制和工作负载的复杂性。这些挑战通常会导致内存利用效率低下、延迟波动以及吞吐量不高效，从而阻碍LLMs的有效部署，尤其是对于非专业人士。通过广泛的实验，我们确定了关键的性能瓶颈，包括内存利用率的突然下降、随着批量大小变化的延迟波动以及多GPU配置中的不效率。这些洞察揭示了一个庞大的优化空间，它由硬件、框架和工作负载参数之间复杂的相互作用所塑造。这强调了优化LLM推理的系统性方法的需求，推动了我们的框架GUIDE的设计。GUIDE利用动态建模和基于仿真的优化来应对这些问题，在批处理延迟、TTFT和解码吞吐量等关键指标上实现了25%到55%的预测误差。通过有效地弥合理论性能与实际部署之间的差距，我们的框架使从业者，特别是非专业人士，能够做出数据驱动的决策，以低成本释放LLMs在异构环境中的全部潜力。|\n",
        "2412.04504": "|**2024-12-03**|**Multi-Bin Batching for Increasing LLM Inference Throughput**|Ozgur Guldogan et.al.|[2412.04504](http://arxiv.org/abs/2412.04504)|null|随着大型语言模型（LLMs）因其多样化的能力而越来越受欢迎，提高其推理系统的效率变得越来越关键。在服务器（例如GPU）上调度推理作业时，批量处理LLM请求是一个关键步骤，它使得系统可以通过并行处理多个请求来最大化吞吐量。然而，请求的生成长度往往不同，这导致资源利用率低下，因为硬件必须在批处理中等待最长运行的请求完成才能进入下一个批次。我们从排队论的角度形式化这个问题，并旨在设计一个吞吐量最优的控制策略。我们提出了多箱批量处理，这是一种简单而有效的方法，可以将具有相似（预测）执行时间的请求分组到预定的箱中，从而可以证明地提高LLM推理吞吐量。通过结合理论分析和实验，包括现实世界中的LLM推理场景，我们证明了与标准批量处理方法相比，显著提高了吞吐量。|\n",
        "2412.06198": "|**2024-12-09**|**SparseAccelerate: Efficient Long-Context Inference for Mid-Range GPUs**|James Vo et.al.|[2412.06198](http://arxiv.org/abs/2412.06198)|null|随着大型语言模型（LLMs）扩展到更长的上下文窗口，注意力机制的计算成本，传统上与输入长度呈二次方增长，对实时和内存受限的部署构成了一个关键挑战。现有的稀疏注意力技术试图降低这种复杂性，但它们通常会产生显著的额外开销或降低精度，使得它们在中等硬件上的大上下文应用中不太实用。在本文中，我们介绍了SparseAccelerate，这是一种动态稀疏注意力方法，它根据输入特征调整其稀疏模式，有效地降低了注意力复杂性的曲线。我们的方法对于从16K个标记开始的长输入长度有效，并且在双NVIDIA A5000 GPU（每个24GB）上可以高效地扩展到128K个标记。实验结果表明，在32K个标记时，SparseAccelerate将首次标记延迟（TTFT）降低了高达1.04倍，同时还提供了大量的内存节省。这些改进为内存密集型应用和长上下文任务带来了实际效益，这些应用和任务在标准注意力机制下之前是无法实现的。除了降低延迟之外，SparseAccelerate还从根本上改变了扩展趋势，显示出相对于上下文长度，竞争方法中最低的TTFT增长梯度。在多个基准测试上的持续评估证实了其可扩展性，将SparseAccelerate定位为向在可访问硬件上实现高效、实时和大上下文LLM推理的关键进步。|\n",
        "2412.05896": "|**2024-12-08**|**XKV: Personalized KV Cache Memory Reduction for Long-Context LLM Inference**|Weizhuo Li et.al.|[2412.05896](http://arxiv.org/abs/2412.05896)|null|近期，生成式大型语言模型（LLM）在众多应用中取得了显著的成果。值得注意的是，其推理过程是逐个生成输出标记，导致许多冗余计算。广泛使用的KV-Cache框架在时间和空间复杂度之间做出了妥协。然而，缓存数据产生了日益增长的内存需求，这可能会迅速耗尽现代加速器（如GPU）有限的内存容量，尤其是在长上下文推理任务中。现有研究通过驱逐对推理精度影响较小的部分缓存数据来减少内存消耗。但由于不同LLM网络层之间静态的缓存分配，实际效果远未达到理想状态。本文观察到，特定层的缓存数据对精度的影响差异很大。我们量化了这种差异，并通过实验和理论验证了这一点。据此，我们对缓存大小进行正式分析，并表明以个性化方式为每个层定制缓存大小可以显著减少内存消耗，同时仍能提供可比的精度。我们将缓存分配模拟为组合优化问题，并给出全局最优解。特别是，我们设计了一种基于轻量级LLM模型的小型采样推理方法，以便快速捕捉差异并将其输入个性化算法。在真实世界数据集上的大量实验表明，我们的提议可以将KV缓存内存消耗平均降低61.6%，计算效率提高2.1倍，并通过量增加至5.5倍。|\n",
        "2412.07017": "|**2024-12-09**|**Asynchronous LLM Function Calling**|In Gim et.al.|[2412.07017](http://arxiv.org/abs/2412.07017)|null|大型语言模型（LLM）通过函数调用与外部工具和数据源进行接口交互。然而，当前LLM函数调用的方法本质上都是同步的，每次调用都会阻塞LLM的推理，限制了LLM的操作和并发函数执行。在这项工作中，我们提出了AsyncLM，这是一种异步LLM函数调用的系统。AsyncLM通过允许LLM并发生成和执行函数调用，提高了LLM的操作效率。AsyncLM不是等待每个调用的完成，而是引入了一种中断机制，在函数调用返回时异步通知正在进行的LLM。我们设计了一种用于函数调用和中断的上下文协议，提供了微调策略以适应中断语义，并在LLM推理过程中高效地实现了这些机制。我们展示了AsyncLM可以将端到端任务完成延迟从1.6倍到5.4倍减少，与在伯克利函数调用排行榜（BFCL）上的一系列基准任务中的同步函数调用相比。此外，我们还讨论了如何扩展中断机制以实现新颖的人-LLM或LLM-LLM交互。|\n",
        "2412.08585": "|**2024-12-11**|**TURBOATTENTION: Efficient Attention Approximation For High Throughputs LLMs**|Hao Kang et.al.|[2412.08585](http://arxiv.org/abs/2412.08585)|null|大型语言模型（LLM）的推理需要大量的计算和内存，尤其是在关键的关注机制方面。虽然量化技术和加速算法，如FlashAttention，提高了整体推理的效率，但它们解决了问题的不同方面：量化专注于权重-激活操作，而FlashAttention提高了执行效率但需要高精度格式。最近的关键值（KV）缓存量化减少了内存带宽，但仍然需要浮点数反量化进行关注操作。我们提出了TurboAttention，这是一种综合方法，旨在同时解决内存和计算效率，以实现关注操作的量化执行。我们的解决方案引入了两个关键创新：FlashQ，一种按头部进行关注量化的技术，它既能够压缩KV缓存，又能够执行激活-激活乘法的量化执行；以及基于稀疏度的Softmax近似（SAS），它消除了在关注操作中的指数运算时对FP32反量化的需求。实验结果表明，TurboAttention在关注操作上实现了1.2-1.8倍的加速，将KV缓存大小减少了超过4.4倍，并且与FP16基线相比，在最大吞吐量上实现了高达2.37倍的提升，同时在各种数据集和模型上优于现有的量化和压缩技术。|\n",
        "2412.08281": "|**2024-12-11**|**Lachesis: Predicting LLM Inference Accuracy using Structural Properties of Reasoning Paths**|Naryeong Kim et.al.|[2412.08281](http://arxiv.org/abs/2412.08281)|null|大型语言模型越来越多地被用于构建执行更复杂任务的智能体。随着LLM通过更长的交互进行更复杂的推理，自洽性，即从多个独立推理的样本中进行采样和边缘化的答案更有可能正确的观点，作为一种简单的验证技术，已经受到了广泛关注。本文旨在通过从推理路径样本的性质预测使用自洽性获得的答案的正确性来实证验证这一直观假设。我们引入了Lachesis，一个基于自洽性的LLM推理的预测模型，并使用AutoFL作为目标技术进行实证评估，AutoFL是一种最近提出的基于LLM的错误定位技术，它使用了自洽性。Lachesis使用特别设计的推理路径表示将收集到的推理路径从AutoFL转换，并训练LSTM和GCN模型以预测一组给定的推理路径是否会导致正确的答案。结果表明，Lachesis可以以高达0.8136的精确度预测答案的正确性，突出了训练一个能够允许提前终止不太可能成功的推理的预测模型的可能性。|\n",
        "2412.08237": "|**2024-12-11**|**TouchTTS: An Embarrassingly Simple TTS Framework that Everyone Can Touch**|Xingchen Song et.al.|[2412.08237](http://arxiv.org/abs/2412.08237)|null|众所周知，基于LLM的系统对数据有很高的需求。近年来，基于LLM的TTS工作通常采用复杂的数据处理流程来获取高质量的训练数据。这些复杂的流程在每一阶段（例如，语音降噪、语音增强、说话人分割和标点模型）都需要优秀的模型，而这些模型本身又需要高质量的训练数据，很少被开源。即使使用最先进的模型，仍然存在一些问题，如背景噪声去除不完整和标点与实际语音停顿的错位。此外，严格的过滤策略通常只保留原始数据的10-30%，这大大阻碍了数据扩展的努力。在这项工作中，我们利用一个噪声鲁棒的音频标记器（S3Tokenizer）设计了一个简化但有效的TTS数据处理流程，在保持数据质量的同时，大幅降低了数据获取成本，实现了超过50%的数据保留率。除了数据扩展的挑战之外，基于LLM的TTS系统与传统方法相比，部署成本也更高。当前的系统通常仅使用LLM进行文本到标记的生成，而对于标记到波形生成则需要单独的模型（例如，流匹配模型），这些模型不能直接由LLM推理引擎执行，从而进一步复杂化了部署。为了解决这些挑战，我们在LLM和流组件中消除了冗余模块，用LLM架构替换了流模型主干。在此基础上，我们提出了一种统一的架构，用于流和非流推理，显著降低了部署成本。最后，我们探讨了利用同一数据训练TTS和ASR任务的可行性，这得益于简化后的流程和S3Tokenizer，后者降低了TTS训练数据的质量要求。|\n"
    },
    "train": {
        "2411.17691": "|**2024-11-26**|**Low-Bit Quantization Favors Undertrained LLMs: Scaling Laws for Quantized LLMs with 100T Training Tokens**|Xu Ouyang et.al.|[2411.17691](http://arxiv.org/abs/2411.17691)|null|我们通过观察发现，在应用低比特量化时，规模较大或训练词数较少的语言模型（LLMs）的量化诱导退化（QiD）较小，而训练词数较多的小型模型则会遭受显著的QiD。为了更深入地了解这一趋势，我们在一个受控环境下研究了1500多个不同规模和训练水平（未训练或完全训练）的量化LLMs检查点，从而推导出QiD与训练词数、模型大小和比特宽度等因素之间的关系定律。利用这些定律，我们提出了一种新视角：可以使用QiD来衡量LLMs的训练水平，并确定不同规模LLMs完全训练所需的训练词数。此外，我们使用这些定律来预测使用100万亿个训练词训练的不同规模LLMs的量化性能。我们的预测表明，未来预期使用超过100万亿个训练词训练的低比特量化模型性能可能并不理想。这为未来的低比特量化提出了潜在的挑战，并突出了在评估低比特量化研究时需要关注模型训练水平。为了促进对此问题的未来研究，我们将本次工作中使用的1500多个量化检查点发布在https://huggingface.co/Xu-Ouyang上。|\n",
        "2411.17679": "|**2024-11-26**|**Enhancing Character-Level Understanding in LLMs through Token Internal Structure Learning**|Zhu Xu et.al.|[2411.17679](http://arxiv.org/abs/2411.17679)|**[link](https://github.com/FloatFrank/TIPA)**|**将文本分割成标记的编码技术，如字节对编码（BPE）和字节级BPE（BBPE），通过将文本分割成标记，显著提高了大型语言模型（LLMs）的计算效率和词汇表示稳定性。然而，这种分割通常掩盖了标记内部的字符结构和序列，导致模型在训练期间无法完全学习这些复杂的细节。因此，LLMs在理解标记内部的字符组成和位置关系方面存在困难，尤其是在使用有限数据的下游任务中进行微调时。在本文中，我们引入了一种名为标记内部位置感知（TIPA）的新方法，通过使用分词器自己的词汇进行反向字符预测任务来训练模型，从而增强LLMs对内部标记结构的理解。这种方法使模型能够有效地学习和泛化字符位置和内部结构。实验结果表明，使用TIPA训练的LLMs在预测标记级别的字符位置方面优于基线模型。此外，当应用于中文拼写纠正（CSC）的下游任务时，TIPA不仅加速了模型收敛，而且显著提高了任务性能。**|\n",
        "2411.17284": "|**2024-11-26**|**Using Large Language Models for Expert Prior Elicitation in Predictive Modelling**|Alexander Capstick et.al.|[2411.17284](http://arxiv.org/abs/2411.17284)|**[link](https://github.com/alexcapstick/llm-elicited-priors)**|**大型语言模型（LLMs）通过训练不同领域的数据，有效地获取了广泛的信息。然而，它们的计算复杂度、成本和缺乏透明度阻碍了它们在特定任务中的直接应用。在临床研究等领域的预测模型中，获取专家注释或先验知识通常是昂贵且耗时的。本研究提出使用LLMs来获取预测模型的专家先验分布。这种方法也为情境学习提供了一种替代方案，其中语言模型直接负责做出预测。我们比较了LLM获取的先验和无关先验，评估了LLM是否真实地生成了参数分布，并提出了情境学习和先验获取的模型选择策略。我们的研究发现，与无关先验相比，在数据量少的情况下，LLM获取的先验参数分布显著降低了预测误差。应用于临床问题，这意味着所需的生物样本更少，降低了成本和资源。先验获取也始终优于情境学习，且成本更低，因此在我们的环境中成为一种更受欢迎的替代方案。我们展示了该方法在各种用例中的实用性，包括临床应用。在感染预测中，使用LLM获取的先验，在研究中提前200天，以相同的准确度减少了55%所需的标签数量。**|\n",
        "2411.17116": "|**2024-11-26**|**Star Attention: Efficient LLM Inference over Long Sequences**|Shantanu Acharya et.al.|[2411.17116](http://arxiv.org/abs/2411.17116)|**[link](https://github.com/NVIDIA/Star-Attention)**|**由于自注意力机制的二次复杂度，基于Transformer的大型语言模型（LLM）在长序列上的推理既昂贵又缓慢。我们引入了星形注意力，这是一种两阶段块稀疏逼近，通过在多个主机之间分散注意力来提高计算效率，同时最小化通信开销。在第一阶段，通过主机间的块局部注意力并行处理上下文。在第二阶段，查询和响应标记通过序列全局注意力关注所有先前缓存的标记。星形注意力可以无缝集成到大多数使用全局注意力训练的基于Transformer的LLM中，通过减少内存需求和提高推理速度至多11倍，同时保持95-100%的准确率。**|\n",
        "2411.16353": "|**2024-11-25**|**The Two-Hop Curse: LLMs trained on A->B, B->C fail to learn A-->C**|Mikita Balesni et.al.|[2411.16353](http://arxiv.org/abs/2411.16353)|null|在论文摘要中，作者首先指出大型语言模型（LLMs）在采用思维链（CoT）进行多跳推理（如“Imagine表演者的配偶是谁？”）时表现出色，但在被迫进行内部推理（不使用CoT）时则表现不佳。作者提到之前关于这一差距大小和性质的研究产生了不一致的证据。在这篇论文中，作者介绍了一种控制环境，用于研究LLMs中的两跳推理，其中超出随机水平的性能构成了潜在推理不可否认的证据。作者在虚构事实上进行微调LLMs（包括Llama 3 8B Instruct和GPT-4o），并确认它们可以推广到使用CoT回答有关它们的两跳问题。作者发现，当事实在训练过程中或提示中一起出现时，模型可以进行潜在推理。然而，出乎意料的是，当学习的事实仅出现在不同的文档中时，模型在两跳推理上完全失败，达到了随机水平准确性和测试损失。作者将这种完全无法组合单独学习的事实称为“两跳诅咒”。此外，作者在真实事实上评估了9个前沿LLMs，发现模型在超过一半的问题类别上完全无法进行无CoT的两跳推理，而在大多数类别上仍然部分成功使用CoT。这些结果表明，LLMs缺乏一种独立于问题类型的一般能力来进行潜在的跨跳推理。|\n",
        "2411.15871": "|**2024-11-24**|**Hiding Communication Cost in Distributed LLM Training via Micro-batch Co-execution**|Haiquan Wang et.al.|[2411.15871](http://arxiv.org/abs/2411.15871)|null|随着大型语言模型（LLMs）的发展，大规模分布式训练变得必要。然而，高度优化的框架由于通信量大，在模型FLOPS利用率上仍然有显著的损失（通常低于50%）。同时，我们的全面分析显示，计算和通信密集型操作的重叠性很好。本文介绍了一种名为DHelix的新型微观结构，它受到DNA结构的启发，显著提高了LLM训练的效率。DHelix设计的核心是链式交错（SI），它将训练微批次连续流通过GPU视为两条链。DHelix并置两条链的前向和后向传递，并通过对称调度来自相对链的操作进行系统优化，这得益于操作级别的重叠分析结果和基于动态规划的搜索算法。同时，DHelix允许两条链共享模型状态和激活数据的空间，有效地容纳了额外内存空间低于3%的两个微批次。DHelix无缝集成到所有现有数据/模型并行形式，其中最具有挑战性的是管道并行，得益于其独特的模型折叠设计，形成了W型管道。我们使用流行的Llama和GPT密集模型，以及Phi混合专家（MoE）模型，在3个GPU集群（A40、A800和H100）上评估了DHelix的训练。结果显示，它在64-A40和64-A800集群上分别实现了12-40%（最高达到58%MFU）和2-29%（最高达到71%MFU）的提高，显著优于现有方法。在H100集群上，虽然更快的网络降低了DHelix的利润空间，但它使得跨节点张量并行成为可能，这在由于通信成本而目前难以实现的情况下是一种实践。|\n",
        "2411.15484": "|**2024-11-23**|**Seed-Free Synthetic Data Generation Framework for Instruction-Tuning LLMs: A Case Study in Thai**|Parinthapat Pengpun et.al.|[2411.15484](http://arxiv.org/abs/2411.15484)|**[link](https://github.com/parinzee/seed-free-synthetic-instruct)**|**我们提出了一种针对低资源语言（特别是泰语）的大语言模型（LLM）指令微调的合成数据方法，以数据高效的方式实现。我们确定了三个有助于指令微调数据集有效性的关键属性：流畅性、多样性和文化背景。我们提出了一种无需种子数据框架，用于生成包含这些基本属性的合成指令微调数据。我们的框架使用LLM生成多样化主题，从维基百科中检索相关上下文，并为各种任务（如问答、摘要和对话）创建指令。实验结果表明，我们的最佳表现合成数据集，结合了这三个关键属性，在仅使用5,000条指令的情况下，与在数万条指令上训练的顶尖泰语LLM相比，实现了具有竞争力的性能。我们的代码和数据集可在https://github.com/parinzee/seed-free-synthetic-instruct上公开获取。**|\n",
        "2411.14500": "|**2024-11-21**|**Exploring Accuracy-Fairness Trade-off in Large Language Models**|Qingquan Zhang et.al.|[2411.14500](http://arxiv.org/abs/2411.14500)|null|大型语言模型（LLMs）在人工智能领域取得了显著进展，展示了它们与人类互动和通过信息传播影响人类认知的能力。然而，最近的研究揭示了这些LLMs内含的偏见问题，这成为一个需要关注的重大问题。在我们的研究中，我们深入研究在LLMs增强过程中，如何协调准确性和公平性的复杂挑战。虽然提高准确性确实可以提升LLMs的整体性能，但这往往是以牺牲公平性为代价的。过度强调一个指标的优化必然会导致另一个指标的显著下降。这强调了在设计优化LLMs阶段时考虑多个因素的重要性。因此，我们主张将LLMs的训练过程重新定义为多目标学习任务。我们的研究揭示了多目标进化学习（MOEL）方法在应对这一挑战方面具有前景。我们的MOEL框架能够同时优化准确性和公平性指标，从而产生一组帕累托最优的LLMs。总之，我们的研究为LLMs中准确性和公平性之间的微妙平衡提供了宝贵的见解，这对于它们在现实世界中的应用越来越重要。通过利用MOEL，我们展示了一条通往更公平和更有效的AI技术的可行途径。|\n",
        "2411.13738": "|**2024-11-20**|**Assessing Gender Bias in LLMs: Comparing LLM Outputs with Human Perceptions and Official Statistics**|Tetiana Bas et.al.|[2411.13738](http://arxiv.org/abs/2411.13738)|**[link](https://github.com/tetianabas/llm_biases)**|**本研究通过比较大型语言模型（LLMs）对性别的感知与人类受访者、美国劳工统计局数据和50%无偏见基准的性别感知，来探讨LLMs中的性别偏见。我们使用职业数据和特定角色的句子创建了一个新的评估集。与LLMs训练数据中常见的基准不同，我们的集合是全新开发的，防止了数据泄露和测试集污染。我们对五个LLMs进行了测试，以使用单词答案预测每个角色的性别。我们使用Kullback-Leibler（KL）散度来比较模型输出与人类感知、统计数据和50%中性基准之间的差异。所有LLMs都显示出与性别中性的显著偏差，并且更符合统计数据，仍然反映了固有的偏见。**|\n",
        "2411.13055": "|**2024-11-20**|**Hardware Scaling Trends and Diminishing Returns in Large-Scale Distributed Training**|Jared Fernandez et.al.|[2411.13055](http://arxiv.org/abs/2411.13055)|null|近年来，神经网络模型能力的显著提升是由模型规模、训练数据和相应的计算资源扩展驱动的。为了开发现代应用（如大型语言模型）所需的无尽大型网络，模型训练需要在数万台硬件加速器（例如GPU）上分布进行，这要求在大规模计算集群中协调计算和通信。在本工作中，我们证明了仔细考虑硬件配置和并行化策略对于有效（即计算和成本高效）地扩展模型规模、训练数据和总计算量至关重要。我们对大规模LLM训练工作负载在模型规模、硬件配置和分布式并行化策略方面的性能进行了广泛的实证研究。我们证明了：（1）超过一定规模后，某些分布式通信策略带来的开销导致之前被认为次优的并行化策略实际上变得更为可取；（2）即使硬件和并行化策略得到适当优化，增加加速器的总数来扩大大型模型训练也会迅速产生递减回报，这意味着每增加一个单位的功率或GPU时长的边际性能较差。|\n",
        "2412.01928": "|**2024-12-02**|**MALT: Improving Reasoning with Multi-Agent LLM Training**|Sumeet Ramesh Motwani et.al.|[2412.01928](http://arxiv.org/abs/2412.01928)|null|使大型语言模型（LLMs）之间实现有效协作是开发能够解决复杂问题的自主系统的关键步骤。尽管LLMs通常被用作单模型生成器，其中人类对其输出进行批评和改进，但联合训练的协作模型潜力尚未得到充分探索。尽管在多智能体通信和辩论环境中取得了一些有希望的结果，但在训练协同完成任务的模式方面进展甚微。在本文中，我们提出了在推理问题上的“多智能体LLM训练”（MALT）的第一步。我们的方法采用了一个顺序多智能体设置，将异构的LLMs分配了专门的角色：生成器、验证器和改进模型迭代地解决问题。我们提出了一种基于轨迹扩展的合成数据生成过程和一种由联合结果驱动的信用分配策略。这使我们的后训练设置能够利用正负轨迹自主改进每个模型的专业能力，作为联合顺序系统的一部分。我们在MATH、GSM8k和CQA上评估了我们的方法，其中在Llama 3.1 8B模型上进行的MALT实现了相对于相同基线模型的相对改进分别为14.14%、7.12%和9.40%。这证明了在数学和常识推理问题上的多智能体协作能力的一个早期进步。更普遍地说，我们的工作为多智能体LLM训练方法的研究提供了具体方向。|\n",
        "2412.01526": "|**2024-12-02**|**Addressing Data Leakage in HumanEval Using Combinatorial Test Design**|Jeremy S. Bradbury et.al.|[2412.01526](http://arxiv.org/abs/2412.01526)|null|大语言模型（LLM）的使用在许多领域都很普遍，包括软件工程，其中它们已被用于自动化诸如程序生成和测试分类等任务。随着基于LLM的方法持续发展，我们定义清晰且稳健的方法来公平地评估性能变得尤为重要。基准测试是评估LLM解决特定任务能力以及评估LLM不同版本随时间解决任务的一种常见方法。例如，HumanEval基准测试由164个手工制作的任务组成，已成为评估基于LLM的程序生成的重要工具。然而，使用类似HumanEval的基准测试来公平评估LLM的主要障碍是基准任务和解决方案数据泄露到训练数据集中所导致的数据污染。这一障碍因LLM训练数据的黑盒特性而加剧，这使得甚至难以知道数据泄露是否发生。为了解决数据泄露问题，我们提出了一种新的基准构建方法，该方法将基准测试由模板任务组成，这些模板任务可以通过组合测试设计实例化为新的具体任务。对于同一模板任务的具体任务必须足够不同，以使数据泄露的影响最小化，同时又要足够相似，以便在性能评估方面可以互换。为了评估我们的基准构建方法，我们提出了HumanEval_T，这是一个使用模板任务和组合测试设计构建的替代基准，用于替代HumanEval。|\n",
        "2412.01523": "|**2024-12-02**|**Data-Centric and Heterogeneity-Adaptive Sequence Parallelism for Efficient LLM Training**|Yujie Wang et.al.|[2412.01523](http://arxiv.org/abs/2412.01523)|null|扩展LLM的上下文长度（即最大支持的序列长度）具有极其重要的意义。为了便于LLM的长上下文训练，序列并行化已成为一项关键技术，它将每个输入序列分散到多个设备上，并需要通信来处理序列。本质上，现有的序列并行化方法假设序列长度相同（即所有输入序列长度相等），因此为所有输入序列利用单一的、静态的散列策略。然而，在现实中，LLM训练语料库中的序列长度表现出显著的可变性，通常遵循长尾分布，这导致了工作负载异质性。在本文中，我们表明采用单一的、静态的策略会导致效率低下和资源利用率不足，强调了需要自适应方法来处理序列间异质的工作负载。为了解决这个问题，我们提出了一种异质性自适应序列并行化方法。对于每个训练步骤，我们的方法捕捉序列长度的变化，并根据工作负载特性分配最优的散列策略组合。我们将此问题建模为线性规划优化，并设计了一个高效有效的求解器以找到最优解。此外，我们在一个支持分布式LLM训练自适应并行化的高性能系统中实现了我们的方法。实验结果表明，我们的系统在性能上比最先进的训练框架高出高达1.98倍。|\n",
        "2412.01505": "|**2024-12-02**|**Scaling Law for Language Models Training Considering Batch Size**|Xian Shuai et.al.|[2412.01505](http://arxiv.org/abs/2412.01505)|null|近年来，大型语言模型（LLMs）取得了显著进展，其中规模定律在快速进步中发挥了关键作用。在本文中，我们通过实证研究探讨了关键超参数，即全局批量大小，对LLMs训练过程的影响。我们首先训练了参数量从1.25亿到26亿的多个语言模型，并使用了高达3000亿的高质量标记。通过这些实验，我们建立了一个关于模型大小和训练数据量的基本规模定律。接着，我们考察了批量大小和学习率的变化如何影响这些模型的收敛性和泛化能力。我们的分析得出了两种情况下的批量大小规模定律：一种是固定计算预算，另一种是固定训练数据量。对逐渐增大的模型进行的外推实验验证了我们的预测定律，这为在特定资源约束下优化LLMs训练策略提供了指导。|\n",
        "2412.04747": "|**2024-12-06**|**Code generation and runtime techniques for enabling data-efficient deep learning training on GPUs**|Kun Wu et.al.|[2412.04747](http://arxiv.org/abs/2412.04747)|null|随着深度学习模型规模的扩大，其训练成本显著增加。由于硬件的进步和当前软件堆栈的限制，对数据效率的需求日益上升。数据效率指的是有效隐藏数据访问延迟和避免不必要的 数据移动。主要挑战源于GPU内存带宽与计算吞吐量之间的不断扩大的差异、即将到来的GPU内存容量限制以及PyTorch软件堆栈中的低效，包括缺乏针对特定设备的PCIe传输优化和高层次领域特定抽象。为了有效缓解深度学习训练中的这些数据效率问题，这篇论文分析了代表性深度训练任务中的数据效率，特别是在图神经网络（GNNs）和大型语言模型（LLMs）中。然后，它提出了新的运行时和代码生成技术来缓解这些挑战，并在保持强大的可编程性和互操作性的同时，将这些优化无缝地集成到PyTorch堆栈中。首先，设计了PyTorch-Direct，将GPU中心的PCIe数据传输范式引入PyTorch以用于GNN训练。其次，提出了Hector中间表示（IR）及其代码生成器，以引入特定领域的分层抽象，并系统地解决关系GNN的内存密集型性能挑战。最后，在LLM训练中，吞吐量越来越多地受到GPU内存容量的限制。为了缓解这一问题，设计了并实现了SSDTrain卸载框架。这些贡献共同表明，代码生成和运行时技术可以系统地缓解深度学习训练中的数据管理瓶颈，这些瓶颈源于工作负载的数据密集型特性以及深度学习训练软件堆栈固有的过度简化。|\n",
        "2412.06370": "|**2024-12-09**|**Exploring Memorization and Copyright Violation in Frontier LLMs: A Study of the New York Times v. OpenAI 2023 Lawsuit**|Joshua Freeman et.al.|[2412.06370](http://arxiv.org/abs/2412.06370)|null|近期，由于2023年12月提起的纽约时报诉OpenAI诉讼，前沿LLM中的侵权问题引起了广泛关注。纽约时报声称，GPT-4通过在LLM训练中使用复制文章以及记住输入内容，从而在LLM输出中公开展示，侵犯了其版权。我们的工作旨在衡量OpenAI的LLM相对于其他LLM在输出中展示逐字记忆的倾向，特别是关注新闻文章。我们发现，GPT和Claude模型都使用拒绝训练和输出过滤器来防止记住的文章逐字输出。我们应用了一个基本的提示模板来绕过拒绝训练，并显示OpenAI模型目前比Meta、Mistral和Anthropic的模型更不容易被激发记忆。我们发现，随着模型规模的增加，尤其是超过100亿参数后，它们显示出显著更强的记忆能力。我们的发现对训练有实际意义：必须更加重视在非常大型模型中防止逐字记忆。我们的发现也具有法律意义：在评估OpenAI LLM的相对记忆能力时，我们探讨了纽约时报版权侵权主张的强度和OpenAI的法律辩护，同时强调了生成AI、法律和政策交叉领域的问题。|\n",
        "2412.05342": "|**2024-12-06**|**Multi-Party Supervised Fine-tuning of Language Models for Multi-Party Dialogue Generation**|Xiaoyu Wang et.al.|[2412.05342](http://arxiv.org/abs/2412.05342)|null|大型语言模型（LLM）通常经过微调以参与双方面或双方对话，但它们在多方面对话（MPD）中适应性不佳，这阻碍了它们在包括多人会议、讨论和日常交流等场景中的应用。以往基于LLM的研究主要关注多智能体框架，而它们的基LLM仍然采用成对微调。在本工作中，我们为多方面对话数据集设计了一个LLM的多方面微调框架（MuPaS），并证明这样一个简单的框架可以让LLM有效地与多方面对话风格保持一致。我们还设计了两种训练策略，可以将MuPaS转换为MPD模拟器。大量实验表明，MuPaS可以实现最先进的多人回应，更高的下一位说话者预测精度，更高的人机和自动评估话语质量，甚至能够在分布外场景、主题和角色描述中生成合理的输出。MuPaS框架将LLM的训练与更复杂的多方面应用，如对话生成、虚拟排练或元宇宙，联系起来。|\n",
        "2412.07298": "|**2024-12-10**|**The Rise and Down of Babel Tower: Investigating the Evolution Process of Multilingual Code Large Language Model**|Jiawei Chen et.al.|[2412.07298](http://arxiv.org/abs/2412.07298)|null|大型语言模型（LLMs）展现出显著的多语言能力。然而，这些能力在预训练过程中发展的机制尚不明确。在本文中，我们利用代码LLMs作为实验平台，探讨LLMs在预训练过程中多语言能力的演变。基于我们的观察，我们提出了巴别塔假说，描述了LLMs获得新语言能力的整个过程。在学习过程中，多种语言最初共享一个由主要语言主导的单个知识系统，并逐渐发展出特定于语言的专门知识系统。然后，我们通过识别工作语言和语言转换神经元来追踪LLMs的内部状态，验证上述假说。实验结果表明，LLMs的内部状态变化与我们的巴别塔假说一致。基于这些见解，我们提出了一种构建适用于多语言代码LLMs的优化预训练语料库的新方法，该方法在性能上显著优于在原始语料库上训练的LLMs。所提出的巴别塔假说为设计预训练数据分布以实现LLMs中最佳多语言能力提供了新的见解。|\n",
        "2412.07210": "|**2024-12-10**|**EDiT: A Local-SGD-Based Efficient Distributed Training Method for Large Language Models**|Jialiang Cheng et.al.|[2412.07210](http://arxiv.org/abs/2412.07210)|null|分布式训练方法对于大型语言模型（LLMs）至关重要。然而，现有的分布式训练方法通常存在通信瓶颈、延迟者和弹性有限等问题。为了解决这些问题，我们提出了EDiT，一种创新的、高效的分布式训练方法，它结合了一种定制的本地SGD方法与模型分片技术，以提升大规模训练效率。EDiT在正向传递过程中进行层级参数同步，减少通信和内存开销，并允许计算和通信重叠。此外，EDiT采用伪梯度惩罚策略来抑制损失波动，确保训练稳定性并提升性能。另外，我们引入了A-EDiT，它是EDiT的全异步版本，适用于异构集群。基于EDiT/A-EDiT，我们进行了一系列实验，以验证LLMs的大规模异步训练，并进行了全面的分析。实验结果表明，EDiT/A-EDiT具有卓越的性能，将其确立为在不同计算生态系统中进行分布式LLM训练的稳健解决方案。|\n",
        "2412.07031": "|**2024-12-09**|**Large Language Models: An Applied Econometric Framework**|Jens Ludwig et.al.|[2412.07031](http://arxiv.org/abs/2412.07031)|null|大型语言模型（LLMs）在经济学研究中被用于形成预测、标注文本、模拟人类反应、生成假设，甚至在数据不存在的时空生成数据。尽管这些用途具有创新性，但它们是否有效？我们何时可以忽略LLM内部工作原理，仅仅依赖其输出？我们开发了一个计量经济学框架来回答这个问题。我们的框架区分了两种类型的实证任务。在一种条件下，使用LLM的输出进行预测问题（包括假设生成）是有效的：LLM的训练数据集与研究者的样本之间没有“泄露”。使用LLM的输出进行估计问题以自动化测量某些经济概念（由某些文本或人类受试者表达）需要额外的假设：LLM的输出必须与它们所替代的黄金标准测量一样好。否则，即使LLM的输出高度准确但并非完美，估计也可能存在偏差。我们在金融和政治经济学方面的示例应用中记录了这些条件被违反的程度及其对研究发现的含义。我们还为实证研究人员提供了指导。确保没有训练泄露的唯一方法是使用具有记录的训练数据和发布权重的开源LLM。处理LLM测量误差的唯一方法是收集验证数据并建模误差结构。一个推论是，如果无法满足候选LLM应用的条件，我们强烈建议：不要使用。|\n"
    }
}