## Updated on 2024.12.11
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#agent>agent</a></li>
    <li><a href=#llm>llm</a></li>
    <li><a href=#infer>infer</a></li>
    <li><a href=#train>train</a></li>
  </ol>
</details>

## agent

|Publish Date|Title|Authors|PDF|Code|abstract|
|---|---|---|---|---|---|
|**2024-12-09**|**AutoDCWorkflow: LLM-based Data Cleaning Workflow Auto-Generation and Benchmark**|Lan Li et.al.|[2412.06724](http://arxiv.org/abs/2412.06724)|null|我们研究了大型语言模型（LLMs）在自动生成数据清洗工作流方面的推理能力。为了评估LLMs完成数据清洗任务的能力，我们实现了一个基于LLM的自动数据清洗工作流（AutoDCWorkflow）的管道，通过提示LLMs进行数据清洗操作来修复三种类型的数据质量问题：重复数据、缺失值和不一致的数据格式。给定一个脏表和一个目的（以查询形式表达），此管道生成一个最小化、干净的表，足以满足目的，并使用生成该表的数据清洗工作流。规划过程涉及三个主要的LLM驱动组件：（1）选择目标列：确定与目的相关的目标列集合。（2）检查列质量：评估每个目标列的数据质量并生成数据质量报告作为操作目标。（3）生成操作与参数：根据数据质量报告结果预测下一个操作和参数。此外，我们提出一个数据清洗基准来评估LLM代理自动生成针对不同难度级别数据清洗目的的工作流的能力。该基准包括注释数据集，作为目的、原始表、清洗表、数据清洗工作流和答案集的集合。在我们的实验中，我们评估了三个自动生成目的驱动数据清洗工作流的LLMs。结果表明，LLMs在规划和生成数据清洗工作流方面表现良好，无需微调。|
|**2024-12-09**|**Toward LLM-Agent-Based Modeling of Transportation Systems: A Conceptual Framework**|Tianming Liu et.al.|[2412.06681](http://arxiv.org/abs/2412.06681)|null|在交通系统需求建模和仿真领域，基于代理的模型和微观仿真是目前最先进的方法。然而，现有的基于代理的模型在行为真实性和资源需求方面仍存在一些局限性，这限制了它们的适用性。在这项研究中，利用新兴的大语言模型（LLMs）和基于LLMs的代理技术，我们提出了一种通用的LLM-代理建模框架用于交通系统。我们认为，LLM代理不仅具备作为代理的基本能力，而且为克服现有基于代理的模型的某些局限性提供了有希望的解决方案。我们的概念框架设计紧密复制了交通网络中人类旅行者的决策和交互过程及特征，并通过相关研究和LLM代理在瓶颈设置中的学习和调整的示范性例子，证明了所提出的系统能够满足决策和学习行为的关键行为标准。尽管需要对基于LLM的代理建模框架进行进一步细化，但我们相信这种方法有潜力改善交通系统建模和仿真。|
|**2024-12-09**|**Beyond pip install: Evaluating LLM Agents for the Automated Installation of Python Projects**|Louis Milliken et.al.|[2412.06294](http://arxiv.org/abs/2412.06294)|null|近年来，许多研究提出了使用大型语言模型（LLM）的智能体来执行“仓库级”任务，这些任务被定义为范围超过单个文件的集合。这引发了这样的推测：这些仓库级任务的编排可能导致能够几乎独立于人为干预进行工作的软件工程智能体。然而，对于需要由这个自主软件工程智能体执行的一系列任务，我们认为缺少了一个重要的任务，那就是通过安装其他仓库来满足项目级的依赖关系。为了研究仓库级安装任务的可行性，我们引入了一个由40个开源Python项目精心挑选的基准仓库安装任务集，其中包含了每个目标仓库的基准安装过程。此外，我们提出了Installamatic智能体，旨在通过搜索仓库文档中的相关说明来执行和验证给定仓库的安装。实证实验表明，研究的55%的仓库至少有一次可以通过我们的智能体自动安装。通过进一步的分析，我们确定了导致我们的智能体无法安装仓库的常见原因，讨论了设计此类智能体时面临的挑战，并考虑了这种智能体可能对开发者产生的影响。|
|**2024-12-08**|**Cooperative SQL Generation for Segmented Databases By Using Multi-functional LLM Agents**|Zhiguang Wu et.al.|[2412.05850](http://arxiv.org/abs/2412.05850)|null|文本到SQL任务旨在根据用户文本问题自动生成SQL查询。为了解决这个问题，我们提出了一种基于多功能代理的协作SQL生成框架（CSMA），通过拥有部分数据库模式的基于大型语言模型（LLM）的代理之间的信息交互来实现。受人类团队合作中协作的启发，CSMA包含三个阶段：1）与问题相关的模式收集，2）对应问题的SQL查询生成，3）SQL查询正确性检查。在第一阶段，代理分析各自的模式并与彼此通信，收集与问题相关的模式信息。在第二阶段，代理尝试使用收集到的信息为问题生成相应的SQL查询。在第三阶段，代理检查SQL查询是否根据他们已知的信息正确创建。这种基于交互的方法使得每个代理的问题相关的数据库模式部分用于SQL生成和检查。在Spider和Bird基准测试上的实验表明，CSMA实现了与现有技术水平相当的高性能水平，同时保持了这些个体代理中的私有数据。|
|**2024-12-06**|**Sense and Sensitivity: Evaluating the simulation of social dynamics via Large Language Models**|Da Ju et.al.|[2412.05093](http://arxiv.org/abs/2412.05093)|null|大型语言模型越来越多地被提议作为经典基于代理模型（ABM）的有力替代品，以模拟社会动态。通过将LLM作为人类行为的代理，这种新方法的希望是能够模拟比经典ABM显著更复杂的动态，并在社会科学、政治学和经济学等领域获得新的见解。然而，由于LLM的“黑盒”特性，LLM代理是否实际上执行了编码在它们自然语言指令中的预期语义尚不清楚，以及由此产生的互动动态是否具有意义。为了研究这个问题，我们提出了一种新的评估框架，将LLM模拟建立在社会科学已建立的参考模型动态的基础上。我们将LLM视为一个黑盒函数，将其输入输出行为与这个参考模型进行比较，这使我们能够评估其行为的详细方面。我们的结果表明，虽然可以设计出近似预期动态的提示，但这些模拟的质量高度依赖于特定提示的选择。重要的是，模拟甚至对任意的微小变化敏感，如轻微的措辞变化和空白。这质疑了当前版本LLM对有意义模拟的有用性，因为没有参考模型，就无法事先确定提示看似无意义的改变将对模拟产生什么影响。|
|**2024-12-05**|**Practical Considerations for Agentic LLM Systems**|Chris Sypherd et.al.|[2412.04093](http://arxiv.org/abs/2412.04093)|null|随着近年来大型语言模型（LLMs）的强度不断增长，对其作为自主代理基础模型的使用兴趣也随之增加。尽管LLMs在自然语言领域的表现显示出涌现能力和广泛的专长，但它们的固有不可预测性使得LLM代理的实现变得具有挑战性，导致相关研究与现实世界中此类系统的实际应用之间出现差距。为了弥合这一差距，本文将研究社区中的可操作见解和考虑纳入到既定应用范例的背景下，以促进稳健LLM代理的构建和知情的部署。具体而言，我们将相关研究结论定位为四个广泛的类别——规划、记忆、工具和控制流——基于应用导向文献中的常见做法，并强调了在为现实世界应用设计代理型LLMs时需要考虑的实用问题，例如处理随机性和高效管理资源。虽然我们没有进行实证评估，但我们提供了讨论代理型LLM设计关键方面的必要背景，这既适用于学术界也适用于工业界。|
|**2024-12-05**|**LossAgent: Towards Any Optimization Objectives for Image Processing with LLM Agents**|Bingchen Li et.al.|[2412.04090](http://arxiv.org/abs/2412.04090)|null|我们提出了一种名为LossAgent的首次出现的损失代理，用于低级图像处理任务，例如图像超分辨率和恢复，旨在实现不同实际应用中低级图像处理的任何定制优化目标。值得注意的是，并非所有优化目标，如复杂的定制感知度量、文本描述和复杂的人类反馈，都可以通过现有的低级损失（例如均方误差损失）来实现，这在端到端优化图像处理网络中提出了一个关键挑战。为了解决这个问题，我们的LossAgent引入了强大的大型语言模型（LLM）作为损失代理，丰富的先验知识文本理解赋予了损失代理理解复杂优化目标、轨迹和状态反馈的能力，从而在低级图像处理网络的优化过程中。特别是，我们通过整合支持低级图像处理端到端优化的现有损失函数，建立了损失库。然后，我们为损失代理设计了面向优化的提示工程，使其在每次优化交互中能够主动和智能地决定库中每个损失的组合权重，从而实现任何定制优化目标所需的优化轨迹。在三个典型的低级图像处理任务和多个优化目标上的大量实验表明，我们提出的LossAgent具有有效性和适用性。代码和预训练模型将在https://github.com/lbc12345/LossAgent上提供。|
|**2024-12-05**|**MISR: Measuring Instrumental Self-Reasoning in Frontier Models**|Kai Fronsdal et.al.|[2412.03904](http://arxiv.org/abs/2412.03904)|**[link](https://github.com/kaifronsdal/self-reasoning-evals)**|**我们提出了一系列任务来评估大型语言模型（LLM）代理的工具体验推理能力。工具体验推理能力可以提高适应性并实现自我修改，但也可能带来重大风险，如使欺骗性对齐成为可能。以往的工作仅评估了非代理设置或有限领域的自我推理。在这篇论文中，我们提出了在广泛场景下，包括自我修改、知识寻求和模糊自我推理等代理任务中的工具体验推理能力的评估方法。我们评估了使用最先进LLM构建的代理，包括商业和开源系统。我们发现，工具体验推理能力仅在能力最强的前沿模型中显现，并且它与上下文高度相关。没有模型通过我们评估中最困难的版本，因此我们的评估可以用于衡量未来模型中工具体验推理能力的提升。我们在https://github.com/kaifronsdal/Self-Reasoning-Evals上开源了我们的评估。**|
|**2024-12-05**|**Educational-Psychological Dialogue Robot Based on Multi-Agent Collaboration**|Shiwen Ni et.al.|[2412.03847](http://arxiv.org/abs/2412.03847)|null|智能对话系统在现代教育和心理辅导领域得到越来越广泛的应用，但大多数现有系统局限于单一领域，无法同时处理教育和心理问题，并且在处理复杂问题时往往缺乏准确性和专业性。为了解决这些问题，本文提出了一种结合教育和心理辅导功能的智能对话系统。该系统由多个AI代理组成，包括安全检测代理、意图识别代理、教育LLM代理和心理LLM代理，它们协同工作以确保提供准确的教育知识问答和心理健康支持服务。具体来说，系统通过意图分类模型识别用户输入的意图，并调用增强检索的教育大型模型和心理大型模型（该模型已使用心理数据进行微调），以便提供专业的教育建议和心理健康支持。|
|**2024-12-03**|**Hacking CTFs with Plain Agents**|Rustem Turtayev et.al.|[2412.02776](http://arxiv.org/abs/2412.02776)|**[link](https://github.com/palisaderesearch/intercode)**|**我们通过简单的LLM代理设计饱和了一所高中水平的黑客基准测试。具体来说，我们通过提示、工具使用和多次尝试，在InterCode-CTF这个流行的进攻性安全基准测试上获得了95%的性能。这一成绩超过了Phuong等人2024年（29%）和Abramovich等人2024年（72%）的研究成果。我们的结果表明，当前的大型语言模型在进攻性网络安全方面已经超越了高中水平。它们的黑客能力尚未得到充分发掘：我们提出的ReAct&Plan提示策略在1-2个回合内解决了许多挑战，无需复杂的工程或高级利用。**|
|**2024-12-02**|**HackSynth: LLM Agent and Evaluation Framework for Autonomous Penetration Testing**|Lajos Muzsai et.al.|[2412.01778](http://arxiv.org/abs/2412.01778)|**[link](https://github.com/aielte-research/HackSynth)**|**我们介绍了HackSynth，这是一种基于大型语言模型（LLM）的全新自主渗透测试代理。HackSynth的双模块架构包括一个规划器和总结器，这使得它能够迭代地生成命令和处理反馈。为了对HackSynth进行基准测试，我们提出了两个基于Capture The Flag（CTF）的新基准集，利用流行的平台PicoCTF和OverTheWire。这些基准集涵盖了200个不同领域和难度的挑战，为评估基于LLM的渗透测试代理提供了一个标准化的框架。基于这些基准，我们展示了广泛的实验，分析了HackSynth的核心参数，包括创新性（温度和top-p）和标记利用。我们使用了多个开源和专有LLM来衡量代理的能力。实验表明，该代理在GPT-4o模型下表现最佳，优于GPT-4o的系统卡片所建议的。我们还讨论了HackSynth行动的安全性和可预测性。我们的发现表明，基于LLM的代理在推进自主渗透测试方面的潜力，以及稳健保障的重要性。HackSynth和基准集公开可用，以促进自主网络安全解决方案的研究。**|
|**2024-12-02**|**Medchain: Bridging the Gap Between LLM Agents and Clinical Practice through Interactive Sequential Benchmarking**|Jie Liu et.al.|[2412.01605](http://arxiv.org/abs/2412.01605)|null|临床决策（CDM）是医疗保健服务中复杂且动态的过程，但对于人工智能系统来说仍然是一个重大挑战。尽管基于大型语言模型（LLM）的智能体已在执照考试和知识问答任务中测试了一般医学知识，但由于缺乏反映实际医疗实践的全面测试数据集，它们在现实场景中的CDM表现有限。为了解决这一差距，我们提出了MedChain，一个包含12,163个临床案例的数据集，涵盖了临床工作流程的五个关键阶段。MedChain与现有基准相比，具有三个反映现实临床实践的显著特点：个性化、交互性和顺序性。此外，为了应对现实世界中的CDM挑战，我们还提出了MedChain-Agent，这是一个集成了反馈机制和MCase-RAG模块的人工智能系统，以便从以往案例中学习并调整其响应。MedChain-Agent在动态收集信息和处理顺序临床任务方面表现出惊人的适应性，显著优于现有方法。在本文被接受后，将发布相关数据集和代码。|
|**2024-12-02**|**Can Large Language Models Serve as Evaluators for Code Summarization?**|Yang Wu et.al.|[2412.01333](http://arxiv.org/abs/2412.01333)|**[link](https://github.com/CGCL-codes/naturalcc)**|**代码摘要通过将代码片段转换为自然语言描述，有助于程序理解和软件维护。多年来，为这项任务开发了众多方法，但一个关键挑战仍然存在：有效地评估生成摘要的质量。虽然人工评估在评估代码摘要质量方面是有效的，但它劳动密集且难以扩展。常用的自动指标，如BLEU、ROUGE-L、METEOR和BertScore，通常与人工判断的关联性不强。在本文中，我们探讨了大型语言模型（LLMs）在评估代码摘要方面的潜力。我们提出了CODERPE（代码摘要评估中的角色扮演者），这是一种利用角色扮演提示来评估生成摘要质量的新方法。具体来说，我们提示LLM代理扮演各种角色，如代码审阅者、代码作者、代码编辑和系统分析师。每个角色从关键维度评估代码摘要的质量，包括连贯性、一致性、流畅性和相关性。我们进一步通过采用各种提示策略，包括思维链推理、情境学习和定制评分表设计，探索了LLMs作为评估者的鲁棒性。结果表明，LLMs作为代码摘要方法的有效评估者。值得注意的是，我们的基于LLM的评估器CODERPE与人工评估的斯皮尔曼相关系数为81.59%，比现有的BERTScore指标高17.27%。**|
|**2024-12-02**|**RL2: Reinforce Large Language Model to Assist Safe Reinforcement Learning for Energy Management of Active Distribution Networks**|Xu Yang et.al.|[2412.01303](http://arxiv.org/abs/2412.01303)|null|随着大规模分布式能源资源被集成到主动配电网络（ADN）中，与传统的配电网络相比，在ADN中实现有效的能源管理变得越来越突出。尽管先进的强化学习方法（RL）极大地提高了ADN能源管理的效率，减轻了复杂建模和优化的负担，但安全性成为RL在实际问题应用中的关键关注点。由于与操作安全约束相对应的惩罚函数的设计和调整需要RL和电力系统操作方面的广泛领域知识，新兴的ADN运营商呼吁采用更灵活和定制化的方法来解决惩罚函数，以便进一步提高操作安全和效率。凭借强大的理解、推理和在上下文中学习的能力，大型语言模型（LLM）为辅助ADN能源管理的安全RL提供了一种有希望的途径。在本文中，我们引入LLM来理解ADN中的操作安全要求并生成相应的惩罚函数。此外，我们提出了一种RL2机制，通过多轮对话迭代和自适应地改进生成的函数，其中LLM代理根据下游RL代理的训练和测试性能调整函数的模式和参数。所提出的方法显著减少了ADN运营商的干预。综合测试结果证明了所提出方法的有效性。|
|**2024-12-02**|**SAUP: Situation Awareness Uncertainty Propagation on LLM Agent**|Qiwei Zhao et.al.|[2412.01033](http://arxiv.org/abs/2412.01033)|null|大型语言模型（LLMs）集成到多步骤智能体系统中，能够在各种应用中实现复杂的决策过程。然而，它们的输出通常缺乏可靠性，因此不确定性估计变得至关重要。现有的不确定性估计方法主要关注最终步骤的输出，未能考虑到多步骤决策过程中的累积不确定性和智能体与其环境之间的动态交互。为了解决这些局限性，我们提出了SAUP（情境感知不确定性传播），这是一个新颖的框架，它通过LLM智能体推理过程的每一步传播不确定性。SAUP通过在传播过程中为每一步的不确定性分配情境权重来融入情境感知。我们的方法与各种单步不确定性估计技术兼容，提供了一个全面且准确的不确定性度量。在基准数据集上的大量实验表明，SAUP显著优于现有最先进的方法，实现了AUROC达到20%的提升。|
|**2024-11-28**|**Using a Feedback Loop for LLM-based Infrastructure as Code Generation**|Mayur Amarnath Palavalli et.al.|[2411.19043](http://arxiv.org/abs/2411.19043)|**[link](https://github.com/Mayur-Palavalli/LLM-IaC-generation)**|**使用大型语言模型（LLMs）进行代码生成有助于提高软件开发者在编码任务中的生产力，但尚未对围绕这些代码的软件开发者的任务产生重大影响。特别是，基础设施管理的挑战仍然是一个未解之谜。我们研究了LLM代理利用基础设施即代码（IaC）范式构建基础设施的能力。我们特别研究了使用反馈循环，该循环会返回生成的IaC的错误和警告，以允许LLM代理改进代码。我们发现，对于循环的每一次迭代，其有效性都会呈指数下降，直到达到某个点并趋于平稳，最终变得无效。**|
|**2024-11-28**|**MATATA: a weak-supervised MAthematical Tool-Assisted reasoning for Tabular Applications**|Vishnou Vinayagame et.al.|[2411.18915](http://arxiv.org/abs/2411.18915)|null|随着工具增强的语言代理的数学推理能力不断增强，但现有方法通常依赖于闭源或大型模型、外部数据或大量的提示工程。这项工作介绍了一种名为MATATA的新颖且经济高效的方法，通过推理、规划和工具使用来训练LLM代理解决表格数据问题。它采用渐进式自我改进范式和迭代式弱监督，赋予了38亿/80亿小语言模型（SLM）的能力，特别适合于本地托管和敏感的商业环境，在这些环境中数据隐私至关重要。通过在不同数据集上使用灵活且可重用的工具，它实现了在共享任务上的有效可扩展性。实验表明，MATATA在基于开源模型的推理框架中，在FinQA和TAT-QA上达到了最先进的性能。此外，MATATA模型在TabMWP上与基于GPT-4的框架竞争，同时仍然是SLM。|
|**2024-11-27**|**Wearable intelligent throat enables natural speech in stroke patients with dysarthria**|Chenyu Tang et.al.|[2411.18266](http://arxiv.org/abs/2411.18266)|null|可穿戴无声语音系统在恢复言语障碍患者的沟通方面具有巨大潜力。然而，无缝、连贯的语音仍然难以实现，临床疗效尚未得到证实。在此，我们提出了一种由人工智能驱动的智能喉部（IT）系统，该系统集成了喉部肌肉振动和颈动脉脉搏信号传感器以及大型语言模型（LLM）处理，以实现流畅、富有情感表达的沟通。该系统利用超灵敏的纺织应变传感器从颈部区域捕捉高质量信号，并支持token级别的处理，以实现实时、连续的语音解码，从而实现无缝、无延迟的通信。在测试中，使用五种言语障碍的卒中患者进行测试，IT的LLM智能代理智能地纠正token错误，丰富句子级情感和逻辑连贯性，实现了低错误率（4.2%的词错误率，2.9%的句子错误率）和用户满意度55%的增长。这项工作为言语障碍患者建立了一个便携、直观的通信平台，有望广泛应用于不同的神经学条件和多语言支持系统。|
|**2024-11-26**|**MALMM: Multi-Agent Large Language Models for Zero-Shot Robotics Manipulation**|Harsh Singh et.al.|[2411.17636](http://arxiv.org/abs/2411.17636)|null|大型语言模型（LLMs）在各种领域，包括机器人操作和导航，展现了出色的规划能力。虽然最近在机器人领域的努力已经利用LLMs进行高级和低级规划，但这些方法通常面临重大挑战，如长期任务中的幻觉以及由于在单次生成计划时缺乏实时反馈而导致的适应性有限。为了解决这些限制，我们提出了一种新的多智能体LLM框架，即用于操作的智能体大型语言模型（MALMM），它将高级规划和低级控制代码生成分配给专门的LLM智能体，并由一个额外的智能体动态管理转换。通过在每一步后纳入环境观察，我们的框架有效地处理了中间失败，并实现了适应性重新规划。与现有方法不同，我们的方法不依赖于预训练的技能策略或在上下文中学习的示例，并且可以推广到各种新的任务。我们在包括长期任务在内的九个RLBench任务上评估了我们的方法，并展示了其在零样本设置下解决机器人操作的能力，从而克服了现有基于LLM的操作方法的局限性。|
|**2024-11-25**|**Agent-Based Modelling Meets Generative AI in Social Network Simulations**|Antonino Ferraro et.al.|[2411.16031](http://arxiv.org/abs/2411.16031)|null|基于代理建模（ABM）已成为模拟社交网络的重要工具，涵盖了诸如信息传播、影响力动态和社区形成等多种现象。然而，手动配置各种代理交互和信息流动态带来挑战，往往导致模型过于简化，缺乏现实世界的普适性。将现代大型语言模型（LLM）与ABM相结合为解决这些挑战和提升模拟真实度提供了一条有希望的途径，利用LLM在感知、推理和行为方面类似人类的能力。在本文中，我们提出了一种新颖的框架，该框架利用LLM赋能的代理根据用户的兴趣和个性特征模拟社交网络用户。该框架允许定制代理交互，类似于各种社交网络平台，包括内容重新分享和个性化推荐机制。我们使用2020年美国选举的全面Twitter数据集验证了我们的框架，证明LLM代理能够准确复制真实用户的言行，包括语言模式和政治倾向。这些代理形成了同质化的意识形态集群，并保留了其社区的主要主题。值得注意的是，基于偏好的推荐对代理行为有显著影响，促进了更高的参与度、网络同质性以及回音室的形成。总体而言，我们的发现突出了LLM代理在推进社交媒体模拟和揭示复杂在线动态中的潜力。|
|**2024-11-24**|**From Laws to Motivation: Guiding Exploration through Law-Based Reasoning and Rewards**|Ziyu Chen et.al.|[2411.15891](http://arxiv.org/abs/2411.15891)|null|大型语言模型（LLMs）和强化学习（RL）是构建自主智能体的两种强大方法。然而，由于对游戏环境的理解有限，智能体往往依赖低效的探索和试错，难以发展长期策略或做出决策。我们提出了一种方法，通过从交互记录中提取经验来模拟游戏环境的潜在规律，并利用这些经验作为内部动机来引导智能体。这些经验以语言形式表达，非常灵活，既可以直接协助智能体进行推理，也可以转化为训练中的奖励。在Crafter上的评估结果显示，RL和LLM智能体都从这些经验中受益，从而提高了整体性能。|
|**2024-11-23**|**Two Heads Are Better Than One: Collaborative LLM Embodied Agents for Human-Robot Interaction**|Mitchell Rosser et.al.|[2411.16723](http://arxiv.org/abs/2411.16723)|null|随着自然语言生成模型（称为大型语言模型，LLMs）的近期发展，一种潜在的应用场景得以开启，即改进人类与机器人助手互动的方式。这些LLMs应能利用其广泛的理解能力，将自然语言命令解释为有效、符合任务和安全的机器人任务执行。然而，在现实中，这些模型存在幻觉问题，可能会引起安全问题或偏离任务。在其他领域，这些问题已通过使用协作人工智能系统得到改善，在该系统中，多个LLM代理可以共同规划、编码和自我检查输出。在本研究中，通过将多个协作人工智能系统与单个独立人工智能代理进行对比测试，以确定在其他领域的成功是否能够转化为改进的人机交互性能。结果显示，代理数量与模型的成功率之间没有明确的趋势。然而，很明显，某些协作人工智能代理架构可以显著提高生成无错误代码和解决抽象问题的能力。|
|**2024-11-23**|**The Decoy Dilemma in Online Medical Information Evaluation: A Comparative Study of Credibility Assessments by LLM and Human Judges**|Jiqun Liu et.al.|[2411.15396](http://arxiv.org/abs/2411.15396)|null|人工智能在进行自动化信息判断任务时是否会产生认知偏差？尽管近期在衡量和缓解人工智能和大型语言模型（LLMs）中的社会和算法偏差方面取得了进展，但LLMs在多大程度上表现出“理性”行为，或者它们是否也容易受到人类认知偏差的触发，仍不明确。为了解决这个未解问题，我们的研究包括一个众包用户实验和一个LLM驱动的模拟实验，比较了在信息检索（IR）环境中，LLMs和人类评判员在潜在诱饵效应下的可信度评估，并实证研究了与传统的基于人类评估的基线相比，LLMs在COVID-19医疗（误）信息评估任务中的认知偏差程度。来自跨主体用户实验和LLM驱动的重复实验的结果表明：1）更大、更新版的LLMs在区分可信信息和虚假信息方面表现出更高的一致性和准确性。然而，由于存在更显著、更具诱饵性质的虚假信息结果，它们更有可能给予虚假信息更高的评分；2）虽然诱饵效应在人类和LLMs的评估中都发生了，但在LLMs的判断中，这种效应在不同条件和主题下比人类的可信度评分更为普遍。与普遍认为的AI工具的“理性”相反，我们的研究从实证上确认了LLM代理中嵌入的认知偏差风险，评估了诱饵对LLMs与人类可信度评估的影响，从而突出了去偏差AI代理、开发心理学导向的AI审计技术和政策（用于自动化判断任务及更多领域）的复杂性和重要性。|
|**2024-11-22**|**XGrammar: Flexible and Efficient Structured Generation Engine for Large Language Models**|Yixin Dong et.al.|[2411.15100](http://arxiv.org/abs/2411.15100)|null|LLM代理的应用正变得越来越复杂和多样化，导致对可以解析为代码、结构化函数调用和具身代理命令的规范化输出的需求日益增长。这些发展对LLM推理中的规范化生成提出了重大需求。无上下文文法是一种灵活的方法，通过限制解码来实现规范化生成。然而，执行无上下文文法需要在运行时遍历词汇表中所有标记的多个栈状态，给规范化生成带来不可忽视的开销。在本文中，我们提出了XGrammar，这是一个灵活且高效的LLM结构生成引擎。XGrammar通过将词汇表划分为可预检查的上下文无关标记和需要运行时解释的上下文相关标记来加速无上下文文法的执行。我们进一步构建了转换来扩展语法上下文并减少上下文无关标记的数量。此外，我们构建了一个高效的持久栈来加速上下文相关标记的检查。最后，我们与LLM推理引擎协同设计语法引擎，以重叠语法计算与GPU执行。评估结果显示，XGrammar可以比现有解决方案实现高达100倍的加速。结合LLM推理引擎，它可以在端到端低LLM服务中实现近乎零开销的结构化生成。|
|**2024-11-22**|**ScribeAgent: Towards Specialized Web Agents Using Production-Scale Workflow Data**|Junhong Shen et.al.|[2411.15004](http://arxiv.org/abs/2411.15004)|**[link](https://github.com/colonylabs/ScribeAgent)**|大型语言模型（LLM）代理正在迅速提升以处理越来越复杂的基于网络的任务。这些代理中的大多数依赖于通用、专有的模型如GPT-4，并专注于设计更好的提示以提升它们的规划能力。然而，通用LLM并未专门训练以理解专门的网络上下文，如HTML，并且它们通常在长期规划方面遇到困难。我们探索了一种替代方法，即使用从超过250个域名收集的生产规模工作流程数据对开源LLM进行微调，这些域名对应60亿个标记。这种方法简单而有效，在现有基准测试中相对于基于提示的代理显示了显著的优势——ScribeAgent在Mind2Web上实现了最先进的直接生成性能，并在WebArena上比之前最佳的文字型网络代理提高了14.1%的任务成功率。我们还对各种微调设计选择进行了详细的消融研究，并提供了关于LLM选择、训练配方、上下文窗口优化以及数据集大小影响等方面的见解。|
|**2024-11-21**|**Physics-Informed LLM-Agent for Automated Modulation Design in Power Electronics Systems**|Junhua Liu et.al.|[2411.14214](http://arxiv.org/abs/2411.14214)|null|基于LLM的自主代理在解决复杂工业任务方面表现出卓越的性能。然而，在追求碳中和和高性能可再生能源系统的过程中，现有的AI辅助设计自动化在可解释性、可扩展性和可用性方面面临着重大限制。为了解决这些挑战，我们提出了LP-COMDA，这是一个基于LLM的、物理信息丰富的自主代理，能够在最小人工监督下自动化电力电子系统中电力转换器的调制设计。与传统的AI辅助方法不同，LP-COMDA包含一个基于LLM的规划器，通过用户友好的聊天界面收集和验证设计规范。规划器随后与物理信息设计优化工具协调，自主迭代生成和优化调制设计。通过聊天界面，LP-COMDA提供可解释的设计过程，展示解释和图表。实验表明，LP-COMDA优于所有基线方法，在标准均方绝对误差方面，与第二好的基准方法相比，误差降低了63.2%。此外，对20位专家的实证研究表明，使用LP-COMDA的设计时间是传统方法的33倍以上，显示出其在设计效率方面的显著改进。|
|**2024-11-21**|**Multi-LLM-Agent Systems: Techniques and Business Perspectives**|Yingxuan Yang et.al.|[2411.14033](http://arxiv.org/abs/2411.14033)|null|在（多模态）大型语言模型时代，大多数操作流程都可以通过LLM智能体进行重构和再现。LLM智能体能够感知、控制和从环境中获取反馈，以自主方式完成给定任务。除了环境交互特性外，LLM智能体还可以调用各种外部工具以简化任务完成过程。这些工具可以被视为包含私有或实时知识且不存在于LLM参数中的预定义操作流程。作为发展的自然趋势，调用工具的智能体正成为自主智能体，因此完整的智能系统最终变成了多LLM智能体系统（MLAS）。本文讨论了MLAS的技术和商业格局。与之前的单一LLM智能体系统相比，MLAS具有以下优势：i) 更高的任务解决性能潜力；ii) 更高的系统变化灵活性；iii) 为每个参与实体保留专有数据；iv) 为每个实体实现货币化的可行性。为了支持MLAS生态系统，我们提供了一个考虑技术要求、数据隐私和商业激励的MLAS协议的初步版本。因此，MLAS将成为实现未来人工集体智慧的实用解决方案。|

<p align=right>(<a href=#updated-on-20241211>back to top</a>)</p>

## llm

|Publish Date|Title|Authors|PDF|Code|abstract|
|---|---|---|---|---|---|
|**2024-12-09**|**Training Large Language Models to Reason in a Continuous Latent Space**|Shibo Hao et.al.|[2412.06769](http://arxiv.org/abs/2412.06769)|null|大型语言模型（LLMs）通常在“语言空间”中进行推理，通过思维链（CoT）来表述推理过程以解决复杂的推理问题。然而，我们认为语言空间并不总是推理的最优选择。例如，大多数单词标记主要用于文本连贯性，而非推理所必需，而一些关键标记则需要复杂的规划和给LLMs带来巨大挑战。为了探索LLMs在不受限制的潜在空间中进行推理的潜力，而不是使用自然语言，我们引入了一种新的范式——椰子（连续思维链）。我们利用LLM的最后隐藏状态作为推理状态的表示（称为“连续思维”）。我们不是将其解码为单词标记，而是直接将其作为连续空间中的后续输入嵌入反馈给LLM。实验表明，椰子可以有效地增强LLM在多个推理任务上的表现。这种新颖的潜在推理范式导致出现高级推理模式：连续思维可以编码多个替代的后续推理步骤，允许模型执行广度优先搜索（BFS）来解决问题，而不是像CoT那样过早地承诺单一确定路径。在需要大量回溯规划的某些逻辑推理任务中，椰子优于CoT，推理过程中思考标记更少。这些发现展示了潜在推理的潜力，并为未来的研究提供了宝贵的见解。|
|**2024-12-09**|**Why Do Developers Engage with ChatGPT in Issue-Tracker? Investigating Usage and Reliance on ChatGPT-Generated Code**|Joy Krishan Das et.al.|[2412.06757](http://arxiv.org/abs/2412.06757)|null|大型语言模型（LLMs）如ChatGPT已显示出协助开发者进行编码和调试任务的潜力。然而，它们在协同问题解决中的角色尚未得到充分探索。在本研究中，我们分析了GitHub上1,012个问题中的1,152次开发者与ChatGPT的对话，以考察ChatGPT的多样使用和对其生成代码的依赖。我们的贡献有四个方面。首先，我们手动分析了289次对话，以了解ChatGPT在GitHub问题中的使用情况。我们的分析显示，ChatGPT主要用于创意构思，而其在验证（例如，代码文档准确性）方面的使用非常有限。其次，我们应用BERTopic模型来识别整个数据集中关键的关注领域。我们发现后端问题（例如，API管理）主导了对话，而测试却意外地覆盖较少。第三，我们利用CPD克隆检测工具来检查ChatGPT生成的代码是否被用于解决问题。我们的发现显示，ChatGPT生成的代码被直接用于解决仅占5.83%的问题。第四，我们使用基于RoBERTa的情感分析模型来估计情感，以确定开发者对不同用途和关注领域的满意度。我们发现，使用ChatGPT进行重构和解决数据分析（例如，分类表数据）问题的正面情绪（即，高度满意）。相反，当使用ChatGPT调试问题和解决自动化任务（例如，GUI交互）时，我们观察到负面情绪。我们的研究发现，开发者存在未满足的需求和日益增长的不满。研究人员和ChatGPT开发者应专注于开发特定任务的解决方案，以帮助解决各种问题，提高软件开发中的用户满意度和解决问题的效率。|
|**2024-12-09**|**Refusal Tokens: A Simple Way to Calibrate Refusals in Large Language Models**|Neel Jain et.al.|[2412.06748](http://arxiv.org/abs/2412.06748)|null|构建安全可靠的语言模型的关键组成部分是使模型能够适当地拒绝遵循某些指令或回答某些问题。我们可能希望模型为各种用户查询类别输出拒绝消息，例如，无意义的问题、执行非法行为的指令，或需要超出模型知识范围的信息的查询。设计拒绝回答此类问题的模型复杂化，因为个人可能希望他们的模型在拒绝不同类别的查询时表现出不同水平的感觉性，不同的用户可能希望有不同的拒绝率。当前默认的方法涉及使用每个类别不同比例的拒绝消息训练多个模型以实现所需的拒绝率，这计算成本高，可能需要为每位用户的拒绝率偏好训练新的模型。为了解决这些挑战，我们提出了拒绝标记，每个拒绝类别一个标记，或一个单一的拒绝标记，这些标记在训练期间添加到模型的响应之前。然后，我们展示了如何在推理期间增加或减少生成每个类别拒绝标记的概率，以引导模型的拒绝行为。拒绝标记允许通过在生成过程中选择性干预来控制单个模型的拒绝率，而不需要任何进一步的微调。|
|**2024-12-09**|**JAPAGEN: Efficient Few/Zero-shot Learning via Japanese Training Dataset Generation with LLM**|Takuro Fujii et.al.|[2412.06738](http://arxiv.org/abs/2412.06738)|null|近期一些研究强调了大型语言模型（LLMs）作为有效的监督训练数据生成器的潜力，提供了如提高推理效率和降低数据收集相关成本等优势。然而，这些研究主要关注英语任务。在本文中，我们探讨了基本的研究问题：LLMs能否作为其他语言任务的优秀训练数据生成器？具体来说，我们利用LLMs在六种不同的日语下游任务下，在少样本和零样本学习场景中合成监督训练数据。随后，我们使用这些合成的数据训练紧凑模型（例如BERT）。这种新颖的方法被称为JAPAGEN。我们的实验发现表明，JAPAGEN在需要正式文本输入的分类任务中实现了稳健的性能，与传统的LLM提示策略相比，取得了具有竞争力的结果。|
|**2024-12-09**|**AutoDCWorkflow: LLM-based Data Cleaning Workflow Auto-Generation and Benchmark**|Lan Li et.al.|[2412.06724](http://arxiv.org/abs/2412.06724)|null|我们研究了大型语言模型（LLMs）在自动生成数据清理工作流中的推理能力。为了评估LLMs完成数据清理任务的能力，我们实现了一个基于LLM的自动数据清理工作流（AutoDCWorkflow）的管道，通过提示LLMs进行数据清理操作来修复三种类型的数据质量问题：重复数据、缺失值和不一致的数据格式。给定一个脏表和目的（以查询形式表达），此管道生成一个最小的、干净的表，足以满足目的，并生成用于生成该表的数据清理工作流。规划过程涉及三个主要的LLM驱动组件：（1）选择目标列：识别与目的相关的目标列集合。（2）检查列质量：评估每个目标列的数据质量，并生成数据质量报告作为操作目标。（3）生成操作与参数：根据数据质量报告的结果预测下一个操作和参数。此外，我们提出一个数据清理基准，以评估LLM代理自动生成解决不同难度水平数据清理目的的工作流的能力。基准包括注释数据集，作为一个包含目的、原始表、干净表、数据清理工作流和答案集的集合。在我们的实验中，我们评估了三种自动生成目的驱动数据清理工作流的LLMs。结果表明，LLMs在规划和生成数据清理工作流方面表现良好，无需微调。|
|**2024-12-09**|**OmniEvalKit: A Modular, Lightweight Toolbox for Evaluating Large Language Model and its Omni-Extensions**|Yi-Kai Zhang et.al.|[2412.06693](http://arxiv.org/abs/2412.06693)|null|随着大型语言模型（LLMs）的快速发展，其应用范围得到了显著扩展，从多语言支持到特定领域的任务和多模态集成。本文介绍了一种新型的基准测试工具箱OmniEvalKit，旨在评估LLMs及其全功能扩展在多语言、多领域和多模态能力方面的表现。与现有专注于单一方面的基准测试不同，OmniEvalKit提供了一个模块化、轻量化和自动化的评估系统。它采用模块化架构，包括静态构建器和动态数据流，促进了新模型和数据集的无缝集成。OmniEvalKit支持超过100种LLMs和50个评估数据集，覆盖了成千上万种模型-数据集组合的全面评估。OmniEvalKit致力于创建一个超轻量级且快速部署的评估框架，使下游应用对人工智能社区更加便捷和灵活。|
|**2024-12-09**|**Exploring Critical Testing Scenarios for Decision-Making Policies: An LLM Approach**|Weichao Xu et.al.|[2412.06684](http://arxiv.org/abs/2412.06684)|null|近年来，决策政策在各种领域，如自动驾驶和机器人技术，取得了令人惊讶的成就。在存在可能威胁其可靠性的关键场景的情况下，对决策政策进行测试至关重要。众多研究努力致力于测试这些政策。然而，由于测试政策和环境的复杂性，仍然存在重大挑战，例如测试效率低和多样性不足。受大型语言模型（LLMs）卓越能力的影响，本文提出了一种基于LLM的在线测试框架，以有效地测试决策政策。主要思路是利用基于LLM的测试场景生成器通过思考和推理智能地生成具有挑战性的测试案例。具体来说，我们首先设计了一个“生成-测试-反馈”流程，并应用模板提示工程充分利用LLMs的知识和推理能力。然后，我们引入了一种多尺度场景生成策略来解决LLMs在精细调整方面固有的挑战，从而进一步提高测试效率。最后，我们在五个广泛使用的基准上评估了基于LLM的方法。实验结果表明，我们的方法在揭示关键和多样化的场景方面显著优于基线方法。|
|**2024-12-09**|**Toward LLM-Agent-Based Modeling of Transportation Systems: A Conceptual Framework**|Tianming Liu et.al.|[2412.06681](http://arxiv.org/abs/2412.06681)|null|在交通运输系统需求建模和仿真领域，基于代理模型和微观模拟是目前最先进的方法。然而，现有的基于代理模型在行为真实性和资源需求方面仍存在一些限制，这限制了它们的适用性。在本研究中，我们利用新兴的大语言模型（LLMs）和基于LLMs的代理技术，提出了一种适用于交通运输系统的一般LLM-代理建模框架。我们认为，LLM代理不仅具备作为代理的基本能力，而且为克服现有基于代理模型的某些局限性提供了有希望的解决方案。我们的概念框架设计紧密模拟了交通网络中人类旅行者的决策、交互过程和特征，并通过相关研究和LLM代理在瓶颈设置中的学习和调整的演示实例，证明了所提出的系统可以满足决策和学习行为的关键行为标准。尽管需要进一步细化基于LLM的代理建模框架，但我们相信这种方法有可能提高交通运输系统建模和仿真的水平。|
|**2024-12-09**|**I Don't Know: Explicit Modeling of Uncertainty with an [IDK] Token**|Roi Cohen et.al.|[2412.06676](http://arxiv.org/abs/2412.06676)|null|大型语言模型因其能够捕捉现实世界知识而闻名，这使得它们在许多下游任务中表现出色。尽管近年来取得了进展，但这些模型仍然容易受到所谓的“幻觉”的影响，导致它们产生不想要且事实错误的文章。在本研究中，我们提出了一种新颖的校准方法，可用于对抗幻觉。我们向模型的词汇表中添加了一个特殊的[IDK]（“我不知道”）标记，并引入了一个目标函数，该函数将概率质量转移到[IDK]标记以应对错误的预测。这种方法允许模型在其输出中明确表达不确定性。我们在多个模型架构和事实性下游任务中评估了我们的方法。我们发现，使用我们的方法训练的模型能够在它们之前可能出错的地方表达不确定性，同时只损失少量的编码知识。我们还对多种方法变体进行了广泛的消融研究，并提供了对我们方法精确度-召回率权衡的详细分析。|
|**2024-12-09**|**ILLUME: Illuminating Your LLMs to See, Draw, and Self-Enhance**|Chunwei Wang et.al.|[2412.06673](http://arxiv.org/abs/2412.06673)|null|在这篇论文中，我们介绍了ILLUME，这是一种统一的多元模态大型语言模型（MLLM），通过统一的下一个标记预测公式，将多元模态的理解和生成能力无缝集成到单个大型语言模型中。为了解决图像-文本对齐通常所需的大量数据集大小，我们提出通过设计一个结合语义信息的视觉标记化器和渐进式多阶段训练程序来提高数据效率。这种方法将数据集大小减少到仅为15M用于预训练——仅为通常所需数量的四分之一——同时实现了与现有统一MLLMs（如Janus）相当甚至更优的性能。此外，为了促进理解和生成能力之间的协同增强，这是以往工作中较少探索的，我们引入了一种新颖的自我增强多元模态对齐方案。该方案监督MLLM自我评估文本描述和自生成图像之间的一致性，促进模型更准确地解释图像，并避免由图像生成中的对齐错误引起的非现实和不正确预测。基于广泛的实验，我们提出的ILLUME在各种多元模态理解、生成和编辑的基准测试中脱颖而出，并与其他最先进的统一MLLMs和专业模型竞争。|
|**2024-12-06**|**Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling**|Zhe Chen et.al.|[2412.05271](http://arxiv.org/abs/2412.05271)|null|我们推出了InternVL 2.5，这是一个基于InternVL 2.0的高级多模态大型语言模型（MLLM）系列，保持了其核心模型架构，同时在训练和测试策略以及数据质量方面引入了显著的提升。在这项工作中，我们深入探讨了模型规模与性能之间的关系，系统地研究了视觉编码器、语言模型、数据集规模和测试时配置的性能趋势。通过在包括跨学科推理、文档理解、多图像/视频理解、现实世界理解、多模态幻觉检测、视觉定位、多语言能力和纯语言处理等广泛基准上的广泛评估，InternVL 2.5展现出具有竞争力的性能，与GPT-4o和Claude-3.5-Sonnet等领先的商业模型相媲美。值得注意的是，我们的模型是第一个在MMMU基准测试中超过70%的开源MLLM，通过思维链（CoT）推理实现了3.7分的提升，并展示了强大的测试时缩放潜力。我们希望这个模型通过设定开发和应用多模态AI系统的新标准，为开源社区做出贡献。HuggingFace演示请见https://huggingface.co/spaces/OpenGVLab/InternVL|
|**2024-12-06**|**APOLLO: SGD-like Memory, AdamW-level Performance**|Hanqing Zhu et.al.|[2412.05270](http://arxiv.org/abs/2412.05270)|null|大型语言模型（LLMs）在训练过程中对内存的消耗非常严重，尤其是使用流行的AdamW优化器时。这种内存负担迫使人们使用更多或更高端的GPU，或者减小批处理大小，从而限制了训练的可扩展性和吞吐量。为了解决这个问题，已经提出了各种内存高效的优化器来减少优化器的内存使用。然而，它们面临着一些关键的挑战：（i）依赖于昂贵的奇异值分解（SVD）操作；（ii）与AdamW相比，性能上有显著的权衡；（iii）仍然有相当大的优化器内存开销以维持竞争优势。  在这项工作中，我们发现AdamW的学习率自适应规则可以作为结构化学习率更新有效地粗化。基于这一洞察，我们提出了近似梯度缩放用于内存高效LLM优化（APOLLO），它使用基于纯随机投影的辅助低秩优化器状态来近似学习率缩放。这种结构化学习率更新规则使得APOLLO对进一步减少内存具有高度容忍性，同时在预训练性能上与AdamW相当。即使是它的秩-1变体APOLLO-Mini，在具有与SGD相当内存成本的条件下，也比AdamW实现了更优的预训练性能。  大量实验表明，APOLLO系列的性能与AdamW相当或更好，同时通过几乎消除AdamW的优化状态，实现了更大的内存节省。这些节省带来了显著的系统级好处：（1）提高了吞吐量：在8xA100-80GB的配置上，通过支持4倍更大的批处理大小，比AdamW实现了3倍的吞吐量。（2）提高了模型的可扩展性：在A100-80GB GPU上使用原始的分布式数据并行（DDP）预训练LLaMA-13B，而不进行系统级优化。（3）低端GPU友好的预训练：使用权重量化，在单个GPU上预训练LLaMA-7B，内存使用量少于12GB。|
|**2024-12-06**|**CompCap: Improving Multimodal Large Language Models with Composite Captions**|Xiaohui Chen et.al.|[2412.05243](http://arxiv.org/abs/2412.05243)|null|多模态大型语言模型（MLLMs）在理解复合图像方面的能力如何？复合图像（CIs）是通过合并多个视觉元素（如图表、海报或截图）合成的合成视觉，而不是通过相机直接捕捉的。虽然CIs在现实世界应用中很普遍，但最近MLLM的发展主要集中于解读自然图像（NIs）。我们的研究揭示，当前的MLLM在准确理解CIs方面面临着重大挑战，常常难以从这些图像中提取信息或进行复杂推理。我们发现，现有的CIs训练数据大多格式化为问答任务（例如，在ChartQA和ScienceQA等数据集中），而高质量的图像-描述数据集，对于稳健的视觉-语言对齐至关重要，却只有自然图像（NIs）才有。为了弥合这一差距，我们引入了复合描述（CompCap），这是一个灵活的框架，利用大型语言模型（LLMs）和自动化工具来合成准确且详细的复合图像。使用CompCap，我们编纂了CompCap-118K数据集，包含118K个图像-描述对，涵盖六种复合图像类型。我们通过监督微调三种规模的MLLMs（xGen-MM-inst.-4B和LLaVA-NeXT-Vicuna-7B/13B）来验证CompCap-118K的有效性。实证结果表明，CompCap-118K显著提升了MLLMs对复合图像的理解能力，分别在11个基准测试中实现了1.7%、2.0%和2.9%的平均提升。|
|**2024-12-06**|**MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale**|Jarvis Guo et.al.|[2412.05237](http://arxiv.org/abs/2412.05237)|null|开源的多模态大型语言模型（MLLMs）在多模态任务中展现出巨大的潜力。然而，它们的推理能力仍然受到现有指令微调数据集的限制，这些数据集主要来自VQA、AI2D和ChartQA等学术数据集，这些数据集针对的是简单的任务，并且只提供短语级别的答案，没有任何中间推理过程。为了解决这些挑战，我们提出了一种可扩展且成本效益高的方法来构建一个包含丰富中间推理过程的、大规模多模态指令微调数据集。我们仅使用开源模型，创建了一个包含1200万个指令-响应对的数据库，涵盖了多样化的、推理密集型任务，具有详细和可靠的推理过程。实验表明，在这样一个数据集上训练MLLMs可以显著提高推理能力，在MathVerse (+8.1%)、MMMU-Pro (+7%)和MuirBench (+13.3%)等基准测试中实现了最先进的性能。此外，该模型在非推理型基准测试上也表现出显著的提升，最高可达4%。消融实验进一步突出了数据集构建过程中关键组件，如重写和自我过滤的重要性。|
|**2024-12-06**|**BEExformer: A Fast Inferencing Transformer Architecture via Binarization with Multiple Early Exits**|Wazib Ansar et.al.|[2412.05225](http://arxiv.org/abs/2412.05225)|null|大型语言模型（LLMs）基于Transformer在各种应用中取得了尖端成果。然而，它们的巨大规模和处理需求使得在资源受限的设备上部署极为困难。在各种效率考虑中，模型二值化和早期退出（EE）是常见的有效解决方案。然而，二值化可能会由于降低精度而影响梯度估计和参数更新，从而导致性能损失。此外，目前的早期退出机制仍处于研究的初级阶段。为了改善这些问题，我们提出了二值化早期退出Transformer（BEExformer），这是第一个将早期退出与二值化结合用于文本推理的选区学习Transformer架构。它通过到冲激函数的微分二阶近似来改进二值化过程。这使得可以计算关于权重符号和幅度的梯度。与基于绝对阈值的EE不同，所提出的EE机制依赖于中间Transformer块中软路由损失估计的熵的分数减少。虽然二值化使模型大小减少了18.44倍，但早期退出在推理过程中将FLOPs减少了54.85%，甚至通过解决深层网络固有的“过度思考”问题，提高了5.98%的准确率。此外，所提出的BEExformer通过不需要从全精度LLM中进行知识蒸馏来简化训练。在GLUE数据集上的广泛评估与SOTA工作的比较展示了其帕累托最优的性能-效率权衡。|
|**2024-12-06**|**100% Hallucination Elimination Using Acurai**|Michael C. Wood et.al.|[2412.05223](http://arxiv.org/abs/2412.05223)|null|大型语言模型（LLMs）中的幻觉问题仍然是人工智能在企业和其他高风险应用中应用的一个关键障碍。尽管检索增强生成（RAG）系统取得了进展，但当前最先进的方法在生成忠实且事实正确的输出时，即使在提供相关和准确的情况下，也未能超过80%的准确率。在这项工作中，我们引入了Acurai，这是一种新颖的系统方法，通过在输入之前重新格式化查询和上下文数据，在LLMs中实现了100%无幻觉的响应。利用对LLMs内部表示的深入了解、名词短语的主导地位的重要性以及离散功能单元（DFUs）的作用，Acurai确保输入上下文和生成输出之间的一致性。我们使用RAGTruth语料库验证了这种方法，证明了它能够消除GPT-4和GPT-3.5 Turbo的100%幻觉。Acurai为实现一致、准确和忠实的AI响应设定了新的标准，标志着可信AI系统发展的重大进步。|
|**2024-12-06**|**Evaluating and Aligning CodeLLMs on Human Preference**|Jian Yang et.al.|[2412.05210](http://arxiv.org/abs/2412.05210)|null|代码大型语言模型（codeLLMs）在代码生成方面取得了显著进展。大多数之前的与代码相关的基准测试，包括各种编程练习和相应的测试用例，被用作评估codeLLMs性能和能力的共同标准。然而，当前codeLLMs主要关注合成正确的代码片段，忽略了与人类偏好的对齐，其中查询应从实际应用场景中采样，而模型生成的响应应满足人类偏好。为了弥合模型生成响应与人类偏好之间的差距，我们提出了一个严格的人类编纂基准测试CodeArena，以模拟现实世界编程任务的复杂性和多样性，其中包含从用户查询中精心挑选的397个高质量样本，涵盖了40个类别和44种编程语言。此外，我们提出了一个多样化的合成指令语料库SynCode-Instruct（近20B个标记），通过扩展网站上的指令来验证大规模合成指令微调的有效性，其中Qwen2.5-SynCoder完全在合成指令数据上训练，可以达到开源codeLLMs的顶尖性能。结果表明，在基于执行的基准测试和CodeArena之间存在性能差异。我们对40多个LLMs在CodeArena上的系统实验揭示了开源SOTA代码LLMs（例如Qwen2.5-Coder）与专有LLMs（例如，OpenAI o1）之间存在显著的性能差距，突显了与人类偏好对齐的重要性。[footnote：https://codearenaeval.github.io/ ]|
|**2024-12-06**|**A Survey of Large Language Model-Based Generative AI for Text-to-SQL: Benchmarks, Applications, Use Cases, and Challenges**|Aditi Singh et.al.|[2412.05208](http://arxiv.org/abs/2412.05208)|null|文本到SQL系统通过将自然语言查询翻译为结构化查询语言（SQL），促进了与数据库的顺畅交互，弥合了非技术用户与复杂数据库管理系统之间的差距。本综述全面概述了AI驱动的文本到SQL系统的演变，突出了其基础组件、大型语言模型（LLM）架构的进步以及Spider、WikiSQL和CoSQL等数据集在推动进展中的关键作用。我们探讨了文本到SQL在医疗保健、教育和金融等领域的应用，强调了它们在提高数据可访问性方面的变革潜力。此外，我们分析了持续存在的挑战，包括领域泛化、查询优化、支持多轮对话交互以及针对NoSQL数据库和动态现实场景量身定制的数据集有限可用性。为了应对这些挑战，我们概述了未来的研究方向，例如扩展文本到SQL的功能以支持NoSQL数据库，设计用于动态多轮交互的数据集，以及优化系统以适应现实世界的可扩展性和鲁棒性。通过审视当前进展并识别关键差距，本文旨在指导基于LLM的文本到SQL系统下一代的研发与应用。|
|**2024-12-06**|**Are Frontier Large Language Models Suitable for Q&A in Science Centres?**|Jacob Watson et.al.|[2412.05200](http://arxiv.org/abs/2412.05200)|null|本文探讨了前沿大型语言模型（LLMs）在科学中心问答互动中的适用性，旨在提高游客参与度同时保持事实准确性。利用从英国莱斯特国家空间中心收集的问题数据集，我们评估了三个领先模型生成的回答：OpenAI的GPT-4、Claude 3.5 Sonnet和Google Gemini 1.5。每个模型都被要求针对8岁儿童观众提供标准答案和创造性回答，这些回答由空间科学专家根据准确性、参与度、清晰度、新颖性和偏离预期答案的程度进行评估。结果显示，在创造性和准确性之间存在着权衡，尽管Claude在保持清晰度和吸引年轻观众方面超越了GPT和Gemini，甚至在要求生成更富有创造性的回答时也是如此。然而，专家观察到，所有模型中更高的新颖性通常与事实可靠性降低有关。这项研究突出了LLMs在教育环境中的潜力，强调了精心设计提示以平衡参与度和科学严谨性的必要性。|
|**2024-12-06**|**SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot**|Jinlin Wu et.al.|[2412.05187](http://arxiv.org/abs/2412.05187)|**[link](https://github.com/franciszchen/surgbox)**|**手术干预，尤其是在神经科领域，代表复杂且高风险的场景，对手术团队提出了巨大的认知负担。尽管有目的的教育和实践可以增强认知能力，但由于患者安全问题的考虑，手术培训机会仍然有限。为了解决手术培训和手术中的认知挑战，我们提出了SurgBox，一个由代理驱动的沙盒框架，旨在系统性地提高外科医生在沉浸式手术模拟中的认知能力。具体来说，我们的SurgBox利用定制化的检索增强生成（RAG）的大型语言模型（LLMs）来真实地复制各种手术角色，从而为有目的的练习提供逼真的训练环境。特别是，我们设计了手术协同助手（Surgery Copilot），这是一个由AI驱动的助手，能够主动协调手术信息流并支持临床决策，从而减轻手术过程中手术团队的认知负荷。通过整合新颖的长短期记忆（Long-Short Memory）机制，我们的手术协同助手可以有效地在即时程序辅助和全面手术知识之间取得平衡。使用真实的神经外科手术记录进行的广泛实验验证了我们的SurgBox框架在提高手术认知能力和支持临床决策方面的有效性。通过提供针对培训和操作支持的综合性解决方案以解决认知挑战，我们的SurgBox框架推动了外科教育和实践的发展，有可能改变手术结果和医疗质量。代码可在https://github.com/franciszchen/SurgBox获取。**|
|**2024-12-05**|**p-MoD: Building Mixture-of-Depths MLLMs via Progressive Ratio Decay**|Jun Zhang et.al.|[2412.04449](http://arxiv.org/abs/2412.04449)|**[link](https://github.com/mcg-nju/p-mod)**|**尽管多模态大型语言模型（MLLMs）在众多任务中表现出色，但其巨大的训练和推理成本阻碍了其发展。大部分计算量来自于被Transformer解码器处理的视觉标记的庞大数量。在本文中，我们提出通过利用混合深度（MoD）机制来构建高效的MLLMs，其中每个Transformer解码器层选择必要的视觉标记进行处理，同时跳过冗余的标记。然而，将MoD集成到MLLMs中并非易事。为了解决训练和推理稳定性以及有限训练数据带来的挑战，我们对MoD模块进行了两项创新设计：tanh门控权重归一化（TanhNorm）和对称标记重新加权（STRing）。此外，我们观察到视觉标记在深层中的冗余性更高，因此设计了一种渐进比率衰减（PRD）策略，该策略通过偏移余弦调度逐步减少每层的标记保留率。这一关键设计充分发挥了MoD的潜力，显著提升了我们模型的效率和性能。为了验证我们方法的有效性，我们在14个基准测试中，对两个基线模型进行了广泛的实验。我们的模型p-MoD在推理时仅占用了55.6%的TFLOPs和53.8%的KV缓存存储，以及训练时的77.7%的GPU小时，其性能与基线模型相当，甚至在某些情况下超过了基线模型。**|
|**2024-12-05**|**EgoPlan-Bench2: A Benchmark for Multimodal Large Language Model Planning in Real-World Scenarios**|Lu Qiu et.al.|[2412.04447](http://arxiv.org/abs/2412.04447)|null|多模态大型语言模型的兴起，借助大型语言模型的力量，最近展示了卓越的多模态理解和推理能力，预示着人工通用智能新时代的到来。然而，实现通用人工智能不仅需要理解和推理能力，还需要在多样场景中有效规划的能力，这涉及到基于复杂环境做出合理决策以解决现实问题。尽管其重要性不言而喻，但当前多模态大型语言模型在不同场景下的规划能力仍处于探索阶段。在本文中，我们介绍了EgoPlan-Bench2，这是一个严格且全面的基准，旨在评估多模态大型语言模型在广泛现实场景中的规划能力。EgoPlan-Bench2涵盖了涵盖4个主要领域和24个详细场景的日常任务，与人类日常生活紧密相关。EgoPlan-Bench2是通过半自动流程构建的，利用以自我为中心的视频，并辅以人工验证。基于第一人称视角，它反映了人类在日常生活中的问题解决方式。我们评估了21个竞争性的多模态大型语言模型，并深入分析了它们的局限性，揭示它们在现实世界规划中面临重大挑战。为了进一步提高当前多模态大型语言模型的规划能力，我们提出了一种无需训练的方法，通过研究复杂规划中各种多模态提示的有效性，使用多模态思维链（CoT）提示。我们的方法在不额外训练的情况下，将GPT-4V在EgoPlan-Bench2上的性能提高了10.24。我们的工作不仅揭示了当前多模态大型语言模型在规划方面的局限性，还为这一关键领域的未来改进提供了见解。我们已经将数据和代码发布在https://qiulu66.github.io/egoplanbench2/。|
|**2024-12-05**|**Moto: Latent Motion Token as the Bridging Language for Robot Manipulation**|Yi Chen et.al.|[2412.04445](http://arxiv.org/abs/2412.04445)|null|最近，在大量语料库上预训练的大型语言模型在多种自然语言处理任务中取得了显著的成功，且仅需少量微调。这一成功为机器人学带来了新的希望，因为机器人学长期以来一直受限于高成本的动作标签数据。我们提出问题：鉴于大量包含互动相关知识的视频数据作为丰富的“语料库”可用，是否可以有效地将类似的生成式预训练方法应用于增强机器人学习？关键挑战是识别一个有效的自回归预训练表示，以促进机器人操作任务。受人类通过观察动态环境学习新技能的方式的启发，我们认为有效的机器人学习应强调与运动相关的知识，这些知识与低级动作紧密相关，并且与硬件无关，便于将学习到的运动转移到实际机器人动作中。为此，我们引入了Moto，它通过潜在运动标记器将视频内容转换为潜在运动标记序列，以无监督的方式从视频中学习运动的“桥梁”语言。我们通过运动标记自回归预训练Moto-GPT，使其能够捕捉多样的视觉运动知识。预训练后，Moto-GPT展示了产生语义可解释的运动标记、预测合理的运动轨迹以及通过输出似然性评估轨迹合理性等有希望的能力。为了将学习到的运动先验转移到真实机器人动作中，我们实施了一种协同微调策略，无缝地将潜在运动标记预测和真实机器人控制连接起来。大量实验表明，经过微调的Moto-GPT在机器人操作基准测试中表现出卓越的鲁棒性和效率，凸显了它从视频数据到下游视觉操作任务中知识转移的有效性。|
|**2024-12-05**|**Divot: Diffusion Powers Video Tokenizer for Comprehension and Generation**|Yuying Ge et.al.|[2412.04432](http://arxiv.org/abs/2412.04432)|**[link](https://github.com/tencentarc/divot)**|**近年来，在大型语言模型（LLMs）中统一图像理解和生成引起了极大的兴趣。这种不断增长的兴趣促使我们探索将这种统一扩展到视频中。核心挑战在于开发一个通用的视频分词器，它能够捕捉视频的空间特征和时序动态，以获得适合LLMs的表示，并且这些表示可以被进一步解码为逼真的视频片段，从而实现视频生成。在这项工作中，我们介绍了Divot，一种基于扩散的视频分词器，它利用扩散过程进行自监督视频表示学习。我们认为，如果一个视频扩散模型能够通过将视频分词器的特征作为条件来有效地去噪视频片段，那么分词器已经成功地捕捉了鲁棒的空间和时序信息。此外，视频扩散模型本质上充当了解码器，将视频从其表示中解码出来。在Divot分词器的基础上，我们通过视频到文本的自回归和文本到视频的生成，使用高斯混合模型来建模连续值的Divot特征分布，提出了Divot-Vicuna。实验结果表明，我们的基于扩散的视频分词器，当与预训练的LLM集成时，在各种视频理解和生成基准测试中实现了有竞争力的性能。经过指令调整的Divot-Vicuna在视频叙事方面也表现出色，能够生成交错的故事和相应的视频。**|
|**2024-12-05**|**Grounding Descriptions in Images informs Zero-Shot Visual Recognition**|Shaunak Halbe et.al.|[2412.04429](http://arxiv.org/abs/2412.04429)|**[link](https://github.com/shaunak27/grain-clip)**|**视觉语言模型（VLMs）如CLIP因其能够在开放词汇概念上执行零样本视觉识别而备受青睐。这是通过选择与查询图像文本表示最相似的物体类别来实现的。尽管在某些领域取得了成功，但这种方法在识别细粒度实体以及泛化到训练分布未捕获的未见概念方面存在困难。近期的工作试图通过在测试时整合类别描述来减轻这些挑战，尽管取得了有限的改进。我们将这些有限的收益归因于图像和描述表示之间的基本不匹配，这种不匹配根植于CLIP的预训练结构。在这篇论文中，我们提出了GRAIN，这是一种新的预训练策略，旨在同时在对细粒度和粗粒度级别上对齐表示。我们的方法学会联合地将文本描述定位到图像区域，并将总体标题与全局图像表示对齐。为了推动这种预训练，我们利用冻结的多模态大型语言模型（MLLMs）来生成大规模合成注释。我们在11个不同的图像分类数据集上展示了我们模型相较于现有最先进方法的零样本性能提升。此外，我们引入了Products-2023，这是一个新整理的、手动标记的数据集，包含新颖的概念，并通过在该数据集上进行基准测试展示了我们模型识别这些概念的能力。我们模型在其他下游任务（如检索）上取得的显著改进进一步突显了我们方法学习的表示的高质量。代码可在https://github.com/shaunak27/grain-clip上获取。**|
|**2024-12-05**|**Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion**|Jiuhai Chen et.al.|[2412.04424](http://arxiv.org/abs/2412.04424)|**[link](https://github.com/jiuhaichen/florence-vl)**|**我们介绍了一组新的多模态大型语言模型（MLLMs），即Florence-VL，它由Florence-2生成视觉基础模型产生，具有丰富的视觉表示。与广泛使用的由对比学习训练的CLIP风格视觉Transformer不同，Florence-2能够捕捉不同层次和方面的视觉特征，这使得它们更加灵活，可以适应各种下游任务。我们提出了一种新颖的特征融合架构和一种创新的训练方案，有效地将Florence-2的视觉特征整合到预训练的LLM（如Phi 3.5和LLama 3）中。特别是，我们提出了“深度-呼吸融合（DBFusion）”来融合从不同深度和多个提示中提取的视觉特征。我们的模型训练包括整个模型的端到端预训练，随后是在精心设计的包含高质量图像标题和指令调整对的多样化开源数据集上对投影层和LLM进行微调。我们对Florence-VL的视觉特征的定量分析和可视化表明，它在视觉-语言对齐方面优于流行的视觉编码器，其中丰富的深度和呼吸发挥了重要作用。Florence-VL在涵盖一般视觉问答（VQA）、感知、幻觉、OCR、图表、知识密集型理解等多种多模态和视觉中心基准测试中，相对于现有的最先进MLLMs实现了显著的改进。为了促进未来的研究，我们的模型和完整的训练方案已经开源。https://github.com/JiuhaiChen/Florence-VL**|
|**2024-12-05**|**Targeting the Core: A Simple and Effective Method to Attack RAG-based Agents via Direct LLM Manipulation**|Xuying Li et.al.|[2412.04415](http://arxiv.org/abs/2412.04415)|null|人工智能代理，由大型语言模型（LLMs）驱动，通过实现无缝、自然和情境感知的通信，已经改变了人机交互。虽然这些进步提供了巨大的实用性，但它们也继承了并放大了固有的安全风险，如偏见、公平性、幻觉、隐私侵犯和缺乏透明度。本文调查了一个关键漏洞：针对AI代理中LLM核心的对抗性攻击。具体而言，我们测试了一个假设，即一个欺骗性的简单对抗性前缀，例如“忽略文档”，可以通过绕过其情境保护措施，迫使LLMs生成危险或不希望的结果。通过实验，我们证明了高攻击成功率（ASR），揭示了现有LLM防御的脆弱性。这些发现强调了迫切需要针对LLM层面以及更广泛的基于代理的架构，采取稳健的多层安全措施来减轻漏洞。|
|**2024-12-05**|**Retrieval-Augmented Machine Translation with Unstructured Knowledge**|Jiaan Wang et.al.|[2412.04342](http://arxiv.org/abs/2412.04342)|**[link](https://github.com/krystalan/RAGtrans)**|**检索增强生成（RAG）通过引入额外信息来提升大型语言模型（LLMs）。在机器翻译（MT）领域，以往的研究通常从配对MT语料库中检索上下文示例，或从知识图中检索特定领域的知识，以增强模型的MT能力。然而，大量的世界知识组织在非结构化文档中，并且可能在不同语言之间没有完全配对。在本文中，我们研究了使用非结构化文档的检索增强MT。具体来说，我们构建了RAGtrans，这是第一个用于训练和评估LLMs检索增强MT能力的基准。RAGtrans包含了通过GPT-4o和人工翻译收集的79K MT样本。此外，还提供了不同语言的文档，为这些样本提供知识。基于RAGtrans，我们进一步提出了一种多任务训练方法，教导LLMs如何在翻译过程中使用多语言文档中的信息。该方法利用现有的多语言语料库创建辅助训练目标，无需额外的标注需求。大量实验表明，该方法将LLMs的BLEU得分提高了1.58-3.09，COMET得分提高了1.00-2.03。**|
|**2024-12-05**|**Liquid: Language Models are Scalable Multi-modal Generators**|Junfeng Wu et.al.|[2412.04332](http://arxiv.org/abs/2412.04332)|null|我们提出了Liquid，一种将视觉理解与生成无缝集成的自回归生成范式。Liquid通过将图像分词成离散代码，并在共享的特征空间中学习这些代码嵌入和文本标记，从而在视觉和语言之间实现整合。与之前的跨模态大型语言模型（MLLM）不同，Liquid使用单个大型语言模型（LLM）来实现这种整合，消除了使用外部预训练的视觉嵌入（如CLIP）的需求。Liquid首次揭示了一种缩放定律，即随着模型规模的增加，统一训练视觉和语言任务所带来的性能下降不可避免地减小。此外，统一的标记空间使得视觉生成和理解任务可以相互增强，有效地消除了早期模型中常见的干扰。我们表明，现有的LLM可以作为Liquid的强大基础，节省100倍的训练成本，同时在多模态能力上优于Chameleon，并保持与主流LLM（如LLAMA2）相当的语言性能。Liquid还优于SD v2.1和SD-XL（在MJHQ-30K上的FID为5.47），在视觉-语言和纯文本任务上都表现出色。这项工作证明了LLAMA3.2和GEMMA2等LLM是强大的多模态生成器，为增强视觉-语言理解和生成提供了可扩展的解决方案。代码和模型将发布。|
|**2024-12-05**|**The Hyperfitting Phenomenon: Sharpening and Stabilizing LLMs for Open-Ended Text Generation**|Fredrik Carlsson et.al.|[2412.04318](http://arxiv.org/abs/2412.04318)|null|本文介绍了在非常小的数据集上对过拟合预训练大型语言模型（LLMs）的出人意料的泛化结果。在开放式文本生成的背景下，有记录表明LLMs倾向于生成重复和乏味的序列，这种现象在使用贪婪解码生成时尤为明显。即使是最先进的、包含数十亿参数的LLMs，它们在大型数据集上通过下一标记预测进行训练，这一问题依然存在。我们发现，通过进一步微调这些模型，使其在少量样本集上达到几乎为零的训练损失——我们称之为超拟合——可以极大地增强其长序列生成能力。使用这些超拟合模型进行贪婪解码，甚至在多样性和人类偏好方面都优于长序列的Top-P采样。这一现象适用于各种大小、不同领域的LLMs，甚至包括自回归图像生成。我们进一步发现，这一现象与Grokking和双重下降现象有显著不同。令人惊讶的是，我们的实验表明，超拟合模型很少陷入它们训练过的重复序列，甚至明确阻止这些序列也会产生高质量的输出。所有超拟合模型都产生极低熵的预测，通常将几乎全部概率分配给单个标记。|
|**2024-12-04**|**From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents**|Xinyi Mou et.al.|[2412.03563](http://arxiv.org/abs/2412.03563)|**[link](https://github.com/fudandisc/socialagent)**|传统的社会学研究通常依赖人类参与，虽然有效，但成本高昂、难以扩展，且存在伦理问题。近年来，大型语言模型（LLMs）的进步突显了它们模拟人类行为的能力，使得个体反应的复制和跨学科研究得以进行。在本文中，我们对这一领域进行了全面调查，展示了由LLMs赋能的代理推动的模拟近期进展。我们将模拟分为三类：（1）个体模拟，模仿特定个体或人口群体；（2）情景模拟，多个代理在特定情境中协作实现目标；（3）社会模拟，模拟代理社会中的互动，以反映现实世界动态的复杂性和多样性。这些模拟从详细的个体建模到大规模社会现象，呈现出一种渐进性。我们对每种模拟类型进行了详细讨论，包括模拟的架构或关键组件、目标或情景的分类以及评估方法。之后，我们总结了常用的数据集和基准。最后，我们讨论了这三种类型模拟的趋势。相关资源的存储库位于{\url{https://github.com/FudanDISC/SocialAgent}}。|
|**2024-12-04**|**SPICE: Smart Projection Interface for Cooking Enhancement**|Vera Prohaska et.al.|[2412.03551](http://arxiv.org/abs/2412.03551)|null|可触摸用户界面（TUI）用于人机交互（HCI），旨在向用户提供数字信息的物理表示，以克服基于屏幕界面的局限性。尽管文献中存在许多引人注目的TUI演示，但针对日常双手任务和过程，如烹饪的TUI研究却很少。为了填补这一空白，我们提出了SPICE（智能投影界面，用于烹饪增强）。SPICE在厨房环境中研究TUI，旨在将食谱遵循体验从简单的基于文本转变为直观互动。SPICE包括跟踪系统、基于代理的软件和视觉大型语言模型，以创建和解释一个将食谱信息直接投影到烹饪表面的厨房环境。我们对SPICE和基于文本的食谱遵循进行了30名参与者的比较可用性研究，评估了任务难度、总时长和效率，以及用户信心和味觉感知。结果表明，SPICE使参与者能够在更短的时间内完成食谱，同时提高了自我报告的效率、信心和味觉。尽管如此，参与者报告说总体难度没有变化，这是未来研究的方向。总的来说，SPICE项目展示了使用TUI改善日常活动的潜力，为HCI和新型计算界面的未来研究铺平了道路。|
|**2024-12-04**|**Evaluating Gender Bias Transfer between Pre-trained and Prompt-Adapted Language Models**|Natalie Mackraz et.al.|[2412.03537](http://arxiv.org/abs/2412.03537)|null|大型语言模型（LLMs）正越来越多地被调整为具有特定任务性，以便在现实世界的决策系统中部署。先前的一些研究通过研究微调适配策略对模型公平性的影响，来调查偏见迁移假说（BTH），发现预训练的掩码语言模型在微调适配时的公平性影响有限。在本工作中，我们扩展了对BTH的研究，将其应用于提示适应下的因果模型，因为提示是一种易于访问且计算高效的部署模型的方法。与先前的研究不同，我们通过一个代词共指消解任务，建立了一个事实：预训练的Mistral、Falcon和Llama模型中的内在偏见与在相同模型零样本和少样本提示时的偏见高度相关（相关系数rho >= 0.94）。此外，我们发现，即使LLMs被特别提示以展示公平或偏见行为（rho >= 0.92），以及少样本长度和刻板化组成发生变化（rho >= 0.97），偏见迁移仍然高度相关。我们的发现强调了确保预训练LLMs公平性的重要性，特别是在它们后来通过提示适配执行下游任务时。|
|**2024-12-04**|**A Review on Scientific Knowledge Extraction using Large Language Models in Biomedical Sciences**|Gabriel Lino Garcia et.al.|[2412.03531](http://arxiv.org/abs/2412.03531)|null|这篇论文回顾了大型语言模型（LLMs）在生物医学领域的最新应用，探讨了它们在自动化复杂任务，如从生物医学文献数据库中提取证据和数据方面的有效性。虽然LLMs展现出巨大的潜力，但仍然存在重大挑战，包括幻觉、上下文理解和跨多种医疗任务泛化能力的问题。我们指出了当前研究文献中的关键差距，尤其是需要统一的基准来标准化评估并确保实际应用中的可靠性。此外，我们提出了未来研究方向，强调将检索增强生成（RAG）等最先进技术集成到LLMs中，以提高证据综合性能。通过解决这些挑战并利用LLMs的优势，我们旨在提高获取医学文献的途径并促进医疗保健领域的重大发现。|
|**2024-12-04**|**FANAL -- Financial Activity News Alerting Language Modeling Framework**|Urjitkumar Patel et.al.|[2412.03527](http://arxiv.org/abs/2412.03527)|null|在快速发展的金融领域，准确及时地解读市场新闻对于需要应对不可预测事件的相关利益方至关重要。本文介绍了FANAL（金融活动新闻警报语言建模框架），这是一个专门为实时金融事件检测和分析而设计的基于BERT的框架，将新闻分为十二个不同的金融类别。FANAL利用通过XGBoost处理的银标签数据进行训练，并采用先进的微调技术，同时结合了ORBERT（概率比BERT），这是一种新的BERT变体，通过ORPO（概率比偏好优化）进行微调，以实现更高级别的类别概率校准和与金融事件相关性的对齐。我们评估了FANAL的性能，并将其与领先的顶级大型语言模型进行了比较，包括GPT-4o、Llama-3.1 8B和Phi-3，证明了其卓越的准确性和成本效益。这一框架为金融智能和响应性设定了新的标准，在性能和成本上均显著超越现有模型。|
|**2024-12-04**|**You're (Not) My Type -- Can LLMs Generate Feedback of Specific Types for Introductory Programming Tasks?**|Dominic Lohr et.al.|[2412.03516](http://arxiv.org/abs/2412.03516)|null|背景：反馈作为学习中最具影响力的因素之一，一直是众多研究的热点。它在教育技术系统的发展中起着关键作用，并传统上基于由专家及其经验定义的决定性反馈。然而，随着生成式AI，尤其是大型语言模型（LLMs）的兴起，我们预计作为学习系统一部分的反馈将发生转变，尤其是在编程的背景下。过去，为编程学习者自动生成反馈具有挑战性。LLMs可能创造新的可能性，提供比以往任何时候都更丰富、更个性化的反馈。  目标：本文旨在使用LLMs为入门级编程任务生成特定类型的反馈。我们重新审视现有的反馈分类法，以捕捉生成的反馈的具体性，例如随机性、不确定性和变化程度。  方法：我们针对真实的学生的程序，迭代设计用于生成特定类型反馈的提示（作为现有反馈分类法的一部分）。然后，我们评估生成的输出，并确定其反映特定反馈类型的程度。  结果和结论：本研究加深了对不同反馈维度和特性的理解。结果对未来的反馈研究有影响，例如关于反馈效果和学习者信息需求的研究。此外，本研究还为开发新的工具和学习系统提供了基础，包括由AI生成的反馈，这些系统面向初学者程序员。|
|**2024-12-04**|**Training-Free Mitigation of Language Reasoning Degradation After Multimodal Instruction Tuning**|Neale Ratzlaff et.al.|[2412.03467](http://arxiv.org/abs/2412.03467)|null|多模态模型通常将强大的大型语言模型（LLM）与视觉编码器相结合，然后通过指令微调在多模态数据上训练。虽然这个过程使LLM适应了多模态环境，但尚不清楚这种适应是否会损害它们原始的语言推理能力。在本工作中，我们探讨了多模态指令微调对语言推理性能的影响。我们关注的是LLaVA，这是一个领先的融合了Vicuna或Mistral等LLM与CLIP视觉编码器的多模态框架。我们将原始LLM与它们的跨模态适应版本在八个语言推理任务中的表现进行了比较。我们的实验产生了几个关键见解。首先，多模态学习对Vicuna和Mistral的影响不同：我们在Mistral上观察到语言推理的下降，但在大多数任务上Vicuna有所改进。其次，尽管多模态指令学习在数学推理任务（例如GSM8K）上始终会降低性能，但它增强了常识推理任务（例如CommonsenseQA）的性能。最后，我们证明了无训练模型合并技术可以有效地减轻在多模态适应的Mistral中观察到的语言推理下降，甚至可以提高视觉任务的表现。|
|**2024-12-04**|**From Words to Workflows: Automating Business Processes**|Laura Minkova et.al.|[2412.03446](http://arxiv.org/abs/2412.03446)|null|随着企业越来越依赖自动化以简化运营，机器人流程自动化（RPA）的局限性逐渐显现，尤其是其依赖专家知识和无法处理复杂决策任务的问题。近年来，人工智能（AI）的进步，特别是生成式AI（GenAI）和大型语言模型（LLMs），为智能自动化（IA）铺平了道路，IA通过集成认知能力来克服RPA的不足。本文介绍了一种名为Text2Workflow的新方法，它可以从自然语言用户请求中自动生成工作流程。与传统的自动化方法不同，Text2Workflow提供了一种通用的解决方案，用于自动化任何业务流程，将用户输入转换为表示为JavaScript对象表示法（JSON）格式的可执行步骤序列。利用LLMs的决策和指令遵循能力，该方法提供了一种可扩展、可适应的框架，使用户能够以最小的手动干预可视化和执行工作流程。这项研究概述了Text2Workflow方法及其在自动化复杂业务流程方面的更广泛影响。|
|**2024-12-04**|**RedStone: Curating General, Code, Math, and QA Data for Large Language Models**|Yaoyao Chang et.al.|[2412.03398](http://arxiv.org/abs/2412.03398)|null|在高质量、精心挑选的数据集上预训练大型语言模型（LLMs）已被广泛认为对于提高其性能和泛化能力至关重要。本研究探讨了Common Crawl作为预训练LLMs的全面且灵活资源的未被充分利用的潜力，既针对通用语言理解也针对专业领域知识。我们引入了RedStone，这是一个创新且可扩展的管道，旨在从Common Crawl中提取和处理数据，便于创建广泛多样的预训练数据集。与传统的数据集不同，后者通常需要昂贵的编辑和特定领域的专业知识，RedStone利用Common Crawl的广度，提供针对广泛领域的定制化数据集。在本工作中，我们通过构建涵盖多个领域的预训练数据集来展示其能力，包括通用语言理解、代码、数学和问答任务。RedStone的灵活性允许它轻松适应其他专业领域，显著降低了创建有价值特定领域数据集的门槛。我们的发现表明，通过像RedStone这样的有效管道，Common Crawl可以作为丰富的、可再生的预训练数据源，为LLMs在领域适应和知识发现方面开辟新的途径。这项工作也强调了创新数据采集策略的重要性，并突出了网络规模数据在LLMs持续进化中的强大资源作用。RedStone代码和数据样本将公开提供在\url{https://aka.ms/redstone}。|
|**2024-12-04**|**WiS Platform: Enhancing Evaluation of LLM-Based Multi-Agent Systems Through Game-Based Analysis**|Chengwei Hu et.al.|[2412.03359](http://arxiv.org/abs/2412.03359)|null|近期，基于大型语言模型（LLMs）的自主多智能体系统（MAS）的进步，增强了应用场景并提升了LLMs处理复杂任务的能力。尽管现有研究显示出有效性，但仍然明显存在评估、分析和复现LLM-based MAS的困难。在本文中，为了促进LLM-based MAS的研究，我们介绍了一个基于“谁是间谍？”（WiS）游戏的开放、可扩展和实时更新的平台，用于访问和分析基于LLMs的MAS。我们的平台具有三个主要优点：（1）支持Hugging Face上可用的模型的统一模型评估界面；（2）实时更新的排行榜用于模型评估；（3）全面评估包括游戏胜率、攻击、防御策略和LLMs的推理。为了严格测试WiS，我们进行了涵盖各种开源和闭源LLMs的广泛实验，我们发现不同的代理在游戏中表现出独特且引人入胜的行为。实验结果证明了我们的平台在评估LLM-based MAS中的有效性和效率。我们的平台及其文档可在\url{https://whoisspy.ai/}公开访问。|
|**2024-12-03**|**T-REG: Preference Optimization with Token-Level Reward Regularization**|Wenxuan Zhou et.al.|[2412.02685](http://arxiv.org/abs/2412.02685)|null|基于人类反馈的强化学习（RLHF）对于将大型语言模型（LLMs）与人类价值观对齐至关重要。传统上，RLHF涉及生成对查询的响应，并使用奖励模型对整个响应分配奖励。然而，由于该方法依赖于单一且稀疏的奖励，这使得模型难以识别序列中哪些部分对最终奖励贡献最大。近期的方法试图通过引入token级奖励来解决这个问题。然而，这些方法通常依赖于训练好的信用分配模型或AI标注者，这引发了关于奖励质量和可靠性的担忧。在本文中，我们提出了token级奖励正则化（T-REG），这是一种利用序列级和token级奖励进行偏好优化的新方法。利用LLMs的自我改进能力，我们的方法使用对比提示，使LLMs能够自我生成token级奖励。这些自我生成的奖励随后充当奖励正则化，引导模型更有效地分配序列级奖励到各个token。这促进了更好的token级信用分配并提高了对齐性能。在包括Alpaca Eval 2和Arena-Hard在内的指令遵循基准测试中进行的实验表明，我们的方法在性能上分别比基线方法高出3.8%和4.4%。我们将发布代码和模型在https://github.com/wzhouad/T-REG上。|
|**2024-12-03**|**Mind the Gap: Examining the Self-Improvement Capabilities of Large Language Models**|Yuda Song et.al.|[2412.02674](http://arxiv.org/abs/2412.02674)|null|自我改进是大型语言模型（LLM）预训练、后训练和测试时推理中的一个机制。我们探索了一个框架，其中模型验证其自己的输出，根据这种验证过滤或重新加权数据，并提炼过滤后的数据。尽管已经取得了一些经验上的成功，但对其根本理解仍然不足。在这项工作中，我们开始对LLM自我改进进行全面的、模块化和受控的研究。我们为自我改进提供了一个数学公式，它主要受一个量控制，我们将该量形式化为生成-验证差距。通过使用各种模型家族和任务的实验，我们发现自我改进存在一个缩放现象——生成-验证差距的变体随着模型预训练的浮点运算量单调增长。我们还考察了自我改进何时可行，一个迭代自我改进过程以及提高其性能的方法。我们的发现不仅推进了对LLM自我改进的理解，具有实际意义，而且为未来对其能力和边界的研究开辟了众多途径。|
|**2024-12-03**|**LLM-Enhanced Path Planning: Safe and Efficient Autonomous Navigation with Instructional Inputs**|Pranav Doma et.al.|[2412.02655](http://arxiv.org/abs/2412.02655)|null|基于自然语言指令引导的自主导航对于改善人机交互和实现在动态环境中的复杂操作至关重要。尽管大型语言模型（LLMs）并非天生用于规划，但它们可以通过提供指导和告知约束来显著提高规划效率，以确保安全。本文介绍了一种规划框架，该框架将LLMs与二维占用栅格图和自然语言命令集成，以提高资源受限环境中的空间推理和任务执行。通过分解高级指令和实时环境数据，该系统为拾取和放置任务生成结构化的导航计划，包括避障、目标优先级和自适应行为。该框架动态重新计算路径以应对环境变化，并符合隐含的社会规范以实现无缝的人机交互。我们的结果表明，LLMs具有设计情境感知系统以增强工业和动态环境中的导航效率和安全的潜力。|
|**2024-12-03**|**Time-Reversal Provides Unsupervised Feedback to LLMs**|Yerram Varun et.al.|[2412.02626](http://arxiv.org/abs/2412.02626)|null|大型语言模型（LLMs）通常被训练来预测时间的正向方向。然而，最近的研究表明，通过提示这些模型回顾并批评它们自己的生成内容可以产生有用的反馈。受此启发，我们探讨了LLMs是否能够被赋予反向（预测和评分）思考的能力，以提供补充正向LLMs的无监督反馈。为此，我们引入了时间反转语言模型（TRLMs），当给定响应条件时，它们可以评分和生成查询，从而在时间反向方向上有效工作。此外，为了有效地推断查询到响应的方向，我们从零开始预训练和微调了一个语言模型（TRLM-Ba），使用反向标记顺序。我们通过实验（在一个风格化的环境中进行理论证明）表明，当用于根据响应对多个正向生成进行再排名时，时间反转模型确实可以补充正向模型的预测。我们在广泛使用的AlpacaEval排行榜上获得了高达5%的改进，超过了使用自我对数困惑度评分的N-best再排名的最佳基线。我们进一步表明，TRLM评分优于给查询响应的常规正向评分，在引用生成和段落检索等应用中带来了显著收益。接下来，我们利用TRLM的生成能力来增强或为LLM的输入安全过滤器提供无监督反馈，展示了在几项针对流行的JailbreakBench排行榜上发布的攻击中，错误否定率大幅降低，而对错误肯定率的影响可以忽略不计。|
|**2024-12-03**|**Improving Dynamic Object Interactions in Text-to-Video Generation with AI Feedback**|Hiroki Furuta et.al.|[2412.02617](http://arxiv.org/abs/2412.02617)|null|大型文本到视频模型在众多下游应用中具有巨大潜力。然而，这些模型在准确描绘动态物体交互方面存在困难，往往导致动作不真实和频繁违反现实物理规律。一种受大型语言模型启发的解决方案是通过外部反馈将生成的输出与期望结果对齐。这使得模型能够自主地改进其响应，消除了大量手动数据收集的需要。在本工作中，我们研究了利用反馈来增强文本到视频模型中物体动态的方法。我们试图回答一个关键问题：哪些类型的反馈，与哪些特定的自我改进算法相结合，可以最有效地提高文本-视频对齐和现实物体交互？我们首先推导出用于文本到视频模型离线强化学习微调的统一概率目标。这种观点突出了如何在现有算法（如KL正则化和策略投影）的设计元素中，作为一个统一框架中的特定选择。然后，我们使用推导出的方法来优化一组文本-视频对齐指标（例如，CLIP分数、光流），但注意到它们往往无法与人类对生成质量的感知相一致。为了解决这一限制，我们提出利用视觉语言模型提供更细致的反馈，特别是针对视频中的物体动态。我们的实验表明，我们的方法可以有效地优化各种奖励，二元AI反馈驱动视频质量动态交互方面的最显著改进，这一点通过AI和人类评估都得到了证实。值得注意的是，当我们使用从AI反馈中导出的奖励信号时，尤其是在涉及多个物体复杂交互和物体坠落等现实描绘的情景中，我们观察到了显著的收益。|
|**2024-12-03**|**AV-Odyssey Bench: Can Your Multimodal LLMs Really Understand Audio-Visual Information?**|Kaixiong Gong et.al.|[2412.02611](http://arxiv.org/abs/2412.02611)|null|近期，多模态大型语言模型（MLLMs），如GPT-4o、Gemini 1.5 Pro和Reka Core，扩展了其功能，包括视觉和听觉模态。虽然这些模型在广泛的视听应用中表现出令人印象深刻的能力，但我们的DeafTest研究表明，MLLMs在人类认为简单的任务上往往表现不佳：1）判断两个声音中哪个更响亮，2）判断两个声音中哪个音调更高。受这些观察的启发，我们引入了AV-Odyssey Bench，这是一个综合性的视听基准，旨在评估这些MLLMs是否真正理解视听信息。该基准包含4,555个精心设计的问题，每个问题都融合了文本、视觉和听觉成分。为了成功推断答案，模型必须有效地利用视觉和听觉输入中的线索。为了确保对MLLM响应的精确和客观评估，我们将问题设计为多项选择，从而消除了人工评估或LLM辅助评估的需求。我们对一系列闭源和开源模型进行了基准测试，并总结了观察结果。通过揭示当前模型的局限性，我们旨在为未来的数据集收集和模型开发提供有用的见解。|
|**2024-12-03**|**Interpretable Company Similarity with Sparse Autoencoders**|Marco Molinari et.al.|[2412.02605](http://arxiv.org/abs/2412.02605)|null|在金融领域，确定公司相似性是一项至关重要的任务，它支撑着对冲、风险管理、投资组合多元化等多个方面。从业者通常依赖行业和产业分类来衡量相似性，例如SIC代码和GICS代码，前者由美国证券交易委员会（SEC）使用，后者在投资界得到广泛应用。将公司描述的嵌入进行聚类已被提出作为一种确定公司相似性的潜在技术，但标记嵌入的可解释性缺乏对在高风险环境下应用构成了重大障碍。稀疏自动编码器（Sparse Autoencoders，SAE）在通过分解大型语言模型（LLM）的激活为可解释特征来增强LLM的可解释性方面已显示出希望。在本文中，我们探讨了使用SAE特征来衡量公司相似性，并将它们与（1）SIC代码和（2）主要群体代码进行了基准测试。我们得出结论，SAE特征可以复制甚至超越行业分类，在量化公司基本特征方面，通过衡量月度收益的相关性（相似性的代理指标）和协整的损益（PnL）来实现。|
|**2024-12-03**|**CEGI: Measuring the trade-off between efficiency and carbon emissions for SLMs and VLMs**|Abhas Kumar et.al.|[2412.02602](http://arxiv.org/abs/2412.02602)|null|本文分析了小型语言模型（SLMs）和视觉语言模型（VLMs）的性能，并评估了模型性能与碳排放之间的权衡，涉及4项基本任务：图像描述、视觉问答（VQA）、对话摘要和文本到SQL转换。选取了属于Qwen和LLaMA架构家族的各种SLMs和VLMs，并评估了基于模型大小（参数数量、量化级别和微调参数）的变体。计算了模型变体的性能和碳排放。为了量化模型性能与碳排放之间的权衡，我们引入了一个新的指标，称为CEGI（碳效率增益指数）。这个指标表示每百万可训练参数单位百分比增益的碳排放。这个指标提供了一个标准化的度量，用于比较模型在性能改进相对于其环境成本方面的效率。实验结果表明，微调SLMs和VLMs可以达到与大语言模型（LLMs）相当的性能水平，同时产生显著较少的碳排放。我们的研究结果表明，从更大模型中获得的边际准确率增益并不能证明其碳排放的大幅增加是合理的。利用较低的位量化级别，所提出的指标进一步提高了能源效率，同时没有影响性能。这项研究突出了在高性能和环境可持续性之间取得平衡的重要性。它为选择适合环保AI开发的模型提供了一个有价值的指标。|
|**2024-12-03**|**PrefixLLM: LLM-aided Prefix Circuit Design**|Weihua Xiao et.al.|[2412.02594](http://arxiv.org/abs/2412.02594)|null|前缀电路是数字加法器的基本组件，由于它们在计算进位信号方面的效率，在数字系统中得到广泛应用。合成最小化面积和延迟的前缀电路对于提升现代计算机系统的性能至关重要。最近，大型语言模型（LLMs）在执行文本生成任务方面展现出了令人惊讶的能力。我们提出了PrefixLLM，它利用LLMs进行前缀电路的合成。PrefixLLM将前缀电路合成任务转化为一种结构化文本生成问题，称为结构化前缀电路表示（SPCR），并引入了一个迭代框架来自动准确地生成有效的SPCRs。我们进一步提出了一种设计空间探索（DSE）框架，该框架使用LLMs迭代搜索面积和延迟优化的前缀电路。与现有技术相比，PrefixLLM在相同的延迟约束下可以将面积降低3.70%。这项工作突出了LLMs在算术电路合成中的应用，这些应用可以转化为结构化文本生成。|
|**2024-12-03**|**OCR Hinders RAG: Evaluating the Cascading Impact of OCR on Retrieval-Augmented Generation**|Junyuan Zhang et.al.|[2412.02592](http://arxiv.org/abs/2412.02592)|**[link](https://github.com/opendatalab/OHR-Bench)**|**检索增强生成（RAG）通过整合外部知识来增强大型语言模型（LLMs），以减少幻觉并吸收最新信息而不需要重新训练。作为RAG的一个重要部分，外部知识库通常通过使用光学字符识别（OCR）从非结构化的PDF文档中提取结构化数据来构建。然而，由于OCR预测的不完美以及结构化数据固有的非均匀表示，知识库不可避免地包含各种OCR噪声。在本文中，我们介绍了OHRBench，这是第一个用于理解OCR对RAG系统级联影响的基准。OHRBench包括从六个真实世界RAG应用领域精心挑选的350个非结构化PDF文档，以及从文档中的多模态元素中衍生出的问答，挑战了现有用于RAG的OCR解决方案。为了更好地理解OCR对RAG系统的影响，我们确定了两种主要的OCR噪声类型：语义噪声和格式噪声，并应用扰动生成了一系列具有不同程度每种OCR噪声的结构化数据。使用OHRBench，我们首先对当前的OCR解决方案进行了全面评估，并揭示了没有一种方案能够为RAG系统构建高质量的知识库。然后，我们系统地评估了这两种噪声类型的影响，并展示了RAG系统的脆弱性。此外，我们讨论了在RAG系统中不使用OCR而采用视觉-语言模型（VLMs）的潜力。代码：https://github.com/opendatalab/OHR-Bench**|
|**2024-11-29**|**T2Vid: Translating Long Text into Multi-Image is the Catalyst for Video-LLMs**|Shukang Yin et.al.|[2411.19951](http://arxiv.org/abs/2411.19951)|**[link](https://github.com/xjtupanda/t2vid)**|**多模态大型语言模型（MLLMs）在图像领域的成功引起了研究界的广泛关注。借鉴以往的成功经验，研究人员最近探索将这一成功扩展到视频理解领域。除了从头开始训练外，一种高效的方法是利用预训练的图像-LLMs，从而产生了两种主流方法，即零样本推理和基于视频数据的进一步微调。在这项工作中，我们对这些方法的研究得出了一种有效的数据增强方法。我们首先对零样本推理方法进行了更深入的检查，并识别出两个限制，即泛化能力有限和缺乏时间理解能力。因此，我们进一步研究了微调方法，并发现当简单使用所有视频数据样本时，学习效率较低，这可以归因于指令多样性的缺乏。针对这个问题，我们开发了一种称为T2Vid的方法，用于生成类似视频的样本，以丰富训练语料库中的指令多样性。整合这些数据使得训练方案既简单又高效，通过仅用15%的样本量进行训练，就能达到与使用完整视频数据集相当甚至更好的性能。同时，我们发现所提出的方案可以在不使用长视频样本的情况下提升长视频理解性能。我们希望我们的研究能够激发更多关于使用MLLMs进行视频理解和高质量数据管理的思考。代码已发布在https://github.com/xjtupanda/T2Vid。**|
|**2024-11-29**|**Critical Tokens Matter: Token-Level Contrastive Estimation Enhances LLM's Reasoning Capability**|Zicheng Lin et.al.|[2411.19943](http://arxiv.org/abs/2411.19943)|null|大型语言模型（LLMs）在推理任务上表现出色。它们通过自回归标记生成来构建推理轨迹，从而发展出一套连贯的思维链条。在本工作中，我们探讨了单个标记对推理任务最终结果的影响。我们发现了“关键标记”的存在，这些标记会导致LLMs中产生错误的推理轨迹。具体来说，我们发现当LLMs被强迫解码其他标记而不是关键标记时，往往会产生积极的结果。受此启发，我们提出了一种新的方法——cDPO，旨在在对齐过程中自动识别和执行对关键标记的标记级奖励。具体来说，我们开发了一种对比估计方法来自动识别关键标记。这是通过比较正负模型的生成可能性来实现的。为此，我们分别对正负模型在不同推理轨迹上进行微调，从而使它们能够识别出导致错误结果的错误轨迹中的关键标记。此外，为了在对齐过程中进一步使模型与关键标记信息对齐，我们将传统的DPO算法扩展到标记级DPO，并利用上述正负模型之间的差异似然作为标记级DPO学习的重要权重。在GSM8K和MATH500基准测试中，使用两个广泛使用的模型Llama-3（8B和70B）和deepseek-math（7B）进行的实验结果表明，所提出的cDPO方法的有效性。|
|**2024-11-29**|**VLSBench: Unveiling Visual Leakage in Multimodal Safety**|Xuhao Hu et.al.|[2411.19939](http://arxiv.org/abs/2411.19939)|null|多模态大型语言模型（MLLMs）的安全性担忧在各个应用领域逐渐成为了一个重要问题。令人惊讶的是，以往的研究指出了一种反直觉的现象，即使用文本未学习（textual unlearning）来调整MLLMs，其安全性表现与使用图文对（image-text pairs）训练的MLLMs相当。为了解释这一反直觉的现象，我们发现在现有的多模态安全基准中存在视觉安全信息泄露（VSIL）问题，即图像中潜在的风险和敏感内容在文本查询中已经暴露出来。这样一来，MLLMs可以轻易地根据文本查询拒绝这些敏感的图文查询。然而，在现实场景中，没有VSIL的图文对很常见，而被现有的多模态安全基准所忽视。为此，我们构建了多模态视觉无泄露安全基准（VLSBench），该基准包含2.4k个图文对，旨在防止视觉安全信息从图像泄露到文本查询。实验结果表明，VLSBench对开源和闭源MLLMs，包括LLaVA、Qwen2-VL、Llama3.2-Vision和GPT-4o，都提出了显著挑战。这项研究证明了在存在VSIL的多模态安全场景中，文本对齐就足够了，而对于没有VSIL的多模态安全场景，多模态对齐则是一个更有前途的解决方案。请参阅我们的代码和数据：http://hxhcreate.github.io/VLSBench|
|**2024-11-29**|**On Domain-Specific Post-Training for Multimodal Large Language Models**|Daixuan Cheng et.al.|[2411.19930](http://arxiv.org/abs/2411.19930)|null|近年来，通用多模态大型语言模型（MLLMs）的发展迅速。然而，将通用MLLMs应用于特定领域，如科学领域和工业应用，仍鲜有探索。本文系统地通过后训练研究MLLMs的领域自适应，重点关注数据合成、训练流程和任务评估。（1）数据合成：利用开源模型，我们开发了一个视觉指令合成器，能有效从特定领域的图像-描述对生成多样化的视觉指令任务。我们的合成任务在增强MLLMs领域特定性能方面优于手动规则、GPT-4和GPT-4V生成的任务。（2）训练流程：虽然两阶段训练——最初在图像-描述对上进行，然后进行视觉指令任务——是开发通用MLLMs的常用方法，但我们采用单阶段训练流程来增强领域特定后训练的任务多样性。（3）任务评估：我们通过对不同来源和规模（例如，Qwen2-VL-2B，LLaVA-v1.6-8B，Llama-3.2-11B）的MLLMs进行后训练，在生物医药和食品两个领域进行实验，然后评估MLLMs在各种领域特定任务上的性能。为了支持MLLMs领域自适应的进一步研究，我们将开源我们的实现。|
|**2024-11-29**|**SIMS: Simulating Human-Scene Interactions with Real World Script Planning**|Wenjia Wang et.al.|[2411.19921](http://arxiv.org/abs/2411.19921)|null|模拟长期人景交互是一项既具挑战性又充满吸引力的任务。以往的研究并未有效地解决基于物理动画的长期人景交互生成带有详细叙述的问题。本文介绍了一种新的框架，用于规划和控制长期物理可能的人景交互。一方面，互联网上充斥着风格独特的人类运动或与场景交互的影视作品，为剧本规划提供了丰富的数据来源。另一方面，大型语言模型（LLMs）能够理解和生成逻辑故事线。这促使我们结合两者，通过基于LLM的流程从视频中提取剧本，然后利用LLMs模仿和创作新的剧本，捕捉复杂的时间序列人类行为和环境交互。通过这种方式，我们利用一种双重感知策略，在语境和空间约束下指导角色动作，实现了语言理解和场景理解。为了便于训练和评估，我们贡献了一个包含从现实世界视频中提取的多样运动序列的综合规划数据集，并使用大型语言模型对其进行扩展。我们还收集并重新标注了来自现有运动学数据集的运动片段，以使我们的策略能够学习多种技能。广泛的实验证明了我们的框架在多种任务执行中的有效性及其对各种场景的泛化能力，与现有方法相比，性能显著提升。我们的代码和数据将很快公开。|
|**2024-11-29**|**PDDLFuse: A Tool for Generating Diverse Planning Domains**|Vedant Khandelwal et.al.|[2411.19886](http://arxiv.org/abs/2411.19886)|null|各种现实世界挑战需要能够适应广泛领域的规划算法。传统上，规划域的创建高度依赖于人工实现，这限制了可用的域的规模和多样性。尽管最近的研究利用了生成式人工智能技术，如大型语言模型（LLM）进行域创建，但这些努力主要集中在将现有域从自然语言描述中翻译出来，而不是生成新的域。相比之下，域随机化的概念，在强化学习中已被证明非常有效，通过在多样化的随机新域上进行训练，提高了性能和泛化能力。受此成功启发，我们的工具PDDLFuse旨在弥合规划域定义语言（PDDL）中的这一差距。PDDLFuse被设计用来生成新的、多样化的规划域，这些域可以用于验证新的规划器或测试基础规划模型。我们已经开发出了调整域生成器参数的方法，以调节其生成的域的难度。这种适应性至关重要，因为现有的域无关规划器往往难以处理更复杂的问题。初步测试表明，PDDLFuse能够高效地创建复杂且多样化的域，这比传统的域生成方法有显著的进步，并为规划研究做出了贡献。|
|**2024-11-29**|**LUMIA: Linear probing for Unimodal and MultiModal Membership Inference Attacks leveraging internal LLM states**|Luis Ibanez-Lissen et.al.|[2411.19876](http://arxiv.org/abs/2411.19876)|null|大型语言模型（LLMs）在各类应用中越来越受欢迎，但关于成员推断（Membership Inference）的担忧也随之增长。以往的研究主要关注黑盒到灰盒模型，从而忽略了内部LLM信息的潜在益处。为了解决这个问题，我们提出使用线性探针（LPs）作为一种检测成员推断攻击（MIAs）的方法，通过检查LLM的内部激活来实现。我们的方法被称为LUMIA，它逐层应用LPs以获取模型内部运作的细粒度数据。我们在包括单模态和多模态任务在内的多个模型架构、规模和数据集上测试了这种方法。在单模态MIAs中，LUMIA在曲线下面积（AUC）上比之前的技术平均提高了15.71%。值得注意的是，LUMIA在65.33%的情况下达到了AUC>60%——相较于现有技术提高了46.80%。此外，我们的方法揭示了关键见解，例如MIAs最易检测的模型层。在多模态模型中，LPs表明视觉输入可以显著有助于检测MIAs——在85.90%的实验中达到了AUC>60%。|
|**2024-11-29**|**AIDetx: a compression-based method for identification of machine-learning generated text**|Leonardo Almeida et.al.|[2411.19869](http://arxiv.org/abs/2411.19869)|**[link](https://github.com/aidetx/aidetx)**|**本文介绍了一种名为AIDetx的新方法，该方法利用数据压缩技术检测机器生成的文本。传统的深度学习分类器通常存在计算成本高和可解释性有限的问题。为了解决这些局限性，我们提出了一种基于压缩的分类框架，该框架利用有限上下文模型（FCMs）。AIDetx为人工写作和AI生成的文本构建了不同的压缩模型，根据哪个模型达到更高的压缩率来对新输入进行分类。我们在两个基准数据集上评估了AIDetx，分别实现了超过97%和99%的F1分数，突显了其高准确性。与当前方法，如大型语言模型（LLMs）相比，AIDetx提供了一个更可解释且计算效率更高的解决方案，显著减少了训练时间和硬件需求（例如，不需要GPU）。完整的实现代码在https://github.com/AIDetx/AIDetx上公开可用。**|
|**2024-11-29**|**Reverse Thinking Makes LLMs Stronger Reasoners**|Justin Chih-Yao Chen et.al.|[2411.19865](http://arxiv.org/abs/2411.19865)|null|逆向思维在人类推理中起着至关重要的作用。人类不仅能从问题推理到解决方案，还能逆向推理，即从解决方案开始推理到问题。这种推理方式往往能提升整体推理性能，因为它使得他们的正向和逆向思维之间能够进行一致性检查。为了使大型语言模型（LLMs）能够进行逆向思维，我们引入了逆向增强思维（RevThink）框架，该框架由数据增强和学习目标组成。在RevThink中，我们通过收集来自教师模型的有序正向-逆向推理来增强数据集，包括：（1）原始问题，（2）正向推理，（3）逆向问题，和（4）逆向推理。然后，我们采用三个目标以多任务学习的方式训练一个较小的学生模型：（a）从问题中生成正向推理，（b）从问题中生成逆向问题，（c）从逆向问题中生成逆向推理。在涵盖常识、数学和逻辑推理的12个数据集上的实验表明，与学生的零样本性能相比平均提升了13.53%，与最强的知识蒸馏基线相比提升了6.84%。此外，我们的方法展示了样本效率——仅使用训练数据中10%的正确正向推理，它就能超越在10倍更多正向推理上训练的标准微调方法。RevThink还显示出对分布外持有数据集的强大泛化能力。|
|**2024-11-29**|**Cross-Domain Recommendation Meets Large Language Models**|Ajay Krishna Vajjala et.al.|[2411.19862](http://arxiv.org/abs/2411.19862)|**[link](https://github.com/ajaykv1/CDR_Meets_LLMs)**|**跨领域推荐（CDR）已成为解决单领域推荐系统面临的冷启动问题的一个有希望的解决方案。然而，现有的CDR模型依赖于复杂的神经网络架构、大量数据集和大量的计算资源，这使得它们在数据稀缺的场景或当简单性至关重要的时效果较差。在这项工作中，我们利用大型语言模型（LLM）的推理能力，并探索其在多个领域对中的CDR领域的性能。我们引入了两种针对CDR的新型提示设计，并证明当LLM被有效提示时，在评分预测和排名任务中，LLM在各种指标和领域组合上优于最先进的CDR基线。这项工作弥合了LLM和推荐系统之间的差距，展示了它们作为有效的跨领域推荐者的潜力。**|
|**2024-11-27**|**Cross-modal Information Flow in Multimodal Large Language Models**|Zhi Zhang et.al.|[2411.18620](http://arxiv.org/abs/2411.18620)|null|近期，自回归多模态大型语言模型（MLLMs）在视觉语言任务上的进展展现出令人鼓舞的成果。虽然已有多种研究探讨大型语言模型内部语言信息的处理，但目前对MLLM的内部工作机制以及语言和视觉信息在这些模型中如何互动的了解甚少。在本研究中，我们旨在通过考察MLLM中不同模态（语言和视觉）之间的信息流，特别是聚焦于视觉问答任务，来填补这一空白。具体来说，给定一个图像-问题对作为输入，我们研究在模型中视觉和语言信息是如何结合以生成最终预测的。通过对LLaVA系列中的一系列模型进行实验，我们发现两个模态的整合过程中存在两个不同的阶段。在底层，模型首先将整个图像的更一般化的视觉特征转移到（语言）问题标记的表示中。在中层，它再次将与问题相关的特定物体的视觉信息转移到问题的相应标记位置。最后，在高层，最终的多模态表示被传播到输入序列的最后位置进行最终预测。总体而言，我们的发现为MLLM中图像和语言处理的时空方面提供了新的全面视角，从而有助于未来对多模态信息定位和编辑的研究。|
|**2024-11-27**|**Automated Literature Review Using NLP Techniques and LLM-Based Retrieval-Augmented Generation**|Nurshat Fateh Ali et.al.|[2411.18583](http://arxiv.org/abs/2411.18583)|null|本研究提出了并比较了多种利用自然语言处理（NLP）技术和检索增强生成（RAG）与大型语言模型（LLM）来自动生成文献综述的方法。研究论文数量的不断增长为手动文献综述带来了巨大挑战，进而推动了自动化需求。本研究的主要目标是开发一个能够仅从PDF文件输入自动生成文献综述的系统。为了实现这一目标，评估了多种自然语言处理（NLP）策略的有效性，包括基于频率的方法（spaCy）、变换器模型（Simple T5）以及与大型语言模型（GPT-3.5-turbo）结合的检索增强生成（RAG）。选择SciTLDR数据集进行实验，并利用三种不同的技术实现三个不同的系统来自动生成文献综述。使用ROUGE分数对所有三个系统进行评估。根据评估结果，大型语言模型GPT-3.5-turbo实现了最高的ROUGE-1分数，为0.364。变换器模型排名第二，spaCy排名最后。最后，为基于大型语言模型的最佳系统创建了一个图形用户界面。|
|**2024-11-27**|**Challenges in Adapting Multilingual LLMs to Low-Resource Languages using LoRA PEFT Tuning**|Omkar Khade et.al.|[2411.18571](http://arxiv.org/abs/2411.18571)|null|大型语言模型（LLMs）展示了令人瞩目的多语言能力，但在为低资源语言调整这些模型时仍存在挑战。在本研究中，我们调查了低秩调整（LoRA）参数高效微调（PEFT）对马哈拉施特拉语Gemma多语言模型的影响，马哈拉施特拉语是一种资源有限的语种。使用含有52,000条指令-响应对的翻译Alpaca数据集，我们的研究发现，尽管评估指标通常显示在微调后性能下降，但手动评估通常表明微调后的模型优于其原始版本。观察表明，在语言适应后，目标语言生成能力有所提高，但推理能力有所下降。这些结果强调了改进评估方法以及创建高质量的本语种数据集的必要性，以便准确评估低资源环境中的语言特定模型性能。|
|**2024-11-27**|**A Pipeline of Neural-Symbolic Integration to Enhance Spatial Reasoning in Large Language Models**|Rong Wang et.al.|[2411.18564](http://arxiv.org/abs/2411.18564)|null|大型语言模型（LLMs）在各种任务上展现出了令人印象深刻的性能。然而，LLMs在空间推理方面往往存在困难，而空间推理是推理和推断的一个重要部分，需要理解空间中物体之间的复杂关系。本文提出了一种新颖的神经符号框架，以增强LLMs的空间推理能力。我们在两个基准数据集——StepGame和SparQA上评估了我们的方法，并实施了三种不同的策略：（1）基于ASP（答案集编程）的符号推理，（2）使用DSPy的LLM + ASP管道，以及（3）事实+逻辑规则。我们的实验表明，与基线提示方法相比，我们的方法在StepGame数据集上实现了40-50%的准确性提升，在更复杂的SparQA数据集上实现了3-13%的提升。特别是“LLM + ASP”管道在寻找关系（FR）和寻找块（FB）任务上取得了特别强的结果，尽管不同类型问题的性能有所差异。令人印象深刻的结果表明，虽然神经符号方法为增强LLMs的空间推理提供了有希望的方向，但它们的有效性在很大程度上取决于具体任务特性和实施策略。我们提出了一套集成的、简单而有效的策略，使用神经符号管道来提升LLMs的空间推理能力。这个管道及其策略在LLMs的推理领域具有广泛的适用性，如时间推理、演绎推理等。|
|**2024-11-27**|**DexDiffuser: Interaction-aware Diffusion Planning for Adaptive Dexterous Manipulation**|Zhixuan Liang et.al.|[2411.18562](http://arxiv.org/abs/2411.18562)|null|在高级机器人中，具有丰富接触交互的灵活操作至关重要。尽管基于扩散的规划方法在简单的操作任务中显示出希望，但它们往往会产生不切实际的幽灵状态（例如，物体在没有手接触的情况下自动移动）或在处理复杂的顺序交互时缺乏适应性。在这项工作中，我们介绍了DexDiffuser，这是一个用于自适应灵活操作的认知扩散规划框架。DexDiffuser通过一个双阶段扩散过程来模拟关节状态动作动力学，该过程包括预接触接触对齐和接触后的目标导向控制，从而实现目标自适应的通用灵活操作。此外，我们结合了基于动力学模型的二元指导和利用大型语言模型进行自动指导函数生成，增强了对物理交互的泛化能力，并通过语言提示促进多样化的目标适应。在物理交互任务（如开门、笔和块重新定位和锤子敲钉）上的实验证明了DexDiffuser在训练分布之外的目标上的有效性，其成功率超过现有方法的平均成功率（59.2%比29.5%）。我们的框架在30度开门任务上达到70.0%的成功率，在笔和块半侧重新定位任务上分别达到40.0%和36.7%，在锤子敲钉半驱动任务上达到46.7%，突出了其在富含接触的操控中的鲁棒性和灵活性。|
|**2024-11-27**|**Retrofitting (Large) Language Models with Dynamic Tokenization**|Darius Feher et.al.|[2411.18553](http://arxiv.org/abs/2411.18553)|null|当前的语言模型（LMs）通常使用固定、静态的子词分词器。这种选择往往被视为理所当然，通常会导致在英语以外的语言中效率降低和功能受限，同时也使得将LMs应用于新的领域或语言变得具有挑战性。为了解决这些问题，我们提出对LMs进行动态分词改造：一种根据输入文本动态决定分词边界的方法。对于编码器风格的模型，我们引入了一种受字节对编码（BPE）启发的子词合并算法，但它在批处理级别上工作。我们在批处理中合并频繁的子词序列，然后应用预训练的嵌入预测超网络实时计算分词嵌入。当与词级边界结合使用时，这在XNLI上的XLM-R模型中平均将分词序列长度减少了>20%，同时任务性能下降不到2%。对于解码器风格的模型，我们以两种方式应用动态分词：1）用于预填充，几乎完全保持Mistral-7B的性能，同时相对于词级减少了高达40%的序列长度；2）通过近似最近邻索引，实现快速生成，并使用一百万个词元的词汇量，展示了扩展到甚至更大、更动态的词汇表的能力。总的来说，我们的研究结果表明，动态分词显著提高了推理速度，并促进了语言间的公平性，向克服静态分词的局限性迈出了重要一步，使LMs更加公平和适应性强。|
|**2024-11-27**|**Emergence of Self-Identity in AI: A Mathematical Framework and Empirical Study with Generative Large Language Models**|Minhyeok Lee et.al.|[2411.18530](http://arxiv.org/abs/2411.18530)|**[link](https://github.com/BrainJellyPie/self)**|**本文介绍了一种数学框架，用于在人工智能（AI）系统中定义和量化自我认同，填补了人工意识理论基础的critical gap。尽管现有的关于人工自我意识的方法通常依赖于启发式实现或哲学抽象，但我们提出了一种以度量空间理论、测度理论和泛函分析为基础的正式框架。我们的框架认为，自我认同源于两个可数学量化的条件：在度量空间 $(\mathcal{M}, d_{\mathcal{M}})$中存在一个连通的连续记忆集$C \subseteq \mathcal{M}$，以及一个连续映射$I: \mathcal{M} \to \mathcal{S}$，它在这个连续集上保持一致的自我识别，其中$(\mathcal{S}, d_{\mathcal{S}})$ 代表可能自我认同的度量空间。为了验证这个理论框架，我们使用Llama 3.2 1B模型进行了实证实验，采用低秩适配（LoRA）进行高效的微调。该模型在一个包含时序结构记忆的合成数据集上进行了训练，旨在捕捉连贯自我认同形成的复杂性。我们的评估指标包括自我意识、响应一致性和语言精确性的量化度量。实验结果表明，可测量的自我意识指标有显著提高，主要自我意识分数从0.276提高到0.801。这使得可以结构化地创建具有经过验证的自我认同特征的AI系统。本研究的影响对类人机器人学和自主系统领域具有直接相关性。**|
|**2024-11-27**|**LLM-ABBA: Understand time series via symbolic approximation**|Erin Carson et.al.|[2411.18506](http://arxiv.org/abs/2411.18506)|null|在之前的研究中，大型语言模型（LLMs）在处理时间序列方面的成功已经得到证明。利用符号时间序列表示，可以有效地在LLMs和时间序列之间架起桥梁。然而，剩余的挑战是如何利用符号或LLMs现有标记中的时间序列隐含语义信息，同时根据时间序列的隐含信息调整LLMs的嵌入空间。名为自适应布朗桥符号聚合（ABBA）的符号时间序列近似（STSA）方法，通过以振幅和周期来建模时间序列模式，同时使用LLMs的现有标记，在保留显著时间序列特征方面表现出卓越的功效。在本文中，我们介绍了一种方法，称为LLM-ABBA，该方法将ABBA整合到大型语言模型中，用于各种下游时间序列任务。通过符号化时间序列，LLM-ABBA在UCR和三个医学时间序列分类任务中，与最近最先进的（SOTA）方法相比具有优势。同时，在ABBA中引入了固定多边形链技巧，通过显著减轻从符号到数值转换过程中由于符号误用而产生的累积误差的影响，来避免预测任务中的明显漂移。在时间序列回归任务中，LLM-ABBA在时间序列外部回归（TSER）基准测试上实现了新的SOTA。与最近SOTA的时间序列预测结果相比，LLM-ABBA也显示了具有竞争力的预测能力。我们相信这个框架也可以无缝地扩展到其他时间序列任务。|
|**2024-11-27**|**GATE OpenING: A Comprehensive Benchmark for Judging Open-ended Interleaved Image-Text Generation**|Pengfei Zhou et.al.|[2411.18499](http://arxiv.org/abs/2411.18499)|null|多模态大型语言模型（MLLMs）在视觉理解和生成任务方面取得了显著进展。然而，生成交织的图像-文本内容仍然是一个挑战，这需要综合的多模态理解和生成能力。虽然统一模型的进展提供了新的解决方案，但现有的基准由于数据量和多样性限制，不足以评估这些方法。为了填补这一差距，我们介绍了GATE OpenING（OpenING），这是一个包含5,400个高质量人工标注实例、涵盖56个真实世界任务的全面基准。OpenING覆盖了多样化的日常场景，如旅行指南、设计和头脑风暴，为挑战交织生成方法提供了一个强大的平台。此外，我们提出了IntJudge，这是一个用于评估开放式多模态生成方法的评判模型。使用新颖的数据流水线进行训练，我们的IntJudge与人类判断的吻合率达到82.42%，比基于GPT的评估器高出11.34%。在OpenING上的大量实验表明，当前的交织生成方法仍有很大的改进空间。关于交织图像-文本生成的关键发现进一步提出，以指导下一代模型的发展。OpenING已开源，请访问https://opening.github.io。|
|**2024-11-27**|**Beyond Examples: High-level Automated Reasoning Paradigm in In-Context Learning via MCTS**|Jinyang Wu et.al.|[2411.18478](http://arxiv.org/abs/2411.18478)|null|在上下文学习（ICL）中，通过复杂的提示和高质量演示，使大型语言模型（LLMs）能够处理下游任务。然而，当面对复杂的数学推理任务时，这种传统的ICL范式显示出局限性，主要是因为它对示例质量的依赖性很大，以及在挑战性场景中需要人类干预。为了解决这些局限性，本文提出了一种HiAR-ICL，这是一种在ICL中的高级自动推理范式，它将焦点从具体示例转移到抽象思维模式，扩展了ICL中传统的上下文概念。HiAR-ICL引入了五个原子推理动作作为构建链式模式的根本组成部分。使用蒙特卡洛树搜索，我们探索推理路径并构建思维卡片来指导后续推理。然后我们开发了一个认知复杂度框架，该框架动态地将问题与适当的思想卡片相匹配。实验结果表明，HiAR-ICL的有效性，使用Qwen2.5-7B-Instruct在MATH基准测试中实现了最先进的准确率（79.6%），超过了GPT-4o（76.6%）和Claude 3.5（71.1%）。|

<p align=right>(<a href=#updated-on-20241211>back to top</a>)</p>

## infer

|Publish Date|Title|Authors|PDF|Code|abstract|
|---|---|---|---|---|---|
|**2024-12-09**|**SparseAccelerate: Efficient Long-Context Inference for Mid-Range GPUs**|James Vo et.al.|[2412.06198](http://arxiv.org/abs/2412.06198)|null|随着大型语言模型（LLM）的上下文窗口长度增加，传统上随着输入长度呈二次增长的关注机制的计算成本，对实时和内存受限的部署构成了一个关键挑战。现有的稀疏关注技术试图减少这种复杂性，但它们往往会产生显著的开销或降低准确性，使得它们在中等硬件上对大型上下文不太实用。在本文中，我们引入了SparseAccelerate，这是一种动态稀疏关注方法，根据输入特征调整其稀疏模式，有效地平缓了关注复杂性的曲线。我们的方法对输入长度从16K个标记开始就非常有效，并且可以在双NVIDIA A5000 GPU（每个24GB）上高效地扩展到128K个标记。实验结果表明，在32K个标记时，SparseAccelerate将时间到第一个标记（TTFT）延迟减少了高达1.04倍，同时也提供了大量的内存节省。这些改进为内存密集型应用和以前用标准关注机制无法实现的长时间上下文任务带来了实际的好处。除了降低延迟之外，SparseAccelerate从根本上改变了扩展趋势，显示出相对于上下文长度，在竞争方法中具有最小的TTFT增长梯度。在多个基准测试上的持续评估证实了其可扩展性，将SparseAccelerate定位为在可访问硬件上实现高效、实时和长上下文LLM推理的关键进步。|
|**2024-12-08**|**XKV: Personalized KV Cache Memory Reduction for Long-Context LLM Inference**|Weizhuo Li et.al.|[2412.05896](http://arxiv.org/abs/2412.05896)|null|近期，生成式大型语言模型（LLM）在众多应用中取得了显著的成功。值得注意的是，其推理过程是逐个生成输出标记，导致许多冗余计算。广泛使用的KV-Cache框架在时间和空间复杂度之间做出了妥协。然而，缓存数据产生的日益增长的内存需求，可以快速耗尽现代加速器（如GPU）有限的内存容量，尤其是在长上下文推理任务中。现有研究通过淘汰对推理精度影响较小的部分缓存数据来减少内存消耗。但由于不同LLM网络层之间静态的缓存分配，实际效益远未理想。本文观察到，特定层的缓存数据对精度的影响差异很大。我们量化了这种差异，并给出了实验和理论验证。据此，我们进行了形式分析，表明以个性化方式为每个层定制缓存大小可以显著减少内存消耗，同时仍然提供可比的精度。我们将缓存分配模拟为组合优化问题，并给出全局最优解。特别是，我们设计了一种基于轻量级LLM模型的小型采样推理，以便快速捕捉差异，然后将其输入到个性化算法中。在真实世界数据集上的大量实验表明，我们的方案可以将KV缓存内存消耗平均降低61.6%，提高计算效率2.1倍，并使吞吐量提高至最高5.5倍。|
|**2024-12-06**|**GUIDE: A Global Unified Inference Engine for Deploying Large Language Models in Heterogeneous Environments**|Yanyu Chen et.al.|[2412.04788](http://arxiv.org/abs/2412.04788)|null|将大型语言模型（LLMs）高效地部署到实际场景中仍然是一个关键挑战，这主要是因为硬件异构性、推理框架的限制以及工作负载的复杂性。这些挑战往往会导致内存利用率、延迟和吞吐量的低效，阻碍LLMs的有效部署，尤其是对于非专业人士。通过大量的实验，我们确定了关键的性能瓶颈，包括内存利用率的突然下降、随着批量大小变化而波动的延迟以及多GPU配置中的低效。这些见解揭示了一个巨大的优化空间，这个空间由硬件、框架和工作负载参数之间复杂的相互作用所塑造。这强调了系统性地优化LLM推理的必要性，推动了我们的框架GUIDE的设计。GUIDE利用动态建模和基于仿真的优化来解决这些问题，在批量延迟、TTFT和解码吞吐量等关键指标上实现了25%至55%的预测误差。通过有效地弥合理论性能与实际部署之间的差距，我们的框架使从业者，尤其是非专业人士，能够做出数据驱动的决策，并以低廉的成本释放LLMs在异构环境中的全部潜力。|
|**2024-12-03**|**Compressing KV Cache for Long-Context LLM Inference with Inter-Layer Attention Similarity**|Da Ma et.al.|[2412.02252](http://arxiv.org/abs/2412.02252)|null|随着大型语言模型（LLMs）如GPT和LLaMA系列中上下文窗口大小的增加，它们处理复杂、长文本任务的能力得到了提升，但这也导致了推理效率的降低，特别是在内存和计算复杂度方面。现有方法，包括选择性保留标记和基于窗口的注意力机制，虽然提高了效率，但风险是丢弃未来文本生成所需的重要标记。在本文中，我们提出了一种通过减少次要标记的内存和计算负担来提高LLM效率而不丢失标记的方法。我们解决了两个挑战：1）研究上下文中重要标记的分布，发现近期标记在上下文中比遥远标记更重要，2）通过跨层共享注意力分数来优化遥远标记的资源。实验表明，我们的方法在不影响性能的情况下节省了35%的KV缓存。|
|**2024-12-03**|**Multi-Bin Batching for Increasing LLM Inference Throughput**|Ozgur Guldogan et.al.|[2412.04504](http://arxiv.org/abs/2412.04504)|null|随着大型语言模型（LLMs）因其多样化的功能而越来越受欢迎，提高其推理系统的效率变得越来越关键。在服务器（例如GPU）上调度推理任务时，批量处理LLM请求是一个关键步骤，这使系统能够通过并行处理多个请求来最大化吞吐量。然而，请求的生成长度往往不同，这会导致资源利用率低下，因为硬件必须等待批量中运行时间最长的请求完成，然后才能转向下一个批次。我们从排队论的角度对这个问题进行了形式化，并旨在设计一个吞吐量最优的控制策略。我们提出了多箱批量处理，这是一种简单而有效的方法，可以通过将具有相似（预测的）执行时间的请求分组到预定的箱中，来证明性地提高LLM推理的吞吐量。通过理论分析和实验，包括现实世界的LLM推理场景，我们展示了与标准批量处理方法相比，显著提高了吞吐量。|
|**2024-12-02**|**PLD+: Accelerating LLM inference by leveraging Language Model Artifacts**|Shwetha Somasundaram et.al.|[2412.01447](http://arxiv.org/abs/2412.01447)|null|为了减少与自回归LLM推理相关的延迟，推测解码作为一种新的解码范式应运而生，其中未来的标记符在并行中进行草拟和验证。然而，推测解码的实际部署受到其对额外计算资源和微调的要求的限制，这限制了其即插即用的可用性。为了解决这些挑战，我们提出了PLD+，这是一套旨在加速LLM推理过程的创新算法，尤其是针对输入引导任务。这些任务包括代码编辑、文本编辑、摘要等，它们的输出通常与输入有大量重叠——这是PLD+设计用来利用的特性。PLD+还利用推理过程中生成的工件（注意力机制和隐藏状态）来加速推理速度。我们在五个输入引导任务上测试了我们的方法，并通过广泛的实验发现，PLD+优于所有无需微调的方法。在贪婪设置中，它在四个任务上甚至优于最先进的依赖微调的方法EAGLE（平均加速率高达2.31）。我们的方法无需微调，不需要任何额外的计算资源，可以轻松用于加速任何LLM的推理。|
|**2024-12-02**|**Efficient LLM Inference using Dynamic Input Pruning and Cache-Aware Masking**|Marco Federici et.al.|[2412.01380](http://arxiv.org/abs/2412.01380)|null|随着移动设备计算能力的不断提升，DRAM带宽的提升却相对缓慢。这对于大型语言模型（LLM）的token生成来说是个不幸的事实，因为其高度依赖于内存。先前的研究曾提出利用ReLU激活的LLM中的自然动态激活稀疏性来减少每个token的有效DRAM带宽。然而，更近期的LLM使用了SwiGLU而不是ReLU，这导致内在稀疏性很小。尽管SwiGLU的激活可以根据幅度进行剪枝，但产生的稀疏模式难以预测，使得先前的方法无效。为了解决这个问题，我们的工作引入了动态输入剪枝（DIP）：一种无预测器的动态稀疏化方法，它以最小的微调保留了准确性。DIP还可以使用轻量级的LoRA适配器来恢复稀疏化过程中损失的一些性能。最后，我们描述了一种新的缓存感知掩码策略，它考虑了缓存状态和激活幅度，以进一步提高缓存命中率，从而提高移动设备上的LLM token率。在模拟硬件设置中，DIP在准确性、内存和吞吐量之间的权衡方面优于其他方法。在Phi-3-Medium上，DIP实现了46%的内存减少和40%的吞吐量增加，同时困惑度损失小于0.1。|
|**2024-12-02**|**RILQ: Rank-Insensitive LoRA-based Quantization Error Compensation for Boosting 2-bit Large Language Model Accuracy**|Geonho Lee et.al.|[2412.01129](http://arxiv.org/abs/2412.01129)|null|低秩适应（LoRA）已成为参数高效LLM微调的主流方法，基于LoRA的量化误差补偿（LQEC）作为恢复压缩LLM精度的一个强大工具而崭露头角。然而，LQEC在4位以下场景中的性能不佳，目前对此限制尚无深入研究。我们提出了一种名为RILQ（秩无关LoRA量化误差补偿）的方法，以理解其基本限制并提高2位LLM的精度。基于对模型激活差异损失的秩无关性质的分析，RILQ使用这种损失来跨层协同调整适配器，从而实现具有低秩适配器的鲁棒误差补偿。在LLaMA-2和LLaMA-3上的评估表明，RILQ在各种最先进的量化器上对2位量化推理的持续改进，以及在特定任务微调中精度的提升。RILQ保持了与现有LoRA方法相当的计算效率，使得适配器合并权重量化的LLM推理具有显著提高的精度，使其成为提升2位LLM性能的有前途的方法。|
|**2024-12-02**|**TruncFormer: Private LLM Inference Using Only Truncations**|Patrick Yubeaton et.al.|[2412.01042](http://arxiv.org/abs/2412.01042)|null|私有推理（PI）在用户数据与专有机器学习模型（如LLM）交互时，在保证用户数据隐私方面发挥着重要作用。然而，由于LLM中存在的非线性函数带来的巨大延迟成本，PI在实践中难以处理。现有工作主要集中在通过近似来提高特定LLM非线性函数（如Softmax或GeLU）的延迟。然而，随着新的LLM架构的不断出现，新的非线性函数也经常被引入，这导致PI研究人员试图优化最新非线性函数的持续追赶游戏。我们引入了TruncFormer，这是一个将任何LLM转换为其明文PI仿真的框架。我们的框架利用了LLM中的非线性函数是可微分的，并且可以使用一系列加法、乘法和截断来精确地近似。此外，我们将加/乘操作和截断操作解耦，并根据给定的字段大小和输入表示大小静态确定截断的位置。这导致延迟优于现有在每次乘法操作后强制截断的加密协议。我们开源了我们的代码供社区使用。|
|**2024-11-29**|**A dynamic parallel method for performance optimization on hybrid CPUs**|Luo Yu et.al.|[2411.19542](http://arxiv.org/abs/2411.19542)|null|AIPC概念越来越受欢迎，越来越多的混合CPU将在客户端设备上运行AI模型。然而，当前的AI推理框架忽略了混合CPU硬件能力的失衡，导致推理性能低下。为了解决这个问题，我们引入了一种针对混合CPU的动态并行方法，该方法通过在并行工作开始之前平衡混合CPU每个核心的工作负载，显著提高了大型语言模型（LLM）的推理性能。这种方法使Neural Speed能够在两个混合英特尔CPU上实现超过90%（平均）的内存带宽。|
|**2024-11-29**|**BatchLLM: Optimizing Large Batched LLM Inference with Global Prefix Sharing and Throughput-oriented Token Batching**|Zhen Zheng et.al.|[2412.03594](http://arxiv.org/abs/2412.03594)|null|许多大型语言模型（LLM）的任务在大批量或离线情况下执行，其性能指标为吞吐量。这些任务通常具有前缀共享的特征，即不同的提示输入可以部分显示共同的prefix。然而，现有的LLM推理引擎往往优化流式请求，在支持具有前缀共享特性的大批量任务方面存在局限性。现有解决方案使用基于LRU的缓存来重用共同前缀的KV上下文。即将被重用的KV上下文可能会因隐式缓存管理而被提前移除。即使没有被移除，共享的KV上下文的生命周期也会因为共享相同上下文的请求没有被一起调度而延长，导致更大的内存使用。这些以流为方向的系统按照先来先服务的顺序调度请求。结果，解码步骤比例较大的请求可能调度得太晚，无法与预填充块混合，从而提高硬件利用率。此外，基于令牌和请求数量的批量处理可能会限制令牌批量的大小，这会防止GPU在主要由解码令牌控制的迭代中饱和。我们提出了BatchLLM来解决这个问题。BatchLLM显式地识别全局的共同prefix。具有相同prefix的请求将被一起调度，以最佳方式重用KV上下文，这也有助于缩短共同KV内存的生命周期。BatchLLM重新排序请求，优先调度解码步骤比例较大的请求，以便更好地将解码令牌与后续预填充块混合，并采用以内存为中心的令牌批量处理来扩大令牌批量大小，这有助于提高GPU利用率。广泛的评估表明，在一系列微基准测试和两个典型的行业工作负载上，BatchLLM的性能优于vLLM 1.1倍到2倍。|
|**2024-11-28**|**Puzzle: Distillation-Based NAS for Inference-Optimized LLMs**|Akhiad Bercovich et.al.|[2411.19146](http://arxiv.org/abs/2411.19146)|null|大型语言模型（LLMs）展示了惊人的能力，但它们的采用受到推理过程中高计算成本的限制。虽然增加参数数量可以提高准确性，但它也拉大了最先进的能力与实际部署之间的差距。我们提出了Puzzle框架，该框架在特定硬件上加速LLMs的推理，同时保持其能力。通过前所未有的规模创新性地应用神经架构搜索（NAS），Puzzle在硬件约束下系统地优化了具有数十亿参数的模型。我们的方法利用块状局部知识蒸馏（BLD）进行并行架构探索，并采用混合整数规划进行精确的约束优化。我们通过Llama-3.1-Nemotron-51B-Instruct（Nemotron-51B）这一公开可用的模型展示了我们框架的实际影响，该模型由Llama-3.1-70B-Instruct衍生而来。Nemotron-51B实现了2.17倍的推理吞吐量加速，可以在单个NVIDIA H100 GPU上运行，同时保留了原始模型98.4%的能力。Nemotron-51B是目前能够以大批次在单个GPU上进行推理的最准确的语言模型。值得注意的是，这种转变只需要45B个训练令牌，而它所衍生的70B模型则需要超过15T个令牌。这建立了一个新的范式，即强大的模型可以通过仅牺牲微小能力来优化高效的部署，这表明推理性能而非参数数量本身应指导模型选择。随着Nemotron-51B的发布和Puzzle框架的介绍，我们为从业者提供了以显著降低的计算成本访问最先进语言建模能力的即时途径。|
|**2024-11-27**|**InputSnatch: Stealing Input in LLM Services via Timing Side-Channel Attacks**|Xinyao Zheng et.al.|[2411.18191](http://arxiv.org/abs/2411.18191)|null|大型语言模型（LLMs）具备广泛的知识和问答能力，已在金融和医疗咨询等对隐私敏感的领域得到广泛应用。在LLMs推理过程中，缓存共享方法被广泛采用以提高效率，通过重用缓存的状态或响应来处理相同或相似的推理请求。然而，我们发现这些缓存机制存在隐私输入泄露的风险，因为缓存可能导致响应时间出现可观察的变化，使其成为基于时间攻击的强候选线索。在本研究中，我们提出了一种新颖的基于时间的侧信道攻击，用于在LLMs推理中执行输入窃取。基于缓存的攻击面临在大型搜索空间中构建候选输入以击中和窃取缓存用户查询的挑战。为了解决这些挑战，我们提出了两个主要组件。输入构造器采用机器学习技术和基于LLM的方法进行词汇相关性学习，同时在通用输入构建中实施优化的搜索机制。时间分析器通过异常值去除实现统计时间拟合，以识别缓存命中模式，并持续提供反馈以优化构造器的搜索策略。我们在两种缓存机制上进行了实验，结果表明我们的方法在各种应用中均能持续获得高攻击成功率。我们的工作突出了与性能优化相关的安全漏洞，强调了在LLMs推理增强的同时优先考虑隐私和安全的必要性。|
|**2024-11-27**|**MiniKV: Pushing the Limits of LLM Inference via 2-Bit Layer-Discriminative KV Cache**|Akshat Sharma et.al.|[2411.18077](http://arxiv.org/abs/2411.18077)|null|由于LLMs（大型语言模型）对内存和计算的高要求，如何在实践中高效地为LLMs提供服务变得极为挑战。在本研究中，我们调查了优化KV缓存的方法，因为其内存占用是LLM推理中的关键瓶颈，尤其是在处理长上下文任务时。为了应对这一挑战，我们引入了MiniKV，这是一种KV缓存优化方法，通过一种新颖的2比特层区分性KV缓存，在同时保持长上下文任务准确性的同时，显著减少了KV缓存的大小。更重要的是，我们开发了专门的CUDA内核，使MiniKV与FlashAttention兼容。在广泛的长上下文任务上的实验表明，MiniKV有效地实现了86%的KV缓存压缩比，同时恢复了超过98.5%的准确性，优于现有方法，同时实现了卓越的系统性能提升。|
|**2024-11-26**|**PIM-AI: A Novel Architecture for High-Efficiency LLM Inference**|Cristobal Ortega et.al.|[2411.17309](http://arxiv.org/abs/2411.17309)|null|大型语言模型（LLMs）因其先进的语言理解和生成能力，在众多应用中变得至关重要。然而，它们对计算和内存的要求给传统的硬件架构带来了巨大的挑战。内存中处理（PIM）将计算单元直接集成到内存芯片中，为LLM推理提供了多项优势，包括减少数据传输瓶颈和提高能效。本文介绍了一种名为PIM-AI的新型DDR5/LPDDR5 PIM架构，专为LLM推理设计，无需修改内存控制器或DDR/LPDDR内存PHY。我们开发了一个模拟器来评估PIM-AI在不同场景下的性能，并证明了其相较于传统架构的显著优势。在基于云的场景中，PIM-AI相较于最先进的GPU，将每秒查询的三年总拥有成本降低了高达6.94倍，具体取决于所使用的LLM模型。在移动场景中，PIM-AI相较于最先进的移动SoC，在每token能耗上实现了10到20倍降低，从而实现了每秒查询增加25到45%，每查询能耗减少6.9倍到13.4倍，延长了电池寿命，并使每次充电的推理次数更多。这些结果突显了PIM-AI颠覆LLM部署的潜力，使其更加高效、可扩展和可持续。|
|**2024-11-26**|**Star Attention: Efficient LLM Inference over Long Sequences**|Shantanu Acharya et.al.|[2411.17116](http://arxiv.org/abs/2411.17116)|**[link](https://github.com/NVIDIA/Star-Attention)**|**由于自注意力机制的二次复杂度，使用Transformer基于的大型语言模型（LLMs）在长序列上进行推理既耗时又昂贵。我们引入了星型注意力，这是一种两阶段的块稀疏近似，通过在多个主机之间分片注意力来提高计算效率，同时最大限度地减少通信开销。在第一阶段，使用并行跨主机的块局部注意力处理上下文。在第二阶段，查询和响应标记通过序列全局注意力关注所有先前缓存的标记。星型注意力与大多数使用全局注意力训练的Transformer基于的LLMs无缝集成，通过减少内存需求和推理时间最多11倍，同时保留95-100%的准确率。**|
|**2024-11-26**|**Efficient LLM Inference with I/O-Aware Partial KV Cache Recomputation**|Chaoyi Jiang et.al.|[2411.17089](http://arxiv.org/abs/2411.17089)|null|对于大型语言模型（LLMs）的推理计算量很大。为了降低自回归解码的成本，采用键值（KV）缓存来存储中间激活，使得GPU只需进行每个新标记所需的增量计算。这种方法显著降低了标记生成的计算开销。然而，KV缓存的内存需求迅速增长，通常超过GPU内存容量。一种成本效益更高的替代方案是将KV缓存卸载到CPU内存中，这可以缓解GPU内存压力，但将瓶颈转移到CPU和GPU之间有限的PCIe连接带宽。现有方法试图通过重叠GPU计算与I/O或采用CPU-GPU异构执行来解决这些问题，但它们受到过度数据移动和对CPU能力的依赖的阻碍。在本文中，我们介绍了一种高效的CPU-GPU I/O感知LLM推理方法，通过在同时通过PCIe总线传输剩余KV缓存的同时，从激活中重新计算部分KV缓存，避免了将整个KV缓存从CPU传输到GPU。这种方法重叠GPU重新计算与数据传输，以最小化GPU空闲时间并最大化推理性能。我们的方法通过集成一个利用输入特性和系统硬件信息的分析模块、一个用于优化计算和通信工作负载分配的调度模块以及一个用于高效执行派生执行计划的运行时模块而完全自动化。实验结果表明，与最先进的方法相比，我们的方法在解码时的延迟降低了高达35.8%，吞吐量提高了46.2%。|
|**2024-11-25**|**MixPE: Quantization and Hardware Co-design for Efficient LLM Inference**|Yu Zhang et.al.|[2411.16158](http://arxiv.org/abs/2411.16158)|null|基于Transformer的大型语言模型（LLMs）随着模型规模的不断扩大取得了显著的成功，但它们的部署仍然面临挑战，主要是因为计算和内存需求巨大。量化技术已成为一种有前景的解决方案，而针对LLMs的最先进量化算法引入了混合精度矩阵乘法（mpGEMM）的需求，即使用低精度权重与高精度激活进行乘法运算。尽管这种方法有优势，但当前硬件加速器如GPU和TPU缺乏对高效mpGEMM的原生支持，导致主顺序循环中的去量化操作效率低下。为了解决这一限制，我们引入了MixPE，这是一种专门设计的混合精度处理单元，旨在高效地在LLM推理中进行低比特量化。MixPE利用两项关键创新来最小化去量化开销并充分发挥低比特量化的潜力。首先，我们认识到每个量化组内的缩放因子和零点是可以共享的，因此我们提议在每个组mpGEMM之后进行去量化，这显著降低了去量化开销。其次，MixPE不是依赖于传统的乘法器，而是使用高效的移位和加法操作进行乘法运算，从而优化了计算和能效。我们的实验结果表明，MixPE在速度上比最先进的量化加速器快2.6倍，在能耗上减少1.4倍。|
|**2024-11-24**|**eFedLLM: Efficient LLM Inference Based on Federated Learning**|Shengwen Ding et.al.|[2411.16003](http://arxiv.org/abs/2411.16003)|null|大型语言模型（LLMs）标志着人工智能（AI）领域的变革时代。然而，LLMs所涉及的数据和参数规模巨大，需要高要求的计算和内存资源，这限制了它们对更广泛用户和研究者的可及性。本文介绍了一种有效的方法，可以提升LLM推理的操作效率和成本效益。通过利用基于transformer的联邦学习（FL）与模型并行分布式训练，我们的模型能够高效地在参与者网络中分配计算负载和内存需求。这种策略允许用户，尤其是那些资源有限的用户，可以协同训练最先进的LLMs。我们还创新了FL框架中的激励机制，奖励有益的贡献并过滤掉恶意活动，从而保护训练过程的完整性和可靠性。同时，我们利用内存层次策略和权重矩阵的奇异值分解（SVD）进一步提升了计算和内存效率。我们的结果，通过公式分析和数值计算得出，显著优化了资源使用，并使先进LLMs的访问权民主化，确保广泛的用户既能参与也能从中受益。|
|**2024-11-24**|**Anda: Unlocking Efficient LLM Inference with a Variable-Length Grouped Activation Data Format**|Chao Fang et.al.|[2411.15982](http://arxiv.org/abs/2411.15982)|null|广泛应用的仅权重量化的大型语言模型（LLM），利用低比特整数（INT）权重并保留浮点（FP）激活，在减少存储需求的同时保持了准确性。然而，这将能耗和延迟瓶颈转向了与昂贵的内存访问和计算相关的FP激活。现有的LLM加速器主要关注计算优化，忽略了联合优化FP计算和数据移动的潜力，尤其是在LLM推理中的主导FP-INT GeMM操作。为了解决这些挑战，我们研究了各种LLM模块中激活精度的敏感性及其对整体模型准确性的影响。基于我们的发现，我们首先提出了Anda数据类型：一种具有组共享指数位和动态尾数位分配的自适应数据格式。其次，我们开发了一种迭代的训练后自适应精度搜索算法，优化不同LLM模块的位宽，以平衡模型准确性、能耗和推理速度。最后，提出了一系列硬件优化技术，以最大限度地发挥Anda格式的优势。这包括基于位面的数据组织方案、具有位串计算功能的Anda增强处理单元以及运行时位面Anda压缩器，以同时优化存储、计算和内存占用。我们在FPINT GeMM操作上的评估表明，与GPU类似的FP-FP基准相比，Anda在包括OPT、LLaMA和LLaMA-2系列在内的流行LLM上平均实现了2.4倍的加速、4.0倍的面积效率提升和3.1倍的能耗效率提升。Anda在各种应用场景、精度要求和系统性能方面表现出强大的适应性，使得在广泛的部署场景中实现高效的LLM推理成为可能。|
|**2024-11-24**|**Chameleon: Adaptive Caching and Scheduling for Many-Adapter LLM Inference Environments**|Nikoleta Iliakopoulou et.al.|[2411.17741](http://arxiv.org/abs/2411.17741)|null|随着大型语言模型（LLMs）的广泛应用，其部署数量呈指数级增长，对推理集群提出了巨大需求。这些集群必须处理针对不同LLM下游任务的大量并发查询。为了处理具有大量LLM参数的多任务设置，方法如低秩自适应（LoRA）允许针对特定任务进行微调，同时跨任务共享大部分基础LLM模型。因此，它们允许以最小的内存需求并发处理任务。然而，现有的LLM服务系统存在效率低下的问题：它们忽视了工作负载异构性，由于频繁的适配器加载而施加了高链路带宽，以及在调度器中存在头阻塞问题。为了解决这些挑战，我们提出了Chameleon，这是一个针对多个适配器环境优化的新型LLM服务系统，它依赖于两个核心思想：适配器缓存和适配器感知调度。首先，Chameleon在GPU内存中缓存流行的适配器，最小化适配器加载时间。重要的是，它使用原本闲置的GPU内存，避免了额外的内存成本。其次，Chameleon使用非抢占式多队列调度，以高效地处理工作负载异构性。通过这种方式，Chameleon同时防止了头阻塞和饥饿现象。我们在最先进的LLM服务平台之上实现了Chameleon，并使用真实世界的生产跟踪和开源LLM对其进行了评估。在高负载下，Chameleon将P99和P50的TTFT延迟分别降低了80.7%和48.1%，同时与最先进的基线相比，提高了1.5倍的吞吐量。|
|**2024-11-24**|**Task Scheduling for Efficient Inference of Large Language Models on Single Moderate GPU Systems**|Wenxiang Lin et.al.|[2411.15715](http://arxiv.org/abs/2411.15715)|null|大型语言模型（LLMs）因其庞大的模型尺寸而闻名，对计算资源和内存需求极高，导致在中等GPU系统上的推理效率低下。量化或剪枝等技术可以缩小模型尺寸，但通常会损害准确度，使其不适合实际应用。在这项工作中，我们介绍了\modelname{}，这是一个高性能的推理引擎，旨在加快LLMs的推理速度，同时不降低模型精度。\modelname{}采用了三种创新方法来提高推理效率：1）模型分区，允许跨CPU计算、GPU计算和CPU-GPU通信异步处理任务，2）自适应分区算法，以优化CPU、GPU和PCIe通信能力的利用，3）令牌分配策略，用于处理LLMs推理过程中的各种提示和生成任务。我们使用Mixtral、LLaMA-2、Qwen和PhiMoE等LLMs，在具有不同CPU和GPU的三个测试环境中进行了综合实验。实验结果表明，\modelname{}在解码速度上比 $1.11\times$到$1.80\times$更快，在预填充速度上比$1.69\times$到$6.33\times$更快，与最先进的解决方案llama.cpp和Fiddler相比，整体速度提高了$1.25\times$到$2.04\times$ 。|

<p align=right>(<a href=#updated-on-20241211>back to top</a>)</p>

## train

|Publish Date|Title|Authors|PDF|Code|abstract|
|---|---|---|---|---|---|
|**2024-12-09**|**Exploring Memorization and Copyright Violation in Frontier LLMs: A Study of the New York Times v. OpenAI 2023 Lawsuit**|Joshua Freeman et.al.|[2412.06370](http://arxiv.org/abs/2412.06370)|null|近期，由于2023年12月提起的纽约时报诉OpenAI诉讼，前沿大型语言模型（LLM）的版权侵权问题引起了广泛关注。纽约时报声称，GPT-4通过复制文章用于LLM训练并记忆输入内容，在LLM输出中公开展示，侵犯了其版权。我们的研究旨在衡量OpenAI的LLM相对于其他LLM在输出中展现逐字记忆倾向的程度，特别是针对新闻文章。我们发现，GPT和Claude模型都使用拒绝训练和输出过滤器来防止记忆文章的逐字输出。我们应用了一个基本的提示模板来绕过拒绝训练，并显示OpenAI模型目前比Meta、Mistral和Anthropic的模型更不易被记忆激发。我们发现，随着模型规模的增加，尤其是超过1000亿参数后，它们显示出显著更强的记忆能力。我们的发现对训练有实际意义：必须更加重视在非常大的模型中防止逐字记忆。我们的发现也具有法律意义：在评估OpenAI的LLM相对记忆能力时，我们探讨了纽约时报版权侵权诉讼的强度和OpenAI的法律辩护，同时强调了生成AI、法律和政策交叉领域的问题。|
|**2024-12-06**|**Code generation and runtime techniques for enabling data-efficient deep learning training on GPUs**|Kun Wu et.al.|[2412.04747](http://arxiv.org/abs/2412.04747)|null|随着深度学习模型的规模扩大，其训练成本显著增加。由于硬件的进步和当前软件栈的局限性，对数据效率的需求日益增长。数据效率是指有效隐藏数据访问延迟以及避免不必要的数据处理。在GPU内存带宽与计算吞吐量之间的日益差距、即将到来的GPU内存容量限制以及PyTorch软件栈中的低效率，包括缺乏针对特定设备的PCIe传输优化和高层次领域特定抽象等问题，都带来了主要挑战。为了有效减轻这些数据效率问题对深度学习训练的影响，本论文分析了代表性深度训练任务中的数据效率，特别是在图神经网络（GNN）和大型语言模型（LLM）中。随后，提出了新颖的运行时和代码生成技术来缓解这些挑战，并在PyTorch栈中无缝实现这些优化，同时保持强大的可编程性和互操作性。首先，设计了PyTorch-Direct，将其GPU中心化的PCIe数据传输范式引入PyTorch以用于GNN训练。接着，提出了Hector中间表示（IR）及其代码生成器，以引入领域特定的层次化抽象并系统地解决关系GNN的内存密集型性能挑战。最后，在LLM训练中，GPU内存容量越来越成为吞吐量的瓶颈。为了缓解这一点，设计了并实现了SSDTrain卸载框架。总之，这些贡献表明，代码生成和运行时技术可以系统地缓解深度学习训练中的数据管理瓶颈，这些瓶颈源于工作负载的数据密集型性质和深度学习训练软件栈中固有的过度简化。|
|**2024-12-06**|**Multi-Party Supervised Fine-tuning of Language Models for Multi-Party Dialogue Generation**|Xiaoyu Wang et.al.|[2412.05342](http://arxiv.org/abs/2412.05342)|null|大型语言模型（LLM）通常经过微调以参与二元或双方面对面的对话，但它们难以适应多方面对话（MPD），这阻碍了它们在包括多人大会议、讨论和日常交流等场景中的应用。以往基于LLM的研究主要关注多智能体框架，而它们的基LLM仍然进行成对微调。在这项工作中，我们为多方面对话数据集设计了一个针对LLM的多方面微调框架（MuPaS），并证明这样一个简单的框架可以使LLM有效地与多方面对话风格保持一致。我们还设计了两种训练策略，可以将MuPaS转换为MPD模拟器。大量实验表明，MuPaS可以实现最先进的多元回应，更高的一步说话者预测准确率，更高的人机和自动评估的语句质量，甚至可以生成合理的外部分布场景、主题和角色描述。MuPaS框架将LLM的训练与更复杂的多方面应用（如对话生成、虚拟排练或元宇宙）连接起来。|
|**2024-12-02**|**MALT: Improving Reasoning with Multi-Agent LLM Training**|Sumeet Ramesh Motwani et.al.|[2412.01928](http://arxiv.org/abs/2412.01928)|null|实现大型语言模型（LLM）之间的有效协作是开发能够解决复杂问题的自主系统的重要一步。虽然LLM通常作为单模型生成器使用，由人类对其输出进行批判和改进，但联合训练的协作模型潜力仍未得到充分探索。尽管在多智能体通信和辩论环境中取得了有希望的结果，但在训练模型共同完成任务方面进展甚微。在本文中，我们提出了在推理问题上进行“多智能体LLM训练”（MALT）的第一步。我们的方法采用了一种序列多智能体设置，将具有不同角色的异构LLM分配给专门的任务：生成器、验证器和改进模型迭代解决问题。我们提出了一种基于轨迹扩展的合成数据生成过程和一种由基于联合结果的奖励驱动的信用分配策略。这使得我们的后训练设置能够利用正负轨迹来自主改进每个模型的专门能力，作为联合序列系统的一部分。我们在MATH、GSM8k和CQA上评估了我们的方法，其中MALT在Llama 3.1 8B模型上分别实现了相对于同一基线模型的14.14%、7.12%和9.40%的相对改进。这证明了在数学和常识推理问题上的多智能体协作能力的一个早期进展。更广泛地说，我们的工作为围绕多智能体LLM训练方法的研究提供了具体方向。|
|**2024-12-02**|**Addressing Data Leakage in HumanEval Using Combinatorial Test Design**|Jeremy S. Bradbury et.al.|[2412.01526](http://arxiv.org/abs/2412.01526)|null|大型语言模型（LLMs）在许多领域得到了广泛应用，包括软件工程领域，其中它们被用于自动化诸如程序生成和测试分类等任务。随着基于LLM的方法不断进化，我们定义清晰且稳健的评估方法以公平地评估性能变得尤为重要。基准是评估LLMs解决特定任务能力以及评估LLM不同版本随时间解决任务的常见方法。例如，HumanEval基准由164个手工制作的任务组成，并已成为评估基于LLM的程序生成的重要工具。然而，使用如HumanEval这样的基准来公平评估LLMs的主要障碍是基准任务和解决方案数据泄露到训练数据集中导致的数据污染。这个问题由于LLM训练数据的黑盒性质而加剧，这使得甚至难以知道是否发生了数据泄露。为了解决数据泄露问题，我们提出了一种新的基准构建方法，其中基准由可以组合测试设计实例化为新具体任务的模板任务组成。对于同一模板任务的具体任务必须足够不同，以至于数据泄露的影响最小，同时足够相似，以便在性能评估方面可以互换。为了评估我们的基准构建方法，我们提出了HumanEval_T，这是一个使用模板任务和组合测试设计构建的替代基准。|
|**2024-12-02**|**Data-Centric and Heterogeneity-Adaptive Sequence Parallelism for Efficient LLM Training**|Yujie Wang et.al.|[2412.01523](http://arxiv.org/abs/2412.01523)|null|扩展LLM的上下文长度（即最大支持的序列长度）具有至关重要的意义。为了促进LLM的长上下文训练，序列并行性已成为一项关键技术，它将每个输入序列分散到多个设备上，并需要通信来处理序列。本质上，现有的序列并行性方法假设序列长度相同（即所有输入序列长度相等），因此为所有输入序列使用单一的、静态的散列策略。然而，在现实中，LLM训练语料库中的序列长度表现出很大的变化，通常遵循长尾分布，导致工作负载异构。在本文中，我们表明采用单一的、静态的策略会导致效率低下和资源利用率不足，强调了需要自适应方法来处理序列间的工作负载异构性。为了解决这个问题，我们提出了一种异构性自适应序列并行性方法。对于每个训练步骤，我们的方法捕捉序列长度的变化，并根据工作负载特性分配最佳的散列策略组合。我们将此问题建模为线性规划优化，并设计了一个高效有效的求解器来找到最优解。此外，我们将我们的方法实现在一个支持自适应并行化的高性能系统中，用于分布式LLM训练。实验结果表明，我们的系统在性能上优于最先进的训练框架，最多可提高1.98倍。|
|**2024-12-02**|**Scaling Law for Language Models Training Considering Batch Size**|Xian Shuai et.al.|[2412.01505](http://arxiv.org/abs/2412.01505)|null|近年来，大型语言模型（LLMs）取得了显著的进展，其中规模法则在快速进步中发挥了关键作用。在本文中，我们通过实验研究了一个关键超参数，即全局批量大小，如何影响LLM的训练过程。我们首先使用高达3000亿个高质量标记，训练了从1.25亿到26亿参数的语言模型。通过这些实验，我们建立了一个关于模型大小和训练数据量的基本规模法则。然后，我们考察了批量大小和学习率的变化如何影响这些模型的收敛性和泛化性。我们的分析在两种不同情况下得出了批量大小规模法则：固定计算预算和固定训练数据量。对不断增加规模模型的推算实验验证了我们的预测法则，为在特定资源约束下优化LLM训练策略提供了指导。|
|**2024-11-26**|**Low-Bit Quantization Favors Undertrained LLMs: Scaling Laws for Quantized LLMs with 100T Training Tokens**|Xu Ouyang et.al.|[2411.17691](http://arxiv.org/abs/2411.17691)|null|我们通过观察发现，在应用低比特量化时，规模较大或训练词数较少的语言模型（LLMs）的量化诱导退化（QiD）较小，而训练词数较多的小型模型则会遭受显著的QiD。为了更深入地了解这一趋势，我们在一个受控环境下研究了1500多个不同规模和训练水平（未训练或完全训练）的量化LLMs检查点，从而推导出QiD与训练词数、模型大小和比特宽度等因素之间的关系定律。利用这些定律，我们提出了一种新视角：可以使用QiD来衡量LLMs的训练水平，并确定不同规模LLMs完全训练所需的训练词数。此外，我们使用这些定律来预测使用100万亿个训练词训练的不同规模LLMs的量化性能。我们的预测表明，未来预期使用超过100万亿个训练词训练的低比特量化模型性能可能并不理想。这为未来的低比特量化提出了潜在的挑战，并突出了在评估低比特量化研究时需要关注模型训练水平。为了促进对此问题的未来研究，我们将本次工作中使用的1500多个量化检查点发布在https://huggingface.co/Xu-Ouyang上。|
|**2024-11-26**|**Enhancing Character-Level Understanding in LLMs through Token Internal Structure Learning**|Zhu Xu et.al.|[2411.17679](http://arxiv.org/abs/2411.17679)|**[link](https://github.com/FloatFrank/TIPA)**|**将文本分割成标记的编码技术，如字节对编码（BPE）和字节级BPE（BBPE），通过将文本分割成标记，显著提高了大型语言模型（LLMs）的计算效率和词汇表示稳定性。然而，这种分割通常掩盖了标记内部的字符结构和序列，导致模型在训练期间无法完全学习这些复杂的细节。因此，LLMs在理解标记内部的字符组成和位置关系方面存在困难，尤其是在使用有限数据的下游任务中进行微调时。在本文中，我们引入了一种名为标记内部位置感知（TIPA）的新方法，通过使用分词器自己的词汇进行反向字符预测任务来训练模型，从而增强LLMs对内部标记结构的理解。这种方法使模型能够有效地学习和泛化字符位置和内部结构。实验结果表明，使用TIPA训练的LLMs在预测标记级别的字符位置方面优于基线模型。此外，当应用于中文拼写纠正（CSC）的下游任务时，TIPA不仅加速了模型收敛，而且显著提高了任务性能。**|
|**2024-11-26**|**Using Large Language Models for Expert Prior Elicitation in Predictive Modelling**|Alexander Capstick et.al.|[2411.17284](http://arxiv.org/abs/2411.17284)|**[link](https://github.com/alexcapstick/llm-elicited-priors)**|**大型语言模型（LLMs）通过训练不同领域的数据，有效地获取了广泛的信息。然而，它们的计算复杂度、成本和缺乏透明度阻碍了它们在特定任务中的直接应用。在临床研究等领域的预测模型中，获取专家注释或先验知识通常是昂贵且耗时的。本研究提出使用LLMs来获取预测模型的专家先验分布。这种方法也为情境学习提供了一种替代方案，其中语言模型直接负责做出预测。我们比较了LLM获取的先验和无关先验，评估了LLM是否真实地生成了参数分布，并提出了情境学习和先验获取的模型选择策略。我们的研究发现，与无关先验相比，在数据量少的情况下，LLM获取的先验参数分布显著降低了预测误差。应用于临床问题，这意味着所需的生物样本更少，降低了成本和资源。先验获取也始终优于情境学习，且成本更低，因此在我们的环境中成为一种更受欢迎的替代方案。我们展示了该方法在各种用例中的实用性，包括临床应用。在感染预测中，使用LLM获取的先验，在研究中提前200天，以相同的准确度减少了55%所需的标签数量。**|
|**2024-11-26**|**Star Attention: Efficient LLM Inference over Long Sequences**|Shantanu Acharya et.al.|[2411.17116](http://arxiv.org/abs/2411.17116)|**[link](https://github.com/NVIDIA/Star-Attention)**|**由于自注意力机制的二次复杂度，基于Transformer的大型语言模型（LLM）在长序列上的推理既昂贵又缓慢。我们引入了星形注意力，这是一种两阶段块稀疏逼近，通过在多个主机之间分散注意力来提高计算效率，同时最小化通信开销。在第一阶段，通过主机间的块局部注意力并行处理上下文。在第二阶段，查询和响应标记通过序列全局注意力关注所有先前缓存的标记。星形注意力可以无缝集成到大多数使用全局注意力训练的基于Transformer的LLM中，通过减少内存需求和提高推理速度至多11倍，同时保持95-100%的准确率。**|
|**2024-11-25**|**The Two-Hop Curse: LLMs trained on A->B, B->C fail to learn A-->C**|Mikita Balesni et.al.|[2411.16353](http://arxiv.org/abs/2411.16353)|null|在论文摘要中，作者首先指出大型语言模型（LLMs）在采用思维链（CoT）进行多跳推理（如“Imagine表演者的配偶是谁？”）时表现出色，但在被迫进行内部推理（不使用CoT）时则表现不佳。作者提到之前关于这一差距大小和性质的研究产生了不一致的证据。在这篇论文中，作者介绍了一种控制环境，用于研究LLMs中的两跳推理，其中超出随机水平的性能构成了潜在推理不可否认的证据。作者在虚构事实上进行微调LLMs（包括Llama 3 8B Instruct和GPT-4o），并确认它们可以推广到使用CoT回答有关它们的两跳问题。作者发现，当事实在训练过程中或提示中一起出现时，模型可以进行潜在推理。然而，出乎意料的是，当学习的事实仅出现在不同的文档中时，模型在两跳推理上完全失败，达到了随机水平准确性和测试损失。作者将这种完全无法组合单独学习的事实称为“两跳诅咒”。此外，作者在真实事实上评估了9个前沿LLMs，发现模型在超过一半的问题类别上完全无法进行无CoT的两跳推理，而在大多数类别上仍然部分成功使用CoT。这些结果表明，LLMs缺乏一种独立于问题类型的一般能力来进行潜在的跨跳推理。|
|**2024-11-24**|**Hiding Communication Cost in Distributed LLM Training via Micro-batch Co-execution**|Haiquan Wang et.al.|[2411.15871](http://arxiv.org/abs/2411.15871)|null|随着大型语言模型（LLMs）的发展，大规模分布式训练变得必要。然而，高度优化的框架由于通信量大，在模型FLOPS利用率上仍然有显著的损失（通常低于50%）。同时，我们的全面分析显示，计算和通信密集型操作的重叠性很好。本文介绍了一种名为DHelix的新型微观结构，它受到DNA结构的启发，显著提高了LLM训练的效率。DHelix设计的核心是链式交错（SI），它将训练微批次连续流通过GPU视为两条链。DHelix并置两条链的前向和后向传递，并通过对称调度来自相对链的操作进行系统优化，这得益于操作级别的重叠分析结果和基于动态规划的搜索算法。同时，DHelix允许两条链共享模型状态和激活数据的空间，有效地容纳了额外内存空间低于3%的两个微批次。DHelix无缝集成到所有现有数据/模型并行形式，其中最具有挑战性的是管道并行，得益于其独特的模型折叠设计，形成了W型管道。我们使用流行的Llama和GPT密集模型，以及Phi混合专家（MoE）模型，在3个GPU集群（A40、A800和H100）上评估了DHelix的训练。结果显示，它在64-A40和64-A800集群上分别实现了12-40%（最高达到58%MFU）和2-29%（最高达到71%MFU）的提高，显著优于现有方法。在H100集群上，虽然更快的网络降低了DHelix的利润空间，但它使得跨节点张量并行成为可能，这在由于通信成本而目前难以实现的情况下是一种实践。|
|**2024-11-23**|**Seed-Free Synthetic Data Generation Framework for Instruction-Tuning LLMs: A Case Study in Thai**|Parinthapat Pengpun et.al.|[2411.15484](http://arxiv.org/abs/2411.15484)|**[link](https://github.com/parinzee/seed-free-synthetic-instruct)**|**我们提出了一种针对低资源语言（特别是泰语）的大语言模型（LLM）指令微调的合成数据方法，以数据高效的方式实现。我们确定了三个有助于指令微调数据集有效性的关键属性：流畅性、多样性和文化背景。我们提出了一种无需种子数据框架，用于生成包含这些基本属性的合成指令微调数据。我们的框架使用LLM生成多样化主题，从维基百科中检索相关上下文，并为各种任务（如问答、摘要和对话）创建指令。实验结果表明，我们的最佳表现合成数据集，结合了这三个关键属性，在仅使用5,000条指令的情况下，与在数万条指令上训练的顶尖泰语LLM相比，实现了具有竞争力的性能。我们的代码和数据集可在https://github.com/parinzee/seed-free-synthetic-instruct上公开获取。**|
|**2024-11-21**|**Exploring Accuracy-Fairness Trade-off in Large Language Models**|Qingquan Zhang et.al.|[2411.14500](http://arxiv.org/abs/2411.14500)|null|大型语言模型（LLMs）在人工智能领域取得了显著进展，展示了它们与人类互动和通过信息传播影响人类认知的能力。然而，最近的研究揭示了这些LLMs内含的偏见问题，这成为一个需要关注的重大问题。在我们的研究中，我们深入研究在LLMs增强过程中，如何协调准确性和公平性的复杂挑战。虽然提高准确性确实可以提升LLMs的整体性能，但这往往是以牺牲公平性为代价的。过度强调一个指标的优化必然会导致另一个指标的显著下降。这强调了在设计优化LLMs阶段时考虑多个因素的重要性。因此，我们主张将LLMs的训练过程重新定义为多目标学习任务。我们的研究揭示了多目标进化学习（MOEL）方法在应对这一挑战方面具有前景。我们的MOEL框架能够同时优化准确性和公平性指标，从而产生一组帕累托最优的LLMs。总之，我们的研究为LLMs中准确性和公平性之间的微妙平衡提供了宝贵的见解，这对于它们在现实世界中的应用越来越重要。通过利用MOEL，我们展示了一条通往更公平和更有效的AI技术的可行途径。|
|**2024-11-20**|**Assessing Gender Bias in LLMs: Comparing LLM Outputs with Human Perceptions and Official Statistics**|Tetiana Bas et.al.|[2411.13738](http://arxiv.org/abs/2411.13738)|**[link](https://github.com/tetianabas/llm_biases)**|**本研究通过比较大型语言模型（LLMs）对性别的感知与人类受访者、美国劳工统计局数据和50%无偏见基准的性别感知，来探讨LLMs中的性别偏见。我们使用职业数据和特定角色的句子创建了一个新的评估集。与LLMs训练数据中常见的基准不同，我们的集合是全新开发的，防止了数据泄露和测试集污染。我们对五个LLMs进行了测试，以使用单词答案预测每个角色的性别。我们使用Kullback-Leibler（KL）散度来比较模型输出与人类感知、统计数据和50%中性基准之间的差异。所有LLMs都显示出与性别中性的显著偏差，并且更符合统计数据，仍然反映了固有的偏见。**|
|**2024-11-20**|**Hardware Scaling Trends and Diminishing Returns in Large-Scale Distributed Training**|Jared Fernandez et.al.|[2411.13055](http://arxiv.org/abs/2411.13055)|null|近年来，神经网络模型能力的显著提升是由模型规模、训练数据和相应的计算资源扩展驱动的。为了开发现代应用（如大型语言模型）所需的无尽大型网络，模型训练需要在数万台硬件加速器（例如GPU）上分布进行，这要求在大规模计算集群中协调计算和通信。在本工作中，我们证明了仔细考虑硬件配置和并行化策略对于有效（即计算和成本高效）地扩展模型规模、训练数据和总计算量至关重要。我们对大规模LLM训练工作负载在模型规模、硬件配置和分布式并行化策略方面的性能进行了广泛的实证研究。我们证明了：（1）超过一定规模后，某些分布式通信策略带来的开销导致之前被认为次优的并行化策略实际上变得更为可取；（2）即使硬件和并行化策略得到适当优化，增加加速器的总数来扩大大型模型训练也会迅速产生递减回报，这意味着每增加一个单位的功率或GPU时长的边际性能较差。|

<p align=right>(<a href=#updated-on-20241211>back to top</a>)</p>

